言

## C++基础

#### 0、C++中的左值和右值

**左值与右值的定义**

C++( 包括 C) 中所有的表达式和变量要么是左值，要么是右值。通俗的左值的定义就是非临时对象，那些可以在多条语句中使用的对象。所有的变量都满足这个定义，在多条代码中都可以使用，都是左值。右值是指临时的对象，它们只在当前的语句中有效。请看下列示例 :

1. 简单的赋值语句

   

   在这条语句中，i 是左值，0 是临时值，就是右值。在下面的代码中，i 可以被引用，0 就不可以了。立即数都是右值。

2. 但是实际上右值是可以被修改的，如 :

```
T().set().get();
```

T 是一个类，set 是一个函数为 T 中的一个变量赋值，get 用来取出这个变量的值。在这句中，T() 生成一个临时对象，就是右值，set() 修改了变量的值，也就修改了这个右值。



**左值和右值的语法符号**

左值的声明符号为”&”， 为了和左值区分，右值的声明符号为”&&”。

~~~ C++
void process_value(int& i) { 
 std::cout << "LValue processed: " << i << std::endl; 
} 
 
void process_value(int&& i) { 
 std::cout << "RValue processed: " << i << std::endl; 
} 
 
int main() { 
 int a = 0;
 process_value(a); 
 process_value(1); 
}
~~~



**转移语义的定义**

右值引用是用来支持转移语义的。转移语义可以将资源 ( 堆，系统对象等 ) 从一个对象转移到另一个对象，这样能够减少不必要的临时对象的创建、拷贝以及销毁，能够大幅度提高 C++ 应用程序的性能。临时对象的维护 ( 创建和销毁 ) 对性能有严重影响。

转移语义是和拷贝语义相对的，可以类比文件的剪切与拷贝，当我们将文件从一个目录拷贝到另一个目录时，速度比剪切慢很多。

通过转移语义，临时对象中的资源能够转移其它的对象里。

在现有的 C++ 机制中，我们可以定义拷贝构造函数和赋值函数。要实现转移语义，需要定义转移构造函数，还可以定义转移赋值操作符。对于右值的拷贝和赋值会调用转移构造函数和转移赋值操作符。如果转移构造函数和转移拷贝操作符没有定义，那么就遵循现有的机制，拷贝构造函数和赋值操作符会被调用。

普通的函数和操作符也可以利用右值引用操作符实现转移语义。



reference：https://www.ibm.com/developerworks/cn/aix/library/1307_lisl_c11/index.html



#### 1、const** define constexpr

1. const限定的变量的值将不能被改变，任何试图改变他的值的行为都将引发错误

2. const变量必须初始化

3. 默认状态下，const对象仅在本文件内有效，如果程序中包含多个文件，则需要在多个文件中都定义同名的const变量，才可以使编译器在编译的过程中把用到该变量的地方都替换成对应的值，此时同名的const变量相当于在不同文件中定义了独立的变量

4. 如果需要将一个const对象在多个文件中实现共享，则声明和定义+extern即可（在一个文件中定义，在其他文件中声明）

5. 在常量初始化的过程中需要注意：常量=（常量/普通变量）但是 不能用常量给普通变量赋值

6. const可以修饰变量（var/指针）+引用

   因为指针是对象，所以：

   第一类：常量指针(* const)和常量对象 const var类似

   第二类：指向常量的指针(const *)和指向常量的引用类似

   ​	常量指针指的是：指针本身不可变，将不能再指向其他的地址，但如果常量指针指向的是一个普通变量，则可以通过该常量指针对指向的变量进行重新赋值

   ​	指向常量的指针：该指针还可以继续指向其他的地址，且指向的是一个常量，对该指针的解引用不能再次赋值(更改其值)



> 指针本身是一个对象，他又可以指向另一个对象，因此指针本身是不是常量，以及指针所指向的是不是一个常量是两个独立的问题，所以顶层const用于表示，指针本身是一个常量，而底层const便表示指针所指向的对象是一个常量
>
> 一般：顶层const：表示任意的对象是常量
>
> ​	   底层const则与指针和引用等符合类型的基本类型相关
>
> ​	   用于声明引用的const都是底层const



**成员函数的前后const**

* 在函数名后+const修饰符

  在c++中，只有被声明为const的成员函数才能被一个const类对象调用，要声明一个const类型的类成员函数，只需要在其后+const（char get() const;）

  只能再成员函数后面+const，类的静态函数或者非成员函数不可以

  +const后，说明函数的成员对象是不允许修改的，成员函数的第一个位置是this指针，则说明this指针的值是不可以修改的，只能读取

  ~~~ C++
  class Screen {
  public:
  int ok() const {return _cursor; }
  int error(intival) const { _cursor = ival; }
  };
  ~~~

  值得注意的是，把一个成员函数声明为const可以保证这个成员函数不修改数据成员，但是，如果据成员是指针，则const成员函数并不能保证不修改指针指向的对象，编译器不会把这种修改检测为错误

  const成员函数可以被具有相同参数列表的非const成员函数重载，在这种情况下，类对象的常量性决定调用哪个函数。

  

* 在函数名前+const修饰符

  表示该函数的返回值只能读取，不能修改

**c++如何定义常量**

~~~ C++
#define PRICE 10 //定义单价常量10
const int PRICE = 10; //定义单价常量10
~~~

1) const 常量有数据类型,而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换,没有类型安全检查,并且在字符替换可能会产生意料不到的错误(边际效应) 。 

(2) 有些集成化的调试工具可以对 const 常量进行调试, 但是不能对宏常量进行调试。

(3)define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。const常量会在内存中分配

const定义常量从**汇编的角度**来看，只是给出了对应的内存地址，而不是象#define一样给出的是立即数，所以，const定义的常量在程序**运行过程**中只有一份拷贝（**因为是全局的只读变量，存在静态区**），而 #define定义的常量在**内存**中有若干个拷贝。

reference:https://www.jianshu.com/p/d3866a219633

reference：https://blog.csdn.net/qq_32811489/article/details/53360443 

**constexpr**

​	constexpr函数是指用于常量表达式的函数，函数的返回类型和参数类型都是字面值类型，且函数体中必须有且只有一条return语句

​	constexpr是内联函数

​	编译器会把对constexpr的函数调用替换成其结果值（常量表达式），当把constexpr函数用于常量表达式的上下文中时（如constexpr的函数返回值是常量表达式的一个因子），则编译器负责检查函数的结果是否符合要求，如果结果恰好不是常量表达式，编译器将发出错误。

#### **2、static**

1. 局部静态对象在程序的执行路径第一次经过对象的定义语句时进行初始化，生命周期贯穿函数调用及其之后的时间，直到程序终止时才被销毁

2. 局部静态变量默认初始化为0

3. 静态数据成员

   1. 在类内数据成员前加上 static 关键字，即为静态数据成员
   2. 对于类静态数据成员，无论有多少个该类的对象，该静态数据成员在内存中只有一份拷贝(其他普通数据成员，每个类对象都有自己的内存拷贝)，该静态数据成员由所有该类对象共享
   3. 静态数据成员存储在全局数据区，在定义时分配存储空间，程序运行结束时销毁
   4. 静态数据成员不能再类中定义和初始化，只能在类中声明，在类外进行定义和初始化，默认初始化为0
   5. 静态数据成员的初始化为 <类型名> <类名>::<变量名> = <值>
   6. 静态数据成员遵从 public private protected 访问规则
   7. 静态数据成员可以直接使用类名加作用域运算符(::)直接访问 <类名>::<变量名>(访问规则允许的情况下)

   每一个static data member只有一个实例，存放在程序的.data区，每次程序参阅（取用）static data member时，就会被内部转化为对给唯一extern实例的直接参考操作

   ​	若取一个static data member的地址，会得到一个指向其数据类型的指针，而不是一个指向其class 的指针

4. 静态成员函数

   1. 在普通类成员函数前加上 static 关键字，即为静态成员函数
   2. 在类外定义静态成员函数时，不用再加 static 关键字，只要在类中声明时加上即可
   3. 静态成员函数只能访问静态数据成员和静态成员函数，普通成员函数可以访问静态成员函数和静态数据成员
   4. 静态成员函数属于类，不属于任意一个类对象
   5. 静态成员函数没有 this 指针
   6. 可以使用 <类名>::<函数名> 访问，也可由类对象使用(./->)访问



#### **3、函数指针的作用**

​	函数指针指向的是函数，每个函数都有一个入口地址，该入口地址就是函数指针指向的地址，有了指向函数的指针变量后，就可以用该指针变量调用函数了

​	函数指针的类型：指向函数类型的指针（函数类型由返回类型+参数类型共同决定，与函数名无关）

​	函数名代表函数的入口地址，所以可以直接用函数名来初始化函数指针

​	在使用过程中，函数指针可以作为形参或返回值

​	**作用**

​	虽然函数不能定义函数类型的形参和函数类型的返回值，但是可以定义函数指针形参和函数指针返回值

​	1.函数指针主要是能够用一个指针的方式指向一个函数，并且还可以换换指向别的函数，比如有多个函数的申明，它们有不同的具体实现，如果需要调用它们，就可以用一个指针轮流指向它们。如虚拟机制（虚拟机制这个事情还需要进一步考虑）

​	2另外，有些地方必须使用函数函数指针才能完成给定的任务，如linux系统中的异步信号中断处理，当发生某一触发信号时，需要调用相应的处理函数，此时需要使用函数指针来实现



#### **4、野指针**

​	野指针指向一个已经被删除的对象或访问受限的内存区域的[指针](https://baike.baidu.com/item/%E6%8C%87%E9%92%88/2878304)。与空指针不同，野指针无法通过简单地判断是否为 [NULL](https://baike.baidu.com/item/NULL)避免

​	**成因**

 1. 指针变量未初始化

    任何[指针变量](https://baike.baidu.com/item/%E6%8C%87%E9%92%88%E5%8F%98%E9%87%8F)刚被创建时不会自动成为NULL指针，它的缺省值是随机的，它会乱指一气。所以，指针变量在创建的同时应当被初始化，要么将指针设置为NULL，要么让它指向合法的内存。如果没有初始化，编译器会报错“ ‘point’ may be uninitializedin the function ”。

2. 指针释放之后未置空

   ​	有时[指针](https://baike.baidu.com/item/%E6%8C%87%E9%92%88)在free或delete后未赋值 NULL，便会使人以为是合法的。别看free和delete的名字（尤其是delete），它们只是把指针所指的内存给释放掉，但并没有把指针本身干掉。此时指针指向的就是“垃圾”内存。

   ​	free()释放的是指针指向的内存！不是指针！这点非常非常重要！指针是一个变量，只有程序结束时才被销毁。释放了内存空间后，原来指向这块空间的指针还是存在！只不过现在指针指向的内容的垃圾，是未定义的，所以说是垃圾。

   ​	因此，释放后的指针应立即将指针置为NULL，防止产生“野指针”

3. 指针操作超越变量作用域

   **注意**

   * 不要返回指向栈内存的指针或引用，因为栈内存在函数结束时会被释放
   * 在使用指针进行内存操作前记得要先给指针分配一个动态内存



#### **5、sizeof 各种基本类型 结构体 类**

​	sizeof是一个运算符，在编译阶段求值，返回constexpr size_t类型

注：

int a = 0;

cout<<sizeof(a=3)<<endl;

sizeof在编译阶段处理。由于sizeof不能被编译成机器码，所以sizeof作用范围内，也就是()里面的内容也不能被编译，而是被替换成类型。=操作符返回左操作数的类型，所以a=3相当于int，而代码也被替换为：

int a = 0;

cout<<4<<endl;

所以不要把sizeof当成函数，也不要看作一元操作符，把他当成一个特殊的编译预处理



* 基本类型：

* 基本类型：

 	1. char或者类型为char的表达式：1
 	2. 引用：被引用对象所占的空间
 	3. 指针：指针本身所占用的空间
 	4. 解引用指针：指针所指向对象所占用的空间，指针不需要有效，也就是说当指针所指向的对象未进行初始化的时候，也可以通过sizeof进行运算

* 构造数据类型：

1. 数组：基础元素*数组元素个数

   int *d = new int[10];

   cout<<sizeof(d)<<endl; // 4

   d是我们常说的动态数组，但是他实质上还是一个指针，所以sizeof(d)的值是4。

2. string：

   string的实现在各库中可能有所不同，但是在同一库中相同一点是，无论你的string里放多长的字符串，他的sizeof都是固定的，字符串所占的空间是从堆中动态分配的，与sizeof无关（注意此时是string类，而不是char *表示的c风格字符串，c++的string类已经封装了strlen()和capacity()，所以尽量使用string而不是char * ）

   字符串的sizeof和strlen

   ​    考虑下面的问题：

   char a[] = "abcdef";

   char b[20] = "abcdef";

   string s = "abcdef";

   cout<<strlen(a)<<endl;   // 6，字符串长度

   cout<<sizeof(a)<<endl;   // 7，字符串容量

   cout<<strlen(b)<<endl;   // 6，字符串长度

   cout<<sizeof(b)<<endl;   // 20，字符串容量

   cout<<sizeof(s)<<endl;   // 12, 这里不代表字符串的长度，而是string类的大小

   cout<<strlen(s)<<endl;   // 错误！s不是一个字符指针。

   a[1] = '\0';

   cout<<strlen(a)<<endl;   // 1

   cout<<sizeof(a)<<endl;   // 7，sizeof是恒定的，没有指定大小的时候，容量恒定为7	

​       strlen是寻找从指定地址开始，到出现的第一个0之间的字符个数，他是在运行阶段执行的，而sizeof是得到数据的大小，在这里是得到字符串的容量。所以对同一个对象而言，sizeof的值是恒定的。string是C++类型的字符串，他是一个类，所以sizeof(s)表示的并不是字符串的长度，而是类string的大小。strlen(s)根本就是错误的，因为strlen的参数是一个字符指针，如果想用strlen得到s字符串的长度，应该使用sizeof(s.c_str())，因为string的成员函数c_str()返回的是字符串的首地址。实际上，string类提供了自己的成员函数来得到字符串的容量和长度，分别是Capacity()和Length()。string封装了常用了字符串操作，所以在C++开发过程中，最好使用string代替C类型的字符串。

3. vector：与string类似，返回该类型固定部分的大小
4. union共用体：

union u

{

   double a;

   int b;

};

union u2

{

   char a[13];

   int b;

};

union u3

{

   char a[13];

   char b;

};

cout<<sizeof(u)<<endl;   // 8

cout<<sizeof(u2)<<endl;   // 16

cout<<sizeof(u3)<<endl;   // 13

​    都知道union的大小取决于它所有的成员中，占用空间最大的一个成员的大小。所以对于u来说，大小就是最大的double类型成员a了，所以sizeof(u)=sizeof(double)=8。但是对于u2和u3，最大的空间都是char[13]类型的数组，为什么u3的大小是13，而u2是16呢？关键在于u2中的成员int b。由于int类型成员的存在，使u2的对齐方式变成4，也就是说，u2的大小必须在4的对界上，所以占用的空间变成了16（最接近13的对界）。

​    结论：结论：复合数据类型，如union，struct，class的对齐方式为成员中对齐方式最大的成员的对齐方式



5. 结构体：

   因为对齐问题使结构体的sizeof变得比较复杂

   struct s1

   {

      char a;

      double b;

      int c;

      char d;

   };

   struct s2

   {

      char a;

      char b;

      int c;

      double d;

   };

   cout<<sizeof(s1)<<endl; // 24

   cout<<sizeof(s2)<<endl; // 16

   ​    同样是两个char类型，一个int类型，一个double类型，但是因为对界问题，导致他们的大小不同。计算结构体大小可以采用元素摆放法，我举例子说明一下：首先，CPU判断结构体的对界，根据上一节的结论，s1和s2的对界都取最大的元素类型，也就是double类型的对界8。然后开始摆放每个元素。

   ​    对于s1，首先把a放到8的对界，假定是0，此时下一个空闲的地址是1，但是下一个元素d是double类型，要放到8的对界上，离1最接近的地址是8了，所以d被放在了8，此时下一个空闲地址变成了16，下一个元素c的对界是4，16可以满足，所以c放在了16，此时下一个空闲地址变成了20，下一个元素d需要对界1，也正好落在对界上，所以d放在了20，结构体在地址21处结束。由于s1的大小需要是8的倍数，所以21-23的空间被保留，s1的大小变成了24。

   ​    对于s2，首先把a放到8的对界，假定是0，此时下一个空闲地址是1，下一个元素的对界也是1，所以b摆放在1，下一个空闲地址变成了2；下一个元素c的对界是4，所以取离2最近的地址4摆放c，下一个空闲地址变成了8，下一个元素d的对界是8，所以d摆放在8，所有元素摆放完毕，结构体在15处结束，占用总空间为16，正好是8的倍数。



6. class：

   * 普通class（只含有普通变量（没有const static），普通函数，构造、析构函数的）的sizeof和struct一致，因为类的大小和普通成员函数，构造、析构函数无关

   * 当class是空类时，为1:他有一个隐藏的被编译器安插进去的1byte大小的char，这使得这一class的两个objects对象在内存中拥有独一无二的地址
   * class之间的普通继承（等价于struct中包含struct的计算）
   * classA包含虚函数，A的派生或者存在虚继承时，考虑隐藏元素（指向虚函数表的指针（4字节））
   * 静态数据成员不影响类的大小

   

   1空类

   class A {};
   1
   大小为1。 
   类的实例化就是给每一个实例在内存中分配一块地址。空类被实例化时，会由编译器隐含的添加一个字节。所以空类的size为1。 

   

   2 虚函数

   class A
   {
   public:
   virtual void fun() {};
   virtual void fun2() {};
   };
   大小为4。 
   当C++类中有虚函数的时候，会有一个指向虚函数表(V-table)的指针，所有的虚函数都在这个表中。指针大小为4，所以size为4。

   在来看如下代码：

   class A
   {
   public:
       char b;
       short c;
       int a;
   };
   class B
   {
   public:
       char a;
       int c;
       short b;
   };
   考虑数据对齐，大小分别为 8 和 12。如果我们将int 换成虚函数，回事什么结果呢？

   class A
   {
   public:
       char b;
       short c;
       virtual void fun() {}
   };
   class B
   {
   public:
       char a;
       virtual void fun() {}
       short b;
   };

   大小分别为 8 8。 都是占4个字节，结果不一样。 这是因为，为了效率问题，编译器(gcc 和 微软)一般会把虚指针放在类的内存空间的最前面的位置，不管虚函数声明的位置。考虑对齐，大小都是 4 +1+1+2 = 8.

   

   3 静态数据成员

   class A
   {
   public:
       char b;
       virtual void fun() {};
       static int c;
   };
   大小为8。 
   静态数据成员被编译器放在程序的一个global data members中，它是类的一个数据成员，但不影响类的大小。不管这个类产生了多少个实例，还是派生了多少新的类，静态数据成员只有一个实例。静态数据成员，一旦被声明，就已经存在。 考虑到数据对齐， 最终是8字节。

   

   4 普通成员函数

   class A
   {
   public:
       void fun() {};
   };

   大小为1。 
   类的大小与构造函数，析构函数，普通成员函数无关。

   

   5 普通单继承

   class A 
   {
       int c;
   };
   class B : public A
   {
       int a;
   };

   大小分别为4 和 8。 可以看到普通的继承就是基类的大小+派生类自身的大小。注意数据对齐。 
   注意：类的数据成员按其声明顺序加入内存，无访问权限无关，只看声明顺序。

   class A
   {
       int a;
       char b;
   };
   class C : public A
   {
   public:
       char c;
   };

   上面这段代码，不同的编译器结果不同，VS的结果是 8 和 12， GCC是8 和 8。VS中 相当于

   class C
   {
       A a;
       char c;
   };

   A的大小为8，对齐值为4， 则考虑总体对齐 8 + 1 + 3(padding) = 12。 
   GCC 则是

   class C
   {
       int a;
       char b;
       char c;
   };

   结果为 4 + 1 + 1 + 2 = 8。

   

   6 含虚函数的单继承

   class A
   {
       virtual void fun () {}
   };
   class C : public A
   {
   public:
       virtual void fun2() {}
   };
   大小分别为4 和 4。派生类继承了基类的虚指针，所以大小为4。

   

   7 虚单继承

   class A
   {
       virtual void fun () {}
   };

   class C : virtual public  A
   {
   public:
       virtual void fun2() {}
   };
   这段代码，VS和gcc结果不一样。VS为 4 和 12。 gcc为4 和4。

   

   8 普通多继承

   class A
   {
       int a;
       char b;
   };

   class B
   {
       char b;
   };
   class C : public  A, public B
   {
   public:
       char c;
   };
   VS：8 1 12 
   GCC：8 1 8 
   VS中相当于把A B当做整体看待， GCC则拆分整合。

   

   9 虚函数多继承

   class A
   {
       virtual void fun() {}
   };

   class B
   {
       virtual void fun2() {}
   };
   class C : public  A, public B
   {
   public:
       virtual void fun3() {}
   };
   结果为 4 4 8。分析：类A一个虚函数表，类B一个虚函数表，类C继承了两个虚函数表，并把自己的虚函数写在了继承顺序中第一个虚函数表中。

   

   10 虚继承

   class A
   {
       virtual void fun() {}
   };

   class B
   {
       virtual void fun2() {}
   };
   class C : virtual public  A, virtual public B
   {
   public:
       virtual void fun3() {}
   };
   GCC： 4 4 8 

   VS：4 4 16



7. 函数类型：

   int f1(){return 0;};

   double f2(){return 0.0;}

   void f3(){}

   cout<<sizeof(f1())<<endl; // f1()返回值为int，因此被认为是int

   cout<<sizeof(f2())<<endl; // f2()返回值为double，因此被认为是double

   cout<<sizeof(f3())<<endl; // 错误！无法对void类型使用sizeof

   cout<<sizeof(f1)<<endl;   // 错误！无法对函数指针使用sizeof   

   cout<<sizeof*f2<<endl;   // *f2，和f2()等价，因为可以看作object，所以括号不是必要的。被认为是double

   结论：对函数使用sizeof，在编译阶段会被函数返回值的类型取代

reference：https://www.cnblogs.com/wanghetao/archive/2012/04/04/2431760.html



#### **6、main函数有没有返回值，分别针对什么情况。如果出现异常，怎么捕获**

​	main函数可以不写return语句，这时当执行完最后一条语句后自动执行一条“return 0;”语句。

​	一般main函数通过返回值把整个程序的执行情况告诉调用者（通常是系统调用，但是系统调用通常会忽视main函数的返回值），一般情况下0表示正常结束，-1表示非正常结束

​	C++的异常情况主要分为两种，一种是编译时的语法错误，另一种是运行时异常，例如访问越界，内存不足等。异常机制专门用于处理运行时异常。当出现异常时，异常事件在C++中表示为异常对象，程序使用throw关键字抛出异常对象，抛出点称为异常出现点，由操作系统为程序设置当前异常类型，然后执行程序的当前异常处理代码块，在包含了异常出现点的最内层的try块，依次匹配catch语句中的异常对象。若匹配成功，则执行catch块内的异常处理语句，然后接着执行try…catch…块之后的代码。如果在当前的try…catch…块内找不到匹配该异常对象的catch语句,则由更外层的try…catch…块来处理该异常；如果当前函数内所有的try…catch…块都不能匹配该异常，则递归回退到调用栈的上一层去处理该异常。如果一直回退到主函数main()都不能处理该异常，则调用系统函数terminate()终止程序。

​	（所有未被捕获的异常最终都会交由std::unexpected()函数处理，缺省情况下该函数会调用std::terminate()函数，而后者又会调用abort()函数终止进程。）

 	void unexpected()在退完栈后立即被调用

​	函数unexpected()将不会返回……

​	当一个函数试图抛出没有列出的异常时，通过unexpected()函数调用了一个异常处理函数。这个异常处理函数的默认实现是调用terminate() 来结束[程序](http://www.chinaitpower.com/Dev/index.html)。可以通过将默认处理函数改为自己的处理函数即可对捕获的异常进行处理而不是直接终止程序。

​	且在异常处理的过程中需要关注局部对象的析构

​	异常抛出的新对象并非创建在函数栈上，而是创建在专用的异常栈上，因此它才可以跨接多个函数而传递到上层，当异常对象与catch语句成功匹配上后，在该catch语句的结束处被自动析构。所有从try到throw语句之间的局部对象的析构函数将被自动调用。但如果一直上溯到main函数后还没有找到匹配的catch块，那么系统调用terminate()终止整个程序，这种情况下不能保证所有局部对象会被正确地销毁。



#### **7、关于C中宏定义的问题**

​	C预处理器在源代码编译之前对其进行一些文本性质的操作，主要任务包括删除注释、插入被#include进来的文件内容、定义和替换由#define 定义的符号以及确定代码部分内容是否根据条件编译（#if )来进行编译。”文本性质”的操作

​	#define是C语言中提供的宏定义命令

​	源程序在进行编译时，需要经过预处理，编译，汇编和连接四个阶段，预处理器将源程序文件中出现的对宏的引用展开成相应的宏 定义，即本文所说的#define的功能，由预处理器来完成。
经过预处理器处理的源程序与之前的源程序有所有不同，在这个阶段所进行的工作只是纯粹的替换与展开，没有任何计算功能

​	#define的使用

​	如果一个define的第二部分特别长的话，可以使用把它分成几行来写，出了最后一行之外，每行的末尾都要加一个反斜杠

​	**宏(macro)**

​	#define 机制还允许把参数替换到文本中，这种实现机制被为**宏(macro)**,2333千呼万唤使出来，原来这个带参数的才叫宏呀，上面说过的define充其量就是一个”定义”。

​	#**define** name(parameter-list) stuff

​	**但是需要注意的是，所有用于数值表达式进行求值的宏定义都要将stuff里面出现参数的地方加上括号，同时将stuff加上括号，这么做为了保证运算优先级**

​	如：#**define** SQUARE(x) ((x)*(x))

​	而不是：#define SQUARE(x) x*x   

​	或    #define SQUARE(x) (x)*(x)

​	放置出现  **int** b =a+1*a+1;     

​	和    int c =121/(a+1)*(a+1); 的情况



#### **8、智能指针及实现（隐含空悬指针问题）**

​	动态内存的管理通过使用new和delete来实现，他的使用很容易出现问题，有时我们会忘记释放内存，在这种情况下会造成内存泄露，有时在上游指针引用内存的情况下我们就释放了他，在这种情况下会产生引用非法内存的指针，所以出现了shared_ptr和unique_ptr

​	C++标准库中提供了一种叫做智能指针(shared_ptrs)的类，智能指针的作用有如同指针，但会记录有多少个shared_ptrs共同指向一个对象。这便是所谓的引用计数。一旦最后一个这样的指针被销毁，也就是一旦某个对象的引用计数变为0，这个对象会被自动删除。**shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。**

​	C++程序设计中使用堆内存是非常频繁的操作，堆内存的申请和释放都由程序员自己管理。程序员自己管理堆内存可以提高了程序的效率，但是整体来说堆内存的管理是麻烦的，C++11中引入了智能指针的概念，方便管理堆内存。使用普通指针，容易造成堆内存泄露（忘记释放），二次释放，程序发生异常时内存泄露等问题等，使用智能指针能更好的管理堆内存。

​	智能指针类将一个计数器与类指向的对象相关联，引用计数跟踪该类有多少个指针共同指向同一个对象。每次创建类的新对象时，初始化指针并将引用计数置为1；当共享指针对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；对一个共享对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。智能指针就是模拟指针动作的类。所有的智能指针都会重载 -> 和 * 操作符。智能指针还有许多其他功能，比较有用的是自动销毁。这主要是利用栈对象的有限作用域以及临时对象（有限作用域实现）析构函数释放内存。

​	(当引用计数为0时，shared_ptr通过调用所指对象的析构函数完成自动销毁，并释放它所占的内存)

​	注：共享指针不能用普通指针进行赋值：因为这是两种不同的类类型（类对象 ，且不存在继承关系）

​	**简单实现**

~~~ C++
template <typename T>
class smart_ptrs {

public:
    smart_ptrs(T*); //用普通指针初始化智能指针
    smart_ptrs(smart_ptrs&);

    T* operator->(); //自定义指针运算符
    T& operator*(); //自定义解引用运算符
    smart_ptrs& operator=(smart_ptrs&); //自定义赋值运算符
    
    ~smart_ptrs(); //自定义析构函数

private:
    int *count; //引用计数
    T *p; //智能指针底层保管的指针
};

跟标准库一样，我们使用模板来实现它。

用普通指针进行初始化时，需要将该指针进行封装，并且引用计数初始化为1。
template <typename T>
smart_ptrs<T>::smart_ptrs(T *p): count(new int(1)), p(p) {
}

template <typename T>
//对普通指针进行拷贝，同时引用计数器加1，因为需要对参数进行修改，所以没有将参数声明为const
smart_ptrs<T>::smart_ptrs(smart_ptrs &sp): count(&(++*sp.count)), p(sp.p)  {
}

定义指针运算符：
template <typename T>
 T* smart_ptrs<T>::operator->() {
    return p;
 }

定义解引用运算符，直接返回底层指针的引用：
template <typename T>
T& smart_ptrs<T>::operator*() {
    return *p;
}

定义赋值运算符，左边的指针计数减1，右边指针计数加1，当左边指针计数为0时，释放内存：
template <typename T>
smart_ptrs<T>& smart_ptrs<T>::operator=(smart_ptrs& sp) {
    //新赋值的count++
    ++*sp.count;
    //原来指向的count--
    if (--*count == 0) { //自我赋值同样能保持正确
        delete count;
        delete p;
    }
    this->p = sp.p;
    this->count = sp.count;
    return *this;
}

定义析构函数：
template <typename T>
smart_ptrs<T>::~smart_ptrs() {
    if (--*count == 0) {
        delete count;
        delete p;
    }
}
~~~

**其他扩展**

**make_shared()**

​	最安全的分配和使用动态内存的方法是调用make_shared()函数，该函数在动态内存中分配一个对象并初始化他，返回指向该对象的shared_ptr



**unique_ptr**

​	一个unique_ptr拥有它所指向的对象，在某个时刻，一个unique_ptr只能指向一个对象，当unique_ptr被销毁时，他所指向的对象也会被销毁。



**weak_ptr**

​	将一个weak_ptr绑定在一个shared_ptr上，不会改变shared_ptr的引用计数，一旦最后一个指向对象的shared_ptr被小回去，即使有weak_ptr指向他，对象也还是会释放。

​	由于weak_ptr所指向的对象可能不存在，我们不能使用weak_ptr直接访问对象，而必须调用lock函数，检查weak_ptr所指向的对象是否存在，如果对象存在，lock()函数返回一个指向共享对象的shared_ptr，否则返回一个空shared_ptr。

​	虽然weak_ptr不能影响共享对象的生存周期，但是可以阻止用户访问一个不再存在的vector的企图。

​	除此之外，weak_ptr还提供了expired()函数来判断所指对象是否已经被销毁。

**注：**

​	weak_ptr并没有重载operator->和operator *操作符，因此不可直接通过weak_ptr使用对象，典型的用法是调用其lock函数来获得shared_ptr示例，进而访问原始对象。

​	所以weak_ptr不能用原生指针来实现。

**RAII：**

​	在栈展开的过程中，会依次调用局部对象的析构函数释放资源。为了避免内存泄漏的情况，应该采用RAII机制（Resource acquisition is initialization，资源获取即初始化），即以对象管理资源，把资源数据用对象封装起来。程序发生异常，执行栈展开时，封装了资源的对象会自动调用其析构函数以释放资源。C++中的智能指针便符合RAII机制



**智能指针的线程安全**

reference：https://blog.csdn.net/solstice/article/details/8547547

shared_ptr<Foo> x(new Foo)

![sp1](http://images.cnitblog.com/blog/112777/201301/28051716-748d3a6587fa498ca055ac6879dbb5f9.png)

shared_ptr<Foo> y = x;

![img](http://images.cnitblog.com/blog/112777/201301/28051717-7cfd55d9140043b19a9596b3f641965a.png)

智能指针包含两个数据成员，具体的复制过程可以分为两个步骤：

中间步骤 1，复制 ptr 指针：

![sp3](http://images.cnitblog.com/blog/112777/201301/28051718-1701317d7aa844908a5a5a1ac3a47dee.png)

中间步骤 2，复制 ref_count 指针，导致引用计数加 1：

![sp4](http://images.cnitblog.com/blog/112777/201301/28051718-fe9595cd458940bab9313d699d6cfb41.png)

在多线程环境中，无论是两个步骤还是一个步骤都会出现race condition，需要利用锁机制来保证线程安全

考虑一个简单的场景

- shared_ptr<Foo> g(new Foo); // 线程之间共享的 shared_ptr
- shared_ptr<Foo> x; // 线程 A 的局部变量
- shared_ptr<Foo> n(new Foo); // 线程 B 的局部变量

![sp5](http://images.cnitblog.com/blog/112777/201301/28051719-683eba58c3744417b9f5829aaedf872b.png)

线程 A 执行 x = g; （即 read g），以下完成了步骤 1，还没来及执行步骤 2。这时切换到了 B 线程。

![sp6](http://images.cnitblog.com/blog/112777/201301/28051720-e25d8dd42ec440aa9f1675c52ef1f898.png)

同时编程 B 执行 g = n; （即 write g），两个步骤一起完成了。

先是步骤 1：

![sp7](http://images.cnitblog.com/blog/112777/201301/28051721-38f027311ff449709a42aa2d6caeb24d.png)

再是步骤 2：

![sp8](http://images.cnitblog.com/blog/112777/201301/28051721-66b4ed146abc44a1b3c3155c0326ded8.png)

这是 Foo1 对象已经销毁，x.ptr 成了空悬指针！

最后回到线程 A，完成步骤 2：

![sp9](http://images.cnitblog.com/blog/112777/201301/28051722-fd09bc0bd2984d7c84e2068268d4a9e5.png)

多线程无保护地读写 g，造成了“x 是**空悬指针**”的后果。这正是多线程读写同一个 shared_ptr 必须加锁的原因。

当然，race condition 远不止这一种，其他线程交织（interweaving）有可能会造成其他错误。



**智能指针出现循环引用怎么解决？**

shared_ptr<A> a (new A())；//A()的引用计数为1

shared_ptr<A> b = a;//现在a、b同时指向A(),A()的引用计数为2

~~~ C++
class B;
class A
{
public:
　　shared_ptr<B> m_b;
};
 
class B
{
public:
　　shared_ptr<A> m_a;
};
 
int main()
{
　　while (true)
　　{
　　　　shared_ptr<A> a(new A); //new出来的A的引用计数此时为1
　　　　shared_ptr<B> b(new B); //new出来的B的引用计数此时为1
　　　　a->m_b = b; //B的引用计数增加为2
　　　　b->m_a = a; //A的引用计数增加为2
　　}
 
　　//b先出作用域，B的引用计数减少为1，不为0，所以堆上的B空间没有被释放，且B持有的A也没有机会被析构，A的引用计数也完全没减少
 
　　//a后出作用域，同理A的引用计数减少为1，不为0，所以堆上A的空间也没有被释放
}
~~~

​	所以在使用基于引用计数的智能指针时，要特别小心循环引用带来的内存泄漏，循环引用不只是两方的情况，只要引用链成环都会出现问题。当然循环引用本身就说明设计上可能存在一些问题，如果特殊原因不得不使用循环引用，那可以让引用链上的一方持用普通指针（或弱智能指针weak_ptr）即可。

reference：https://www.cnblogs.com/itZhy/archive/2012/10/01/2709904.html

**使用weak_ptr来打破循环引用**

~~~ C++
#include <iostream>
#include <memory>
using namespace std;

class B;
class A
{
public:// 为了省去一些步骤这里 数据成员也声明为public
    weak_ptr<B> pb;
    //shared_ptr<B> pb;
    void doSomthing()
    {
        shared_ptr<B> pp = pb.lock();
        if(pp)//通过lock()方法来判断它所管理的资源是否被释放
        {
            cout<<"sb use count:"<<pp.use_count()<<endl;
        }
    }

    ~A()
    {
        cout << "kill A\n";
    }
};

class B
{
public:
    //weak_ptr<A> pa;
    shared_ptr<A> pa;
    ~B()
    {
        cout <<"kill B\n";
    }
};

int main(int argc, char** argv)
{
    shared_ptr<A> sa(new A());
    shared_ptr<B> sb(new B());
    if(sa && sb)
    {
        sa->pb=sb;
        sb->pa=sa;
    }
    sa->doSomthing();
    cout<<"sb use count:"<<sb.use_count()<<endl;
    return 0;
}
//sb use count:2  pb.lock()将获取一个共享指针，此时引用计数+1，所以未2
//sb use count:1  so_somethind()函数结束后，将减少B的引用计数，此时为1
//kill B 局部变量栈结构，后进先出，先析构B，所以B中指向A的共享指针也释放资源，即此时A的引用计数也更新为1
//kill A
~~~

> weak_ptr除了对所管理对象的基本访问功能（通过get()函数）外，还有两个常用的功能函数：expired()用于检测所管理的对象是否已经释放；lock()用于获取所管理的对象的强引用指针。不能直接通过weak_ptr来访问资源。那么如何通过weak_ptr来间接访问资源呢？答案是：在需要访问资源的时候weak_ptr为你生成一个shared_ptr，shared_ptr能够保证在shared_ptr没有被释放之前，其所管理的资源是不会被释放的。创建shared_ptr的方法就是lock()方法。



#### **9、char (* p) [] 、char * p[]、char (* p)()的区别**

* char p0[] = {'a','b','c','d','e','f'};     此时的”abcdef“在栈中 局部变量

  char p1[] = "abcdef";    等价于 char p1[] = {'a','b','c','d','e','f','\0'};     此时的”abcdef“在栈中

>  char * p2 = "abcdef";  p2=”abcdef“首地址，  且此时的”abckef“在静态数据区,常量字符串，该写法当前已经淘汰，最好不要这样写
>
> 可以写成
>
> const char * p2 = "abcdef"；

* ##### char *p[]

  可以将p与[]结合在一起，也就是p[]是一个数组，p中存放的是数据中首个元素的地址，数组里存放的是char*类型的数据。

  ![img](https://img-blog.csdn.net/20180418141939402)

* ##### char (*p)[]

  可以将 (* p)看成一个整体，（* p)存放的是char[]数组中首个元素的地址，p存放的是(*p)的地址，即数组的地址

![img](https://img-blog.csdn.net/20180418141959862)

* char (* p)()

  p指向一个函数，该函数没有参数，返回值是char类型

  尚未初始化的函数指针

#### **10、向一个文科生解释一下指针和引用的差别**

​	在c++底层中，引用是通过指针实现的，所以，在实现层面上来说，引用就是指针，但是在c++语法上来说，c++编译器并不为引用类型分配内存，所以引用不能为空，必须被初始化，一旦初始化不能更改引用对象。所有对引用的操作都是对原始对象的操作。

​	引用相当于是原始对象的别名，不需要为引用分配新的空间，且必须初始化，就好像你要给一个人起别名的话，这个别名的拥有者一定得存在

​	指针相当于原始对象的亲戚，可以通过指针找到原始对象，并影响原始对象，且这个指针可以为空，好像两个人在没有确认关系之前，可能不是亲戚。



#### **11、再解释一下对象和类**

​	类就好像女娲造的人一样，造出来的都是人，但是每次造人的时候，放的材料不一样，捏出来的人也不一样，都是独立的个体，通过参数对类的实例化得到一个对象的过程中，参数就是捏人的材料，实例化过程就是造人的过程，造出的小人儿就是对象，人这个概念就是class类



#### **12、C、C++什么区别**

* c语言面向过程，编译速度快，容易学习，显示描述程序细节，较少更新标准

* c++面向对象，c++几乎是c语言的超集，只有少量功能不支持。

  c++中增加了classes，templates、exception，new delete的动态内存管理、智能指针、新标识符、标准库也更加复杂，功能更加丰富等

  c++提供了RAII机制实现资源管理，且在语言层面上提供了OOP编程，提供了继承、多态、重载等模式

  

  **c语言的struct与c++的struct的区别**

  * c语言中的struct只能定义数据成员，不能定义成员函数，相当于是一个复杂数据类型，不能用于面向对象编程，且在使用过程汇总必须为 strcut Test t来使用，struct不能省略

  * C++中的struct和class很相似，拥有成员函数，可以实现继承、多态，在声明过程中可以省略struct

    c++中的struct和class两者之间的区别是：

    1. class中默认是private的，struct默认是public的
    2. class可以用于表示模板类型，struct不可以

  

  **c语言实现c++的封装**

  ​	class  数据成员 ==  struct 的数据成员

  ​	class  成员函数 ==  在struct中添加成员函数指针

  ```C++
  typedef struct Astruct
  {
      int _a;   //成员变量
      void(*pf1)();  //成员函数指针
      int (*pf2)();
  }*Astr;
  ```

  **C语言实现c++的继承**

  ```C++
  利用组合实现
  typedef struct A
  {
      int _a;
  }A;
  typedef struct B
  {
      A a;
      int _b;
  }B;
  1、继承是属于的关系，而组合是包含的关系 
  2、继承是复用原有类，可以通过派生类访问基类，而组合仅仅是组合在一起，只能通过已有类的对象访问自己的成员变量与函数
  ```

  **C语言实现c++的多态**

  ```C++
  在c++中，多态是通过父类的指针或引用去调用一个在父类中存在的virtual 类型函数<虚函数>，实现动态绑定，我们知道，要想使用父类的指针或引用调用子类的函数，在父类中，必须将其声明为虚函数、并且与子类中的函数参数列表，返回值，函数名相同 
  C语言实现多态思路： 
  在C语言中，c++中的多态是通过函数覆盖实现的：
      struct A a;
      struct B b;
      a.print = printpa;  //A 中的函数指针指向函数
      b.Pa.print = printpb;//B通过A的对象的函数指针指向的函数
  ```

#### **13、C语言volatile，说个应用场景**

​	volatile是易变的，不稳定的意思，该关键字是一种类型修饰符，用它修饰的变量表示可以被某些编译器未知的因素修改，比如操作系统，硬件或者其他线程等。

​	遇到这个关键字声明的变量，编译器对访问该变量的代码不在进行优化，从而可以提供对特殊地址的稳定访问。

​	volatile 关键字告诉编译器该变量是随时可能发生变化的，每次使用它的时候必须从内存中取出他的值，因而编译器生成的汇编代码会从原内存地址中读取数据使用。

​	如果一个寄存器或者变量表示一个端口或者多个线程的共享数据，就容易出错，所以volatile可以保证对特殊地址的稳定访问。



#### 14、new、delete和malloc、free

​	c++中同时包含new、delete和malloc、free，C语言中只有malloc、free

​	new、delete是运算符，malloc()、free()是库函数

* new和malloc的区别如下

  1. new 能自动分配空间大小，而malloc需要计算字节数
  2. malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free，所以malloc/free不能调用构造函数与析构函数，即无法完成动态对象的内存空间的动态分配
  3. new operator 由两步构成，分别是 operator new 和 construct，且operator new可以重载，可以自定义内存分配策略，甚至不做内存分配，甚至分配到非内存设备上
  4. new是类型安全的，malloc不是

  ~~~ C++
  int* p = new float[2]; // 编译时指出错误
  int* p = malloc(2*sizeof(float)); // 编译时无法指出错误
  ~~~

  5. 返回值不同，malloc分配失败时，返回的是空指针。operator  new**抛出std::bad_alloc异常**。

* delete与free同理
* 由于内部数据类型的“对象”没有构造与析构的过程，对它们而言malloc/free和new/delete是等价的。

**既然new/delete的功能完全覆盖了malloc/free，为什么C++还保留malloc/free呢？**

​	方便c++程序调用c函数

**delete是如何知道要释放的内存的大小的**

​	在申请内存时，指针所指向区块的大小信息，一般记录在该指针的前面（具体实现由编译器决定），所以delete可以根据这个记录的数据进行指定数量的内存释放



#### 15、C++中的内存分布

* **虚拟存储器**

  - 源程序编译后链接到一个以0地址为始地址的线性或多维虚拟地址空间。而且每个进程都拥有这样一个空间，每个指令和数据都在这个虚拟地址空间拥有确定的地址，把这个地址称为虚拟地址（Virtual Address）。将进程中的目标代码、数据等虚拟地址组成的虚拟空间称为虚拟存储器（Virtual Memory）。

  - 典型的虚拟存储器中有类似的布局：

    Text Segment (.text)
    Initialized Data Segment (.data)
    Uninitialized Data Segment (.bss)
    The Stack
    The Heap

    如下图所示：

* 一个程序将操作系统分配给其运行的内存块分为 4 个区域。

![img](http://images.cnblogs.com/cnblogs_com/skynet/201103/201103071829128268.png)

​	当进程被创建时，内核为其提供一块物理内存，将虚拟内存映射到物理内存，这些都是由操作系统来做的。

* **内存分配的方式**

1. 从静态存储区域分配
    内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量， static 变量。

   静态对象的函数不是线程安全的、不可重入的，正是因为它具有“记忆”功能。

2. 在栈上创建
    在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中 ，效率很高，但是分配的内存容量有限。

3.  从堆上分配
    亦称动态内存分配 。程序在运行的时候用 malloc 或 new 申请任意多少的内存，程序员自己负责在何时用 free 或 delete 释放内存。动态内存的生存期由程序员决定 ，使用非常灵活，但如果在堆上分配了空间，就有责任回收它，否则运行的程序会出现内存泄漏，频繁地分配和释放不同大小的堆空间将会产生堆内碎块。

* **可执行文件组成及内存分布**

  通过上面的小节，我们知道将源程序转换为可执行程序的步骤，典型的可执行文件分为两部分：

  * 代码段（Code），由机器指令组成，该部分是不可改的，编译之后就不再改变，放置在文本段（.text）。（guess:所以无论是普通函数还是静态函数都放在.text区中）

    文本段通常是共享的，多个实例之间共享文本段，且不可修改文本段

  * 数据段（Data），它由以下几部分组：

    * 常量（constant），通常放置在只读read-only的文本段（.text）
    * 静态数据（static data），初始化的放置在数据段（.data）；未初始化的放置在（.bss，Block Started by Symbol，BSS段的变量只有名称和大小却没有值）
    * 动态数据（dynamic data），这些数据存储在堆（heap）或栈（stack）

* **一个例子**
  * 变量（函数外）：如果未初始化，则存放在BSS段；否则存放在data段
  * 变量（函数内）：如果没有指定static修饰符，则存放在栈中；否则同上
  * 常量：存放在文本段.text
  * 代码：存放在文本段
  * 函数参数：存放在栈或寄存器中

~~~ C++
int a = 0; // 全局初始化区 
char *p1; // 全局未初始化区  作用域为整个程序，生命期是整个程序运行期间，在内存的bbs段
int static bS;//作用域为整个程序，生命期是整个程序运行期间，在内存的bbs段
int main() {
    int b; // 栈 c是一个未初始化的局部变量，作用域为函数func体内，即仅在函数体内可见，生命期也是函数体内
    char s[] = /"abc/"; // 栈 e是一个未初始化的局部变量，作用域为函数main体内，即仅在函数体内可见，生命期是main函数内
    char *p2; // 栈
    char *p3 = /"123456/"; //123456//0 在常量区， p3 在栈上。
    static int c =0;// 全局（静态）初始化区
    static int d;//d是一个未初始化的静态局部变量，作用域为函数func体内，即仅在函数体内可见，生命期是整个程序运行期间，在内存的bbs段
    p1 = new char[10];
    p2 = new char[20];
    // 分配得来得和字节的区域就在堆区。
    strcpy(p1, /"123456/"); //123456//0 放在常量区，编译器可能会将它与 p3 所指向的 /"123456/" 优化成一个地方。
}

综上：数据声明的位置决定了数据的作用域，数据类型决定了数据在内存中的位置和生命周期
~~~

reference:https://www.jianshu.com/p/fb75db17bfdf

* **总结：数据存储类别**

  数据在内存中的位置取决于它的存储类别。一个对象是内存的一个位置，解析这个对象依赖于两个属性：存储类别、数据类型。

  * 存储类别决定对象在内存中的生命周期。
  * 数据类型决定对象值的意义，在内存中占多大空间。

C/C++中由（auto、 extern、 register、 static）存储类别和对象声明的上下文决定它的存储类别。

* 自动对象（automatic objects）
  	auto和register将声明的对象指定为自动存储类别。他们的作用域是局部的，诸如一个函数内，一个代码块{***}内等。操作了作用域，对象会被销毁。

  * 在一个代码块中声明一个对象，如果没有执行auto，那么默认是自动存储类别。

  * 声明为register的对象是自动存储类别，存储在计算机的快速寄存器中。不可以对register对象做取值操作“&”，而且不能是静态的。

reference：https://blog.csdn.net/sxhlovehmm/article/details/47680137 

##### Linux虚拟地址空间布局

​	包含内核空间+用户空间的布局介绍

​	注意此处是虚拟地址空间布局，与实际的物理地址空间布局不同

​	一般程序员需要关注的是虚拟地址即可，物理地址的分配与释放由操作系统来完成

​	 在多任务操作系统中，每个进程都运行在属于自己的内存沙盘中。这个沙盘就是虚拟地址空间(Virtual Address Space)，在32位模式下它是一个4GB的内存地址块。在Linux系统中, 内核进程和用户进程所占的虚拟内存比例是1:3，这并不意味着内核使用那么多物理内存，仅表示它可支配这部分地址空间，根据需要将其映射到物理内存。

reference：http://www.cnblogs.com/clover-toeic/p/3754433.html

![img](https://images0.cnblogs.com/i/569008/201405/270929306664122.jpg)



#### 16、C++类内存分布

reference：http://blog.jobbole.com/108457/

* c结构

~~~ C++
struct  A {  
   char  c;  
   int  i;  
};
//从上图可见，A在内存中占有8个字节，按照声明成员的顺序，前4个字节包含一个字符（实际占用1个字节，3个字节空着，补对齐），后4个字节包含一个整数。A的指针就指向字符开始字节处。
~~~

![img](http://jbcdn2.b0.upaiyun.com/2016/12/a1feb6ce8393d267ab98b0bb8bda5d17.jpg)

* 有c++特征的c结构

  **除非为了实现虚函数和虚继承引入的隐藏成员变量外，C++类实例的大小完全取决于一个类及其基类的成员变量！成员函数基本上不影响类实例的大小。只有成员变量才占用类实例的空间**。

~~~ C++
struct  B {  
public :  
   int  bm1;  
protected :  
   int  bm2;  
private :  
   int  bm3;  
   static   int  bsm;  
   void  bf();  
   static   void  bsf();  
   typedef   void * bpv;  
   struct  N { };  
};
//静态成员，该数据存放在程序的数据段 中，不在类实例中
~~~

![img](http://jbcdn2.b0.upaiyun.com/2016/12/965a320202b85b3da8a205a1ca80a85e.jpg)



* 单继承

~~~ C++
struct  C {  
   int  c1;  
   void  cf();  
};

struct  D : C {  
   int  d1;  
   void  df();  
};
//每个派生类的实例都包含了一份完整的基类实例数据。在D中，并不是说基类C的数据一定要放在D的数据之前，只不过这样放的话，能够保证D中的C对象地址，恰好是D对象地址的第一个字节。这种安排之下，有了派生类D的指针，要获得基类C的指针，就不必要计算偏移量 了
~~~

![img](http://jbcdn2.b0.upaiyun.com/2016/12/28c4b6a521c3800fd693ea98229f627d.jpg)

![img](http://jbcdn2.b0.upaiyun.com/2016/12/32d993b9645bb4145f3b1eb5f4c01c37.jpg)

* 多重继承

~~~ C++
struct  E {  
   int  e1;  
   void  ef();  
};

struct  F : C, E {  
   int  f1;  
   void  ff();  
};
//单继承相同的是，F实例拷贝了每个基类的所有数据。 与单继承不同的是，在多重继承下，内嵌的两个基类的对象指针不可能全都与派生类对象指针相同
~~~

![img](http://jbcdn2.b0.upaiyun.com/2016/12/103c5cccdba4bea4ab94d336679d4891.jpg)

![img](http://jbcdn2.b0.upaiyun.com/2016/12/dfae96160ad5bdc619f0d1ecf8a77789.jpg)

* 虚继承

  ​	如果经理类和工人类都继承自雇员类，很自然地，它们每个类都会从雇员类获得一份数据拷贝。**如** **果不作特殊处理，一线经理类的实例将含有两个 雇员类实例，它们分别来自两个雇员基类 。** 如果雇员类成员变量不多，问题不严重；如果成员变量众多，则那份多余的拷贝将造成实例生成时的严重开销。更糟的是，这两份不同的雇员实例可能分别被修改，造成数据的不一致。因此，我们需要让经理类和工人类进行特殊的声明(虚继承)，说明它们愿意共享一份雇员基类实例数据。

~~~ C++
struct  G :  virtual  C {  
   int  g1;  
   void  gf();  
};

struct  H :  virtual  C {  
   int  h1;  
   void  hf();  
};

struct  I : G, H {  
   int  i1;  
   void  _if();  
};

//当 使用指针访问虚基类成员变量时，由于指针可以是指向派生类实例的基类指针，所以，编译器不能根据声明的指针类型计算偏移，而必须找到另一种间接的方法，从 派生类指针计算虚基类的位置。

//在VC++ 中，对每个继承自虚基类的类实例，将增加一个隐藏的“虚基类表指针”（vbptr） 成员变量，从而达到间接计算虚基类位置的目的。该变量指向一个全类共享的偏移量表，表中项目记录了对于该类 而言，“虚基类表指针”与虚基类之间的偏移量。
~~~

![img](http://jbcdn2.b0.upaiyun.com/2016/12/01a5727fdc16ddbd2664226922078f88.jpg)

> **GdGvbptrG（In G, the displacement of G’s virtual base pointer to G）意 思是：在G中，G对象的指针与G的虚基类表指针之间的偏移量，在此可见为0，因为G对象内存布局第一项就是虚基类表指针； GdGvbptrC（In G, the displacement of G’s virtual base pointer to C）意思是：在G中，C对象的指针与G的虚基类表指针之间的偏移量，在此可见为8**
>
> 

![img](http://jbcdn2.b0.upaiyun.com/2016/12/c2be7ac8bfa0614120dd618951a1eb3f.jpg)

![img](http://jbcdn2.b0.upaiyun.com/2016/12/24225e7ad619b691f1916eaef72cb5ff.jpg)

> 也就是说idGvbptrG所存在的这个表是I继承体系中的全部类都可见
>
> 在I中，G拥有一个隐藏的“虚基类表指针”成员，指向一个虚基类表，该表的第二项是GdGvbptrC
>
> 在I中，H拥有一个隐藏的“虚基类表指针”成员，指向一个虚基类表的某项，第一项表示，H对象与H指针的偏移，第二项表示C对象与H指针的偏移
>
> GdGvbptrC：表示在I实例内存布局中，C对象距离G指针的偏移是20

**总结**

**首先排列非虚继承的基类实例；2 有虚基类时，为每个基类增加一个隐藏的vbptr，除非已经从非虚继承的类那里继承了一个vbptr；3 排列派生类的新数据成员；4 在实例最后，排列每个虚基类的一个实例。**

**该布局安排使得虚基类的位置随着派生类的不同而“浮动不定”，但是，非虚基类因此也就凑在一起，彼此的偏移量固定不变**



**基于上述内存结构的成员访问**

* **没有继承**

~~~ C++
C* pc;  
pc->c1; // *(pc + dCc1);
//pc是指向C的指针
//dCc1是在C中，C指针地址与其c1成员变量之间的偏移量值
~~~

* 单继承

~~~ C++
D* pd;  
pd->c1; // *(pd + dDC + dCc1); // *(pd + dDc1);   
pd->d1; // *(pd + dDd1);
~~~

> a. 当访问基类成员c1时，计算步骤本来应该为“pd+dDC+dCc1”，即为先计算D对象和C对象之间的偏移，再在此基础上加上C对象指针与成员变量c1 之间的偏移量。然而，由于dDC恒定为0，所以直接计算C对象地址与c1之间的偏移就可以了。
> b. 当访问派生类成员d1时，直接计算偏移量

* 多重继承

~~~ C++
F* pf;  
pf->c1; // *(pf + dFC + dCc1); // *(pf + dFc1);   
pf->e1; // *(pf + dFE + dEe1); // *(pf + dFe1);   
pf->f1; // *(pf + dFf1);
~~~

> a. 访问C类成员c1时，F对象与内嵌C对象的相对偏移为0，可以直接计算F和c1的偏移；
> b. 访问E类成员e1时，F对象与内嵌E对象的相对偏移是一个常数，F和e1之间的偏移计算也可以被简化；
> c. 访问F自己的成员f1时，直接计算偏移量。

* 虚继承

~~~ C++
I* pi;  
pi->c1; // *(pi + dIGvbptr + (*(pi+dIGvbptr))[1] + dCc1);   
pi->g1; // *(pi + dIG + dGg1); // *(pi + dIg1);   
pi->h1; // *(pi + dIH + dHh1); // *(pi + dIh1);   
pi->i1; // *(pi + dIi1);   
I i;  
i.c1; // *(&i + IdIC + dCc1); // *(&i + IdIc1);

//dIGvbptr:在I中，I对象指针与G的“虚基类表指针”之间的偏移
//*(pi + dIGvbptr)是虚基类表的开始地址
//*(pi + dIGvbptr)[1]是虚基类表的第二项的内容（在I对象中，G对象的“虚基类表指针”与虚基类之间的偏移）
//dCc1是C对象指针与成员变量c1之 间的偏移
~~~

**虚继承： 当类有虚基类时，访问非虚基类的成员仍然是计算固定偏移量的问题。然而，访问虚基类的成员变量，开销就增大了** ， 因为必须经过如下步骤才能获得成员变量的地址：

1. 获取“虚基类表指针”；

2. 获取虚基类表中某一表项的内容；

3. 把内容中指出的偏移量加到“虚基类表指针”的地址上。

**如果不是通过指针访问，而是直接通过对象实例，则派生类的布局可以在编译期间静态获得，偏移量也可以在编译时计算，因此也就不必要根据虚基类表的表项来间接计算了**



下面总结一下（当基类有虚函数时）：

**1. 每个类都有虚指针和虚表；**

**2. 如果不是虚继承，那么子类将父类的虚指针继承下来，并指向自身的虚表（发生在对象构造时）。有多少个虚函数，虚表里面的项就会有多少。多重继承时，可能存在多个的基类虚表与虚指针；**

**3. 如果是虚继承，那么子类会有两份虚指针，一份指向自己的虚表，另一份指向虚基表，多重继承时虚基表与虚基表指针有且只有一份。**



* 强制转化

~~~ C++
I* pi;  
(G*)pi; // (G*)pi;   
(H*)pi; // (H*)(pi ? pi + dIH : 0);   
(C*)pi; // (C*)(pi ? (pi+dIGvbptr + (*(pi+dIGvbptr))[1]) : 0);
//a. 强制转化pi为G*时，由于G*和I*的地址相同，不需要计算；
//b. 强制转化pi为H*时，只需要考虑一个常量偏移；
//c. 强制转化pi为C*时，所作的计算和访问虚基类成员变量的开销相同，首先得到G的虚基类表指针，再从虚基类表的第二项中取出G到虚基类C的偏移量
~~~

> **一般说来，当从派生类中访问虚基类成员时，应该先强制转化派生类指针为虚基类指针，然后一直使用虚基类指针来访问虚基类成员变量。这样做，可以避免每次都要计算虚基类地址的开销**



**基于上述结构的成员函数访问**

- 没有继承（普通成员函数）

  选择成员函数不应该带来什么额外负担们这是因为编译器内部已将“Member 函数实例”转换为“Nomember 函数实例”

​	转换步骤：

​	1.安插额外参数this指针到 函数参数中，用于数据存取

```C++
Point3d Point3d::magnitude(Point3d *const this);
```

2. 将函数内对数据成员的操作转换为通过this指针来存取
3. 将Member function重新写成一个外部函数，并将函数名经过“mangling”处理，使他在程序中成为一个独一无二的函数

**注：**

​	每进行一次调用操作，就需要进行一次转换处理

​	this对象存储在寄存器中，所以通过this对象对数据成员进行存取（堆中）和直接从栈中对局部变量进行存取的效率是几乎一致的，虚函数待讨论



* 静态成员函数

  static member function主要的特性使没有this指针

  ~~~ C++
  //如果取一个static member function的地址，那么将返回其在内存的地址，类型是函数类型
  &Point3d::object_count();
  会得到一个数值，类型是：
  unsigned int (*)();
  而不是：
  unsigned int (Point3d::*)();
  //由于static member funtion没有this指针，所以其运行效率等价于 nomember function
  ~~~

  

* 虚函数

  note：**只有虚函数才会在虚拟函数表中**

  reference：https://blog.csdn.net/qq_17368865/article/details/79108084

  1）每个有虚函数的类都有自己的虚函数表，每个包含虚函数的类对象都有虚函数表指针。 
  2）对于多重继承，如果多个基类都有虚函数，则继承类中包含多个基类虚函数表，子类的虚函数地址放在声明的第一个基类虚函数表后面。 
  3）计算类对象的内存大小的时候，需要计算有多少个虚函数指针
  

  * 一般继承（无虚函数覆盖）

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_Drawing3.jpg)

  

  在这个继承关系中，子类没有重载任何父类的函数。那么，在派生类的实例中，其虚函数表如下所示：

  对于实例：Derive d; 的虚函数表如下：

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable2.JPG)

  1）虚函数按照其声明顺序放于表中。

  2）父类的虚函数在子类的虚函数前面。

  * **一般继承（有虚函数覆盖）**

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_Drawing4.jpg)

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable3.JPG)

  1）覆盖的f()函数被放到了虚表中原来父类虚函数的位置。

  2）没有被覆盖的函数依旧。

  这样，我们就可以看到对于下面这样的程序，

  Base *b = new Derive();

  b->f();

  由b所指的内存中的虚函数表的f()的位置已经被Derive::f()函数地址所取代，于是在实际调用发生时，是Derive::f()被调用了。这就实现了多态。

  * **多重继承（无虚函数覆盖）**

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_Drawing1.jpg)

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable4.JPG)

  1） 每个父类都有自己的虚表。

  2） 子类的成员函数被放到了第一个父类的表中。（所谓的第一个父类是按照声明顺序来判断的）

  ​	这个的意思指的是，现将父类的虚拟函数表拷贝到自己的虚拟函数表中，然后进行修改，多重继承中，会在自己的类中设计多个表与父类的表一一对应

  ​	也就是说，每个class会设计自己的虚拟表，但是虚拟表中某虚拟函数的地址可能与基类是一致的

  ​	这样做就是为了解决不同的父类类型的指针指向同一个子类实例，而能够调用到实际的函数。**（强制转换的时候使用dynamic_cast）**

  ![img](http://jbcdn2.b0.upaiyun.com/2016/12/d6112680f99c5332a430940082f91593.jpg)

  Q：public P

  * **多重继承（有虚函数覆盖）**

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_Drawing2.jpg)

  ![è¿éåå¾çæè¿°](https://p-blog.csdn.net/images/p_blog_csdn_net/haoel/15190/o_vtable5.jpg)

  三个父类虚函数表中的f()的位置被替换成了子类的函数指针，所以多重继承中，派生类含有多个父类的vptr

  **虚函数表总结**
  Base虚表：Base类如果有虚函数的话，就按照虚函数出现的先后次序来填写续表

  Derived虚表：对于继承Base类的对象，首先按照Base类的虚表格式复制，如果有重写（覆盖）基类的虚函数，则在对应的位置修改，不改变次序。如果派生类中新增虚函数，则将这虚函数填写到第一个父类虚函数后面即可。

  

* 虚继承

reference: https://blog.csdn.net/xy913741894/article/details/52981011

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20161029200507284)

B是虚基类

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20161030171333408)

为了便于分析，我们可以把这个图拆解下来，**也就是说从B到B1,B2是两个单一的虚拟继承，而从B1,B2到则是多继承**，这样一来，问题就变得简单多了。对于B到B1,B2两个单一的虚拟继承，根据前面讲的很容易得到B1，B2的对象模型：

![è¿éåå¾çæè¿°](https://img-blog.csdn.net/20161031114524546)

![1556538775518](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1556538775518.png)

类D的虚表指针：类D的虚表指针=虚基类的虚表指针，且包含尚未被覆盖的虚基类虚函数+全部子类都覆盖了的虚基类的中的某函数，如f()

B1实际上是最左边的父类，所以D中的新添的虚函数追加在B1的后面

且B1的偏移指针，是为了方便访问虚基类B中的成员而设计的，跟上述的vbptr一致



**虚函数相关的总结与补充**

1. 普通成员函数存放在text段，每个class实例的大小与普通成员函数无关
2. 如果有虚函数，虚函数也放在text段，但是每个class实例中需要多放一个vptr（指向虚函数表的指针），这样就会对class实例的大小造成影响（多了一个指针的位置）。

> 这里P:pf()接受了一个隐藏的this指针参数， 对于每个成员函数调用，编译器都会自动加上这个参数。同时，注意成员变量访问也许比看起来要代价高昂一些，因为成员变量访问通过this指针进行，在有的 继承层次下，this指针需要调整，所以访问的开销可能会比较大。然而，从另一方面来说，编译器通常会把this指针缓存到寄存器中，所以，成员变量访问 的代价不会比访问局部变量的效率更差。
>
> 译者注：访问局部变量，需要到SP寄存器中得到栈指针，再加上局部变量与栈顶的偏移。在没有虚基类的情况下，如果编译器把this指针缓存到了寄存器中，访问成员变量的过程将与访问局部变量的开销相似。

3. 继承时发生的覆盖是静态 （根据成员函数的静态类型在编译时决定）还是动态 （通过对象指针在运行时动态决定），依赖于成员函数是否被声明为**“虚函数”。**

   ​	对于非虚的成员函数来说，调用哪个成员函数是在编译时，根据“->”操作符左边指针表达式的类型静态决定的。特别地，即使ppq指向Q的实例，ppq->pf()仍然调用的是P::pf()，因为ppq被声明为“P*”。（注意，“->”操作符左边的指针类型决定隐藏的this参数的类型。）

   ​	对于**虚函数** 调用来说，调用哪个成员函数在**运行时** 决定。不管“->”操作符左边的指针表达式的类型如何，调用的虚函数都是**由指针实际指向的实例类型所决定** 。比如，尽管ppq的类型是P*，当ppq指向Q的实例时，调用的仍然是Q::pvf()。

4. 每个类对象的vptr放在类对象内存的顶端，方便虚拟函数的快速访问。且每次调用虚拟函数c()时，虽然不知道ptr所指的对象的真正类型，但是可以存取到该对象的虚函数表，虽然不知道哪个c()函数实例会被调用，但是知道每一个c()函数地址都放在slot4中，（虚函数存放的slot相对位置不变），再根据运行时判断出的对象类型，找到相应的class的函数实例，将this对象传入即可



* 虚析构函数

~~~ C++
struct  V {  
   virtual  ~V();  
};
struct  W : V {  
   operator delete ();  
};
//当且仅当类里包含至少一个虚函数的时候才去声明虚析构函数
假如A是B的父类，
A* p = new B();
如果析构函数不是虚拟的，那么，你后面就必须这样才能安全的删除这个指针：
delete (B*)p;
但如果构造函数是虚拟的，就可以在运行时动态绑定到B类的析构函数，直接：
delete p;
就可以了。这就是虚析构函数的作用。
~~~

​	一个类如果有虚析构函数的话，将会象有其他虚函数一样，拥有一个虚函数表指针，虚函数表中包含一项，其内容为指向对该类适用的虚析构函数的地址。这些机制和普通虚函数相同。 虚析构函数的特别之处在于：当类实例被销毁时，虚析构函数被隐含地调用。



#### 17、C++中内存泄漏问题

程序中包含静态内存、栈、堆三种存储空间

静态内存：局部static对象，类static数据成员，全局变量（定义在任何函数之外）

栈：定义在函数内的非static变量

静态存储空间和栈内存中的对象由编译器自动创建和销毁

堆：需要进行动态内存分配管理

**内存泄漏：**是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放（如已经不再持有引用这块内存的对象（通常是指针），这些分配出去的内存将无法收回），造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。

​	内存泄露是在程序存活的状态下，已分配的堆内存由于某种原因无法释放而造成的内存浪费现象，如果程序正常结束或者因为其他原因而崩溃，无论堆内存是否手动delete，操作系统都会将该进程所拥有的全部内存资源进行释放。



**对于C和C++这种没有垃圾回收机制的语言来讲，我们主要关注两种类型的内存泄漏：**

（1）堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak. 

（2）系统资源泄露（Resource Leak）.主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定



**使用C/C++语言开发的软件在运行时，出现内存泄漏。可以使用以下两种方式，进行检查排除:**

⑴ 使用工具软件BoundsChecker，BoundsChecker是一个运行时错误检测工具，它主要定位程序运行时期发生的各种错误。

⑵ 调试运行DEBUG版程序，运用以下技术：CRT(C run-time libraries)、运行时函数调用堆栈、内存泄漏时提示的内存分配序号(集成开发环境OUTPUT窗口)，综合分析内存泄漏的原因，排除内存泄漏。

(3) 内存泄露多半可以通过review代码来发现解决的，也可以使用工具valgrind，来检测程序的内存分配回收情况

原文：https://blog.csdn.net/Clever_Pig/article/details/75050398 

##### Valgrind 的介绍

　　Valgrind 可以用来检测程序是否有非法使用内存的问题，例如访问未初始化的内存、访问数组时越界、忘记释放动态内存等问题。在 Linux 可以使用下面的命令安装 Valgrind：

```
$ wget ftp://sourceware.org/pub/valgrind/valgrind-3.13.0.tar.bz2
$ bzip2 -d valgrind-3.13.0.tar.bz2
$ tar -xf valgrind-3.13.0.tar
$ cd valgrind-3.13.0
$ ./configure && make
$ sudo make install
```

##### 检测内存泄漏

　　Valgrind 可以用来检测程序在哪个位置发生内存泄漏，例如下面的程序：

```
#include <stdlib.h>

int main()
{
    int *array = malloc(sizeof(int));

    return 0;
}
```



　　编译程序时，需要加上`-g`选项：

```
$ gcc -g -o main_c main.c
```



　　使用 Valgrind 检测内存使用情况：

```
$ valgrind --tool=memcheck --leak-check=full  ./main_c
==31416== Memcheck, a memory error detector
==31416== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==31416== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
==31416== Command: ./main_c
==31416==
==31416==
==31416== HEAP SUMMARY:
==31416==     in use at exit: 4 bytes in 1 blocks
==31416==   total heap usage: 1 allocs, 0 frees, 4 bytes allocated
==31416==
==31416== 4 bytes in 1 blocks are definitely lost in loss record 1 of 1
==31416==    at 0x4C2DBF6: malloc (vg_replace_malloc.c:299)
==31416==    by 0x400537: main (main.c:5)
==31416==
==31416== LEAK SUMMARY:
==31416==    definitely lost: 4 bytes in 1 blocks
==31416==    indirectly lost: 0 bytes in 0 blocks
==31416==      possibly lost: 0 bytes in 0 blocks
==31416==    still reachable: 0 bytes in 0 blocks
==31416==         suppressed: 0 bytes in 0 blocks
==31416==
==31416== For counts of detected and suppressed errors, rerun with: -v
==31416== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
```



　　先看看输出信息中的`HEAP SUMMARY`，它表示程序在堆上分配内存的情况，其中的`1 allocs`表示程序分配了 1 次内存，`0 frees`表示程序释放了 0 次内存，`4 bytes allocated`表示分配了 4 个字节的内存。
　　另外，Valgrind 也会报告程序是在哪个位置发生内存泄漏。例如，从下面的信息可以看到，程序发生了一次内存泄漏，位置是`main.c`文件的第 5 行：

```
==31416== 4 bytes in 1 blocks are definitely lost in loss record 1 of 1
==31416==    at 0x4C2DBF6: malloc (vg_replace_malloc.c:299)
==31416==    by 0x400537: main (main.c:5)
```



------

　　Valgrind 也可以用来检测 C++ 程序的内存泄漏，下面是一个正常的 C++ 程序，没有发生内存泄漏：

```
#include <string>

int main()
{
    auto ptr = new std::string("Hello, World!");
    delete ptr;

    return 0;
}
```



　　使用 Valgrind 分析这段程序：

```
$ valgrind --tool=memcheck --leak-check=full --show-leak-kinds=all ./main_cpp
==31438== Memcheck, a memory error detector
==31438== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.
==31438== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info
==31438== Command: ./main_cpp
==31438==
==31438==
==31438== HEAP SUMMARY:
==31438==     in use at exit: 72,704 bytes in 1 blocks
==31438==   total heap usage: 2 allocs, 1 frees, 72,736 bytes allocated
==31438==
==31438== 72,704 bytes in 1 blocks are still reachable in loss record 1 of 1
==31438==    at 0x4C2DBF6: malloc (vg_replace_malloc.c:299)
==31438==    by 0x4EC3EFF: ??? (in /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21)
==31438==    by 0x40104E9: call_init.part.0 (dl-init.c:72)
==31438==    by 0x40105FA: call_init (dl-init.c:30)
==31438==    by 0x40105FA: _dl_init (dl-init.c:120)
==31438==    by 0x4000CF9: ??? (in /lib/x86_64-linux-gnu/ld-2.23.so)
==31438==
==31438== LEAK SUMMARY:
==31438==    definitely lost: 0 bytes in 0 blocks
==31438==    indirectly lost: 0 bytes in 0 blocks
==31438==      possibly lost: 0 bytes in 0 blocks
==31438==    still reachable: 72,704 bytes in 1 blocks
==31438==         suppressed: 0 bytes in 0 blocks
==31438==
==31438== For counts of detected and suppressed errors, rerun with: -v
==31438== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
```



　　使用 Valgrind 分析 C++ 程序时，有一些问题需要留意。例如，这个程序并没有发生内存泄漏，但是从`HEAP SUMMARY`可以看到，程序分配了 2 次内存，但却只释放了 1 次内存，为什么会这样呢？
　　实际上这是由于 C++ 在分配内存时，为了提高效率，使用了它自己的内存池。当程序终止时，内存池的内存才会被操作系统回收，所以 Valgrind 会将这部分内存报告为 reachable 的，需要注意，reachable 的内存不代表内存泄漏，例如，从上面的输出中可以看到，有 72704 个字节是 reachable 的，但没有报告内存泄漏。

reference：http://senlinzhan.github.io/2017/12/31/valgrind/

- **确定的内存泄露**
  - **直接的内存泄露**（**definitely lost**）：直接是没有任何指针指向该内存
  - **间接的内存泄露**（**indirectly lost**）：间接是指向该内存的指针都位于内存泄露处，即由直接内存泄露引起的内存泄露
- **可能的内存泄露**（**possibly lost**）：指仍然存在某个指针能够访问某块内存，但该指针指向的已经不是该内存首地址



#### 18、为什么栈内存中的对象是由操作系统来进行释放管理呢?

​	c++中heap和stack在c++标准中相对应的术语是自由存储（即用new创建对象时所分配的空间）和局部变量

​	局部变量会在作用域结束后由操作系统完成内存释放，因为分配和释放的次序刚好相反，所以可以利用栈的先进后出特性来进行管理，且局部变量一般都是在作用域内维持变量的生命周期，所以可以将这项工作不需要进行人为判断，可以交给操作系统来处理，简单方便高效。栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。

​	栈不会存在碎片问题，因为栈是先进后出的队列，内存块弹出栈之前，在其上面的后进的栈内容已弹出。而频繁申请释放操作会造成堆内存空间的不连续，从而造成大量碎片，使程序效率降低。

​	可见，堆容易造成内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和内核态切换，内存申请的代价更为昂贵。所以栈在程序中应用最广泛，函数调用也利用栈来完成，调用过程中的参数、返回地址、栈基指针和局部变量等都采用栈的方式存放。所以，建议尽量使用栈，仅在分配大量或大块内存空间时使用堆。

​	且自由存储会在作用域结束后继续生存，分配和释放的次序没有限制，需要程序员人为判断释放的合适时机，手动析构、释放内存，实现上可能采用自由链表或者其他动态内存分配机制。

#### 19、C/C++ 指针越界

1. 正确情况

```
void func()
{
    char *pChar = new char;

    //赋值
    pChar[0] = 'a';
}
```

2. 错误情况，但程序不一定会崩溃 

```
void func()
{
    char *pChar = new char;

    // 赋值
    pChar[0] = 'a';
    pChar[1] = 'b';
}
```

3. 错误情况，程序崩溃可能性大于（2）

```
void func()
{
    char *pChar = new char;

    // 赋值
    pChar[0] = 'a';
    pChar[1] = 'b';
    //......
    pChar[1023] = 'c';
    pChar[1024] = 'd';
}
```

​	一. C/C++的内存分为5大区

​     	栈区，堆区，符号常量区，全局/静态区，程序代码区

​	二. 现在计算机是多任务的，也就是说内存中同时存在多个进程，操作系统为每个进程都分配了一定的内存空间

​	三. 每个进程对自己所拥有的内存具有访问（读写）权限

​	四. 除了堆区外的空间都是在编译时就确定的，所以无法改变，只有堆区是可以动态扩充的

​	五. 当指针访问到了不属于当前进程所拥有的内存时，就会发生中断终止程序（程序崩毁）

​	六.  char *pChar = new char; 是在当前进程的堆区中开辟一小块内存（大小为1Byte），pChar拥有对这块（1Byte）内存操作的权利，而实际上，pChar拥有访问当前进程整个堆区的权利

​	七. 理论上每个进程的堆区大小为2-3GByte，但初始大小却可能只有几十KByte左右

​	八. 所以上诉程序实际上是对自己的堆区内存进行赋值操作（毫无意义），又由于程序在内存中的分布通常是不完全连续的，所以程序的指针越界是非常危险的行为（导致程序崩溃的主要原因）

​	九. 同理 

​	    char ch, *pChar = &ch;

​	此时 pChar 拥有对当前进程的栈区进行访问的权利，但越界操作可能会访问到其它进程的空间而导致程序崩溃

​	同时，栈区内存大小 通常小于 堆区的初始内存大小

​	所以在堆区 pChar[1024] 可能不会导致程序崩溃

​	但在栈区中 pChar[512] 可能就会导致程序崩溃

​	十. 当你程序中使用指针的时候，一定要牢记越界检查，因为即便程序在运行时没有崩溃也并不一定代表指针就一定没有越界。

reference：https://my.oschina.net/tigerBin/blog/1538671

#### 20、2g物理内存，new一个3g的数组时发生什么

1. 是32位机还是64位机

   对于程序员来说，编程时只需要考虑虚拟内存，实际的物理操作交给操作系统、CPU处理器、TLB来完成

   如果是32位机，程序员可以考虑的空间大小是2的32次方-1，如果new的大小小于这个量就迈出了成功的第一步

   ​	处理器的存储管理部件MMU支持虚实地址转换，多进程空间等功能，是通用处理器中体现“通用”特性的重要单元，也是处理器核操作系统交互的组紧密的不扥，在虚拟存储系统中，由操作系统以页为单位实现从以进程虚拟地址空间到系统物理地址空间的映射，由处理器通过TLB的实现存储访问时从虚拟地址到物理地址的快速转换，在用户程序访问虚存空间时，处理器核操作系统之间存在复杂的交互过程。

   ​	在32位模式下，地址空间为4g，MIPS的存储空间分为5段，最下面的0-2g段被称为用户端，用户态程序只能再这个地方访问，如果用户的程序要分配一个2.1g的数组，操作系统会告诉用户，超过限制完成不了。

   ![1557125892763](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557125892763.png)

   

2. new之后是否立即使用

   ​       new操作包含两个步骤：申请+分配

   ​       当申请一个超过2g的空间时，程序是不会报错的，因为此时只是简单的申请，只有当真正进行使用的时候才会进行分配，考察具体的物理内存中是否有连续的物理内存满足申请空间的大小（连续的空闲链表的空间应该也相当于是连续的物理内存，有待考究）

   ​	当真正在使用这个超过2g的空间时，程序会报运行时错误，memory allocation failure

   ​	new可以抛出的异常时 bad_alloc Exception

3. 如果确实要申请一个大于2g的空间

   那么可以有下述两种方式来进行解决

   a. 将数据分段存储使用

   b. 利用mmp映射机制

   ​	mmp是指将硬盘上的文件的位置与进程的虚拟地址空间中的一块大小相同的区域之间的一一对应，在内存映射的过程中没有实际的数据拷贝，直到数据使用时才会进行数据拷贝

   ​	mmap()会返回一个指针ptr，它指向进程逻辑地址空间中的一个地址，这样以后，进程无需再调用read或write对文件进行读写，而只需要通过ptr就能够操作文件

   ​	ptr指向的是逻辑地址，需要先转换为物理地址，然后在mmu查找，产生缺页中断，缺页中断响应函数在swap中寻找对应的页面，如果找不到，则会通过mmp()建立的映射关系，从硬盘上将文件读取到物理内存中，如果在拷贝数据时，发现物理内存不够用，则会通过虚拟内存机制（swp）将暂时不用的物理页面交换到硬盘上

   ​	由于mmp()只是建立初始化了一个逻辑地址和文件映射的数据结构，不存在内存映射，所以不走页表的套路，且将文件加载进内存将不使用read和write系统调用。

   ​	通过内存映射的方法访问硬盘上的文件，效率要比read和write系统调用高，这是为什么呢？原因是read()是系统调用，其中进行了数据拷贝，它首先将文件内容从硬盘拷贝到内核空间的一个缓冲区，然后再将这些数据拷贝到用户空间，在这个过程中，实际上完成了 两次数据拷贝 ；而mmap()也是系统调用，如前所述，mmap()中没有进行数据拷贝，真正的数据拷贝是在缺页中断处理时进行的，由于mmap()将文件直接映射到用户空间，所以中断处理函数根据这个映射关系，直接将文件从硬盘拷贝到用户空间，只进行了 一次数据拷贝 。因此，内存映射的效率要比read/write效率高。

   reference：https://blog.csdn.net/best_fiends_zxh/article/details/77044481



#### 21、值传递和地址传递

​	**地址传递：**  包括指针传递和引用传递

​	指针指向一块内存，他的内容是所指内存的地址

​	引用是某块内存的别名

​	**引用传递：**

​	形参相当于是实参的“别名”，对形参的操作其实就是对实参的操作，在引用传递过程中，被调函数的形参虽然也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址。被调函数对形参的任何操作都会通过栈中存放的地址访问主调函数中的实参变量。正因为如此，被调函数对形参做的任何操作都影响了主调函数中的实参变量。

​	**地址传递：**

​	指针是一个实体，本质上相当于是值传递，形参（局部变量）中存储地址值的副本，但是可以通过该地址副本和实参地址对应同一块内存，可通过形参对该内存进行操作

​	指针传递和引用传递可以达到相同的效果，但是为什么设计地址传递和引用传递呢？原因如下：

 	1. 引用不能为null，在创建的同时必须初始化
 	2. 引用一旦被初始化之后，将不能改变引用关系
 	3. 指针可以为null，初始化的位置灵活，且可随意修改指针与所指向的对象

​	**值传递：**

​	形参是实参的拷贝，改变形参的值并不会影响外部实参的值。从被调用函数的角度来说，值传递是单向的（实参->形参），参数的值只能传入，不能传出。当函数内部需要修改参数，并且不希望这个改变影响调用者时，采用值传递。

​	**综上**

​	地址传递是在实参的内存上直接进行修改，值传递是将实参的值拷贝到另外的内存地址后才进行修改

#### 22、++i和i++的区别

​	++i将对象+1后，直接将改变了的对象作为左值返回

​	i++返回原始对象的右值，在运算中需要将对象原始值存储下来，以便返回这个未修改的内容

#### 23、C++模板

​	模板是c++泛型编程的基础，一个模板就是一个创建类或者函数的蓝图或者说公式，当使用一个vector这样的泛型类型或者find这样的泛型函数时，我们提供足够的信息，就可以将蓝图转换为特定的类或者函数

​	**函数模板**

~~~ C++
template <typename T>
int compare (const T &v,const T &v2){
}
//实例化函数模板
cout<<compore(1,2)<<endl;
//编译器通常会用函数实参来为我们推断模板实参，即实参1,2类型为int，编译器会推断模板实参为int，并将他绑定到模板实参T上
~~~

​	**类模板**

~~~ C++
template <typename T> class Blob{
    public:
    T& back();
    ...
}
//实例化类模板
Blob<int> b;
~~~

#### 24、C++中的流处理

​	c++的输入输出不是建立在语言上的,而是由I/O流库中定义的一组模板类实现的,且这个类库不是正式语言定义的组成部分,就是说`cin,cout`等并不是语言的关键字.

​	C++语言的数据输入/输出操作是通过I/O流库来实现的。C++中把数据之间的传输操作称为流，流既可以表示数据从内存传送到某个载体或设备中，即输出流，也可以表示数据从某个载体或设备传送到内存缓冲区变量中，即输入流。

​	C++流包含标准I/O流、文件I/O流、字符串I/O流

​	c++把输入输出看作是字节流,输入时,程序从输入流中截取(>>)字符,输出时,程序将字节插入(<<)到输出流.通过这样的方式,流就相当于连接输入端和输出端的一个桥梁,两端只需要关联到相应的流上即可实现连接,这样处理输入输出的方式将独立与流的去向。

​	注，对于串流，提供了两套类，一个基于C类型字符串char *编写（定义于头文件strstream）,一个基于std::string编写（定义于sstream), 后者是C++标准委员会推荐使用的

​	**string流**

1.标准输入读取：cin >> string

​	a.忽略开头所有的空白字符（空格、换行、制表符等）；

​	b.读取字符直至再次遇到空白字符，读取终止；

2.读取整行文本：getline(istream, string)

​	a.不忽略开头的空白字符；

​	b.读取字符直至遇到换行符，如果第一个字符是换行符，则返回空string；

​	c.返回时丢弃换行符，换行符不存储在string中。

​	**sstream**

~~~ C++
//未用sstream
int n=10000;
char s[10];
sprintf(s,”%f”,n);// 看！错误的格式化符

//sstream
string result=”10000”;
int n=0;
stream<<result;
stream>>n;//n等于10000
~~~

​	由于n和s的类型在编译期就确定了，所以编译器拥有足够的信息来判断需要哪些转换。<sstream>库中声明的标准类就利用了这一点，自动选择所必需的转换。而且，转换结果保存在stringstream对象的内部缓冲中。你不必担心缓冲区溢出，因为这些对象会根据需要自动分配存储空间。

​	注意，<sstream>使用string对象来代替字符数组。这样可以避免缓冲区溢出的危险。而且，传入参数和目标对象的类型被自动推导出来，即使使用了不正确的格式化符也没有危险。

reference:https://blog.csdn.net/luguifang2011/article/details/40979231

reference：https://www.jianshu.com/p/821844fe9805

#### 25、define

define是预处理命令，将标识符定义为宏，即指示预处理器将其后出现的所有标识符都替换为字符串

**1.无参宏定义**

~~~ C++
#define  标识符  字符串
#define MAXNUM 99999
~~~

**2.有参宏定义**

~~~ C++
#define  宏名(形参表)  字符串
#define add(x, y) (x + y)
cout << "1 plus 1 is " << add(1, 1.5) << ".\n";
~~~

**3.宏定义中的多行定义**

~~~C++
#define MACRO(arg1, arg2) do { /
/* declarations */ /
stmt1; /
stmt2; /
/* ... */ /
} while(0) /* (no trailing ; ) */
//记得要在每一个换行的时候加上一个”/”
~~~

**4.宏定义中的条件编译**

在大规模的开发过程中，特别是跨平台和系统的软件里，define最重要的功能是条件编译。可以在编译的时候通过#define设置编译环境。

~~~ C++
#ifdef WINDOWS
......
(#else)
......
#endif
#ifdef LINUX
......
(#else)
......
#endif
~~~

**5.如何取消宏**

~~~ C++
/定义宏
#define [MacroName] [MacroValue]
//取消宏
#undef [MacroName]
~~~

**6.防止重复包含头文件** 

~~~ C++
#ifndef __headerfileXXX__
#define __headerfileXXX__
…
文件内容
…
#endif
~~~

reference：https://blog.csdn.net/u012611878/article/details/52534622



析构函数能否为私有

#### 26、**C++11新特性有哪些？**

**1、新增基于范围的for循环** 

​	类似Java中foreach语句，为遍历数组提供了很大方便。

~~~ C++
int nArr[5] = {1,2,3,4,5};
for(int &x : nArr)
{
    x *=2;   //数组中每个元素倍乘
}
~~~

**2、自动类型推断 auto** 

​	自动类型推导，用法很简单不多赘述，比如写一个auto a = 3, 编译器就会自动推导a的类型为int.

​	auto的使用有以下两点必须注意：

- auto声明的变量必须要初始化，否则编译器不能判断变量的类型。
- auto不能被声明为返回值，auto不能作为形参，auto不能被修饰为模板参数

**关于效率**: auto实际上实在编译时对变量进行了类型推导，所以不会对程序的运行效率造成不良影响。另外，auto并不会影响编译速度，因为编译时本来也要右侧推导然后判断与左侧是否匹配。



**3、匿名函数 Lambda** 

​	我们可以向算法传递任何可调用的对象，可调用对象有函数、函数指针、lamba表达式和重载了函数调用运算符的类。

​	一个lambda表达式表示一个可调用的代码单元，我们可以将其理解为一个未命名的内联函数。

​	[capture list] (paramter list) ->return type {function body}

 	1. 返回类型必须使用尾置类型,如果省略返回类型时，将会根据函数体中的代码推断出返回类型
 	2. 调研lambda表达式时给定的实参用来初始化形参，且lambda不能有默认参数
 	3. lambda出现在一个函数中，可以使用其局部变量，且这些局部变量必须包含在捕获列表中

~~~ C++
有名字的lambda表达式
auto f = [] {return 42;}
//忽略返回值和参数列表
//调用方式为
cout<<f()<<endl;

未命名的lambda表达式
stable_sort(words.begin(),words.end(),[](const string &a,const string&b){return a.size()<b.size()})
~~~

**4、后置返回类型（tailng-return-type）**

​	任何函数的定义都可以使用尾置返回类型，但是这种形式对于返回类型比较复杂的函数最有效，比如返回类型是数组的指针或者数组的引用

 	1. 为了表示函数真正的返回类型跟在形参列表之后，我们在本应该出现返回类型的地方放了一个auto
 	2. 尾置返回类型在形参列表后面，并以->开头

~~~ C++
auto func (int i) ->int(*)[10]
//表示返回类型是一个指针，并且该指针指向了含有10个整数的数组
~~~

**5、虚函数的override和final** 

​	派生类定义了一个函数与基类中的虚函数的名字相同，但是参数不同，这仍然是合法的行为，编译器将认为新定义的这个函数与基类中原有的函数石象湖独立的，这是，派生类中的函数并没有覆盖基类的版本，但是实际的编程中，我们可能希望派生类的这个函数覆盖基类的函数

​	要想调试这样的问题非常困难，所以我们可以利用overrid关键字来说明这个函数时派生类的虚函数，这么做的好处是更加明确程序的意图，并使编译器可以帮助我们发现类似的错误（**只有虚函数才能被覆盖**）

​	我们还能把某个函数指定为final，则之后任何想尝试覆盖该函数的操作都将引发错误。

**6、空指针常量 nullptr** 

​	得到空指针最直接的方法是使用nullptr来初始化指针，nullptr是一种特殊的字面值，他可以被转换成任意其他的指针类型，我们也可以通过字面值0来生成空指针。过去的程序中生成空指针时会欧诺个到一个名为NULL的预处理变量，该变量定义在头文件cstdlib中。

**7、long long int类型** 

​	c++基本内置类型包含算数类型和空类型，算术类型包含字符、整型、布尔值和浮点数类型，整型用于表示不同尺寸的整数，int至少和一个short一样大，一个long至少和一个int一样大，一个long long 至少和一个long一样大，long long是c++中新提出的类型。

**8、模板的别名** 

​	typedef Blob<string> StrBlob;

​	我们只能使用string实例化的模板版本的Blob，不能定义typdef引用一个模板，但是可以通过using实现

​	template<typename T> using twin = pair<T,T>;

​	twin<int> win_loss

​	在这段代码中，我们将twin定义为成员类型相同的pair的别名

**9、允许sizeof运算符可以在类型数据成员上使用，无需明确对象**

**10、线程支持** 

​	C++11的标准库中提供了多线程库，使用时需要`#include <thread>`头文件，该头文件主要提供了管理线程的类和函数

**11、智能指针**

**shared_ptr**，基于引用计数的智能指针，会统计当前有多少个对象同时拥有该内部指针；当引用计数降为0时，自动释放

 **weak_ptr**，weak_ptr只引用，不计数，基于引用计数的智能指针在面对循环引用的问题将无能为力，因此C++11还引入weak_ptr与之配套使用，

 **unique_ptr**: 遵循独占语义的智能指针，在任何时间点，资源智能唯一地被一个unique_ptr所占有，当其离开作用域时自动析构。资源所有权的转移只能通过`std::move()`而不能通过赋值



reference：https://blog.csdn.net/fx677588/article/details/70157088

reference:https://www.jianshu.com/p/78c700c8d72d

#### 27、try和catch用的多吗？ 

 	 在申请内存空间时使用过，try一个代码段，然后catch一个std::bad_alloc EXception，如果catch到了就在catch的代码区中进行异常处理和响应。

​	在c++中，可以直接抛出异常之后自己进行捕捉处理，因为catch语句时按照其出现顺序逐一进行匹配的，所以当程序使用具有继承关系的多个异常时必须对catch自居的顺序进行组织和管理，使得派生类的异常处理代码出现在基类的异常处理代码之前。

#### 28、**inline的作用**

​	将函数指定为内联函数，通常就是将他在每个调用点上“内联的”展开，消除了函数调用时的运行时开销。

​	一般来说，内联机制用于优化规模较小，流程直接，频繁调用的函数，很多编译器都不支持内联递归函数。

#### 29、RTTI :smile:

​	RTTI是”Runtime Type Information”的缩写，意思是运行时类型信息，它提供了运行时确定对象类型的方法。

**1. typeid函数**

1 对于c++的内置数据类型，typeid可以方便的输出它们的数据类型。

~~~ C++
short s = 2;
cout<<typeid(s).name()<<endl; // short
~~~

2 对于自己创建的类对象，依然可以输出它们的数据类型

~~~ C++
class A
{
public:
     void Print() { cout<<"This is class A."<<endl; }
};
A *pA1 = new A();
A a2;
cout<<typeid(pA1).name()<<endl; // class A *
cout<<typeid(a2).name()<<endl; // class A
~~~

3 RTTI 核心

~~~ C++
#include <iostream>
#include <typeinfo>
using namespace std;

class A
{
public:
     void Print() { cout<<"This is class A."<<endl; }
};

class B : public A
{
public:
     void Print() { cout<<"This is class B."<<endl; }
};

int main()
{
     A *pA = new B();
     cout<<typeid(pA).name()<<endl; // class A *
     cout<<typeid(*pA).name()<<endl; // class A
     return 0;
}
~~~

分析：

1. 我使用了两次typeid，但是两次的参数是不一样的；输出结果也是不一样的；当我指定为pA时，由于pA是一个A类型的指针，所以输出就为class A * ；
2. 当我指定*pA时，它表示的是pA所指向的对象的类型，所以输出的是class A；
3. 所以需要区分typeid(*pA)和typeid(pA)的区别，它们两个不是同一个东西；

但是，这里又有问题了，明明pA实际指向的是B，为什么得到的却是class A？

~~~ C++
#include <iostream>
#include <typeinfo>
using namespace std;

class A
{
public:
     virtual void Print() { cout<<"This is class A."<<endl; }
};

class B : public A
{
public:
     void Print() { cout<<"This is class B."<<endl; }
};

int main()
{
     A *pA = new B();
     cout<<typeid(pA).name()<<endl; // class A *
     cout<<typeid(*pA).name()<<endl; // class B
     return 0;
}
~~~

**划重点：**
 好了，我将Print函数变成了虚函数，输出结果就不一样了，这说明什么？

1. 这就是RTTI在捣鬼了，**当类中不存在虚函数时**，typeid是编译时期的事情，也就是静态类型，就如上面的cout<<typeid(*pA).name()<<endl;输出class A一样；
2.  **当类中存在虚函数时**，typeid是运行时期的事情，也就是动态类型，就如上面的cout<<typeid(*pA).name()<<endl;输出class B一样，关于这一点，我们在实际编程中，经常会出错，一定要谨记。

**(这个真的很重要 一定要多看看 一个类里面有virutal 和没有virtual 对于编译器来说，做的事完全不同的事情，所有一定要看清楚这个类有没有virtual)**

**2. type_info类里面的比较运算符**

使用type_info类中重载的==和!=比较两个对象的类型是否相等
这个会经常用到，通常用于比较两个带有虚函数的类的对象是否相等，例如以下代码：

~~~ C++
#include <iostream>
#include <typeinfo>
using namespace std;

class A
{
public:
     virtual void Print() { cout<<"This is class A."<<endl; }
};

class B : public A
{
public:
     void Print() { cout<<"This is class B."<<endl; }
};

class C : public A
{
public:
     void Print() { cout<<"This is class C."<<endl; }
};
//接受基类指针，且A中含有虚函数，利用动态类型的typeid
void Handle(A *a)
{
     if (typeid(*a) == typeid(A))
     {
          cout<<"I am a A truly."<<endl;
     }
     else if (typeid(*a) == typeid(B))
     {
          cout<<"I am a B truly."<<endl;
     }
     else if (typeid(*a) == typeid(C))
     {
          cout<<"I am a C truly."<<endl;
     }
     else
     {
          cout<<"I am alone."<<endl;
     }
}

int main()
{
     A *pA = new B();
     Handle(pA);//B
     delete pA;
     pA = new C();
     Handle(pA);//C
     return 0;
}
~~~

**3. dynamic_cast机制**

dynamic_cast<type *> (e)

e:可以是目标type的公有派生类，可以是目标type的公有基类或者e的类型就是目标type的类型

**e的类型可以是基类，但是e所指对象必须是派生类，才可以在转换为目标type的过程中安全转换。**

~~~ C++
#include <iostream>
#include <typeinfo>
using namespace std;

class A
{
public:
     virtual void Print() { cout<<"This is class A."<<endl; }
};

class B
{
public:
     virtual void Print() { cout<<"This is class B."<<endl; }
};

class C : public A, public B
{
public:
     void Print() { cout<<"This is class C."<<endl; }
};

int main()
{
     A *pA = new C;
     //C *pC = pA; // Wrong 编译器会提示错误
     C *pC = dynamic_cast<C *>(pA);
     if (pC != NULL)
     {
          pC->Print();
     }
     delete pA;
}
~~~

​	在上面代码中，如果我们直接将pA赋值给pC，这样编译器就会提示错误，而当我们加上了dynamic_cast之后，一切就ok了。那么dynamic_cast在后面干了什么呢？
 	dynamic_cast主要用于在多态的时候，它允许在运行时刻进行类型转换，从而使程序能够在一个类层次结构中安全地转换类型，把基类指针（引用）转换为派生类指针（引用）。

​	当类中存在虚函数时，编译器就会在类的成员变量中添加一个指向虚函数表的vptr指针，每一个class所关联的type_info object也经由virtual table被指出来，通常这个type_info object放在表格的第一个slot。当我们进行dynamic_cast时，编译器会帮我们进行语法检查。如果指针的静态类型和目标类型相同，那么就什么事情都不做；否则，首先对指针进行调整，使得它指向vftable，并将其和调整之后的指针、调整的偏移量、静态类型以及目标类型传递给内部函数。其中最后一个参数指明转换的是指针还是引用。两者唯一的区别是，如果转换失败，前者返回NULL，后者抛出bad_cast异常。对于在typeid函数的使用中所示例的程序，我使用dynamic_cast进行更改，代码如下：

​	**c++深度探索对象模型一书中如是说：**

​	dynamic——cast运算符可以在执行期决定真正的类型，如果downcast是安全的（也就是说，如果base type pointer指向一个derived class object),这个运算符会传回适当转换过的指针，如果downcast是不安全的，这个运算符会传回0或者bad_cast

​	dynamic_cast的成本主要是获得两个类型描述器， A *a = new B(); A *pA = dynamic_cast<B *>(a);

在本次dynamic_cast过程中，如果A中有虚函数，启动动态机制，需要获得a对象的实际类型描述器，pA的静态类型A的类型描述器，然后将这两个类型描述器交给一个runtime library函数，比较之后告诉我们是否吻合，对染这个比static——cast昂贵的多，但却安全的多！

​	静态类型A的类型描述器由编译器产生，a对象所指的师姐对象类型描述器，通过虚函数表获得，虚函数表的第一个slot内涵type_info object的地址，次tyoe_info object与a所指的class type有关。

~~~ C++
#include <iostream>
#include <typeinfo>
using namespace std;

class A
{
public:
     virtual void Print() { cout<<"This is class A."<<endl; }
};

class B : public A
{
public:
     void Print() { cout<<"This is class B."<<endl; }
};

class C : public A
{
public:
     void Print() { cout<<"This is class C."<<endl; }
};

void Handle(A *a)
{
     if (dynamic_cast<B*>(a))
     {
          cout<<"I am a B truly."<<endl;
     }
     else if (dynamic_cast<C*>(a))
     {
          cout<<"I am a C truly."<<endl;
     }
     else
     {
          cout<<"I am alone."<<endl;
     }
}

int main()
{
     A *pA = new B();
     Handle(pA);
     delete pA;
     pA = new C();
     Handle(pA);
     return 0;
}
~~~

这个是使用dynamic_cast进行改写的版本。实际项目中，这种方法会使用的更多点。

**RTTI 实现底层实现的原理：**

简单的讲，是在一个类的虚函数表里面添加了一个新的条目

reference:https://www.jianshu.com/p/3b4a80adffa7

#### 30、类型转换

1. 算术转换：算术转换的规则定义了一套类型转换的层次，其中运算符的运算对象将转换成最宽的类型

2. 隐式转换：

   1. 数组转换为指针：在大多数用到数组的表达式中，数组自动转换成指向数组首元素的指针
   2. 指针的转换：常量0、字面值nullptr都可以转换成任何类型的指针
   3. bool类型的转换：如果指针或者算术类型的值为0，转换为false
   4. 转换成常量：允许将指向非常量类型的指针转换成指向相应类型的常量的指针

3. 显示转换：

   1. static_cast:当需要把一个较大的算术类型赋值给较小的类型时，static_cast非常有用，他会告诉程序的读者和编译器，我们知道并且不在乎潜在的精度的损失
   2. const_cast：用于改变表达式的常量属性，只改变运算对象的底层const属性

   ~~~ C++
   const char * p;
   char * pp = const_cast<char*> (p);//正确，但是通过p写值是未定义的问题
   ~~~

   上述代码是将常量对象转换为非常量对象，一旦我们去除了变量的常量属性，编译器就不能阻止我们再对他进行写操作了，但是如果对象本身是一个常量，即使通过const_cast获得了写权限，执行写操作也会产生未定义的结果

   3. dynamic_cast：运行时类型识别，将基类指针或引用转换为派生类指针或引用

#### 31、在main（）函数之前执行一段代码

其实程序运行到main函数之前做了很多工作：

> 操作系统装载程序之后，首先运行的代码并不是main的第一行，而是某些特别的代码，这些代码准备好main函数执行说需要的环境，并且负责调用main函数，这时候你才可以再main函数里放心大胆的写各种代码：申请内存、使用系统调用、触发异常、访问IO。在main函数返回之后，他会记录main函数的返回值，调用atexit注册的函数，然后结束进程。
>  ——《程序员的自我修养--链接、装载与库》

如何做到Main函数之前或main之后执行代呢，其实上面引用已经提到部分，使用全局变量和atexit函数。

~~~ C++
#include <stdlib.h>

inline int startup_1(){
    printf("startup_1执行\n");
    return 0;
}

inline void exit_1(){
    printf("exit_1执行\n");
}

inline int exit_route_1(void (*func)(void)){
    return atexit(func);
}

int static no_use_variable_startup_1 = startup_1();
int static no_use_variable_exit_1 = exit_route_1(exit_1);

int main(int argc, const char * argv[]) {
    printf("main执行\n");
    return 0;
}

startup_1执行
main执行
exit_1执行
~~~

在代码里我们定义了静态全局变量no_use_variable_startup_1和no_use_variable_exit_1，它们分别通过startup_1()和exit_route_1()完成全局初始化，全局变量的初始化工作是在main函数之前完成的，所以startup_1()和exit_route_1()就达到了main之前调用的目的。

no_use_variable_startup_1和no_use_variable_exit_1变量的作用就是提供调用函数的接口。

在main之前我们通过exit_route_1调用atexit将exit_1注册给进程，等main执行完后会调用exit_1函数。

reference：https://www.jianshu.com/p/37f18b7d0cca

- gcc中使用attribute关键字，声明constructor和destructor函数

  ```C
  __attribute() void before_main(){}
  ```

#### 32、c++的线程使用

​	一个线程在创建的时候，线程对象与线程是没有被分离的，或者称为可连接的。

​	一个没有被分离的线程，在退出时，系统会保留它的虚拟内存，包括他们的堆栈和其他系统资源，这种线程被称为“**僵尸线程**”。大量的僵尸线程，会大量占用系统的内存资源，导致运行异常。

​	避免僵尸线程实际上就是要考虑如何正确的回收线程资源。

1. 线程A退出后，线程B调用pthread_join来主动释放线程A的资源。pthread_join可能发生阻塞。

> 未分离的线程执行完后如果不join的话，线程的资源会一直得不到释放而导致内存泄漏！

2. 在线程task中，pthread_detach(pthread_self());

reference：https://blog.csdn.net/bobbypollo/article/details/79891451

#### 33、c++里面的同步和互斥怎么实现的 

mutex:互斥锁 

​	多个线程访问同一资源时，为了保证数据的一致性，最简单的方式就是使用 mutex（互斥锁）。

condition variable : 条件变量

​	条件变量（Condition Variable）的一般用法是：线程 A 等待某个条件并挂起，直到线程 B 设置了这个条件，并通知条件变量，然后线程 A 被唤醒。经典的「生产者-消费者」问题就可以用条件变量来解决。

​	这里等待的线程可以是多个，通知线程可以选择一次通知一个（`notify_one`）或一次通知所有（`notify_all`）。

**有多种mutex，我们只考虑lock_guard 和 unique__lock锁，unique__lock锁和lock_guard原理相同**

**lock_guard**

```C++
#include <iostream>
#include <mutex>
#include <thread>
#include <vector>

std::mutex g_mutex;
int g_count = 0;

void Counter() {
  // lock_guard 在构造函数里加锁，在析构函数里解锁。
  std::lock_guard<std::mutex> lock(g_mutex);

  int i = ++g_count;
  std::cout << "count: " << i << std::endl;
}

int main() {
  const std::size_t SIZE = 4;

  std::vector<std::thread> v;
  v.reserve(SIZE);

  for (std::size_t i = 0; i < SIZE; ++i) {
    v.emplace_back(&Counter);
  }

  for (std::thread& t : v) {
    t.join();
  }

  return 0;
}
Mutex 3
```

**unique_lock**

`unique_lock` 与 `lock_guard` 原理相同，但是提供了更多功能（比如可以结合条件变量使用）。
注意：`mutex::scoped_lock` 其实就是 `unique_lock<mutex>` 的 `typedef`。

reference：https://segmentfault.com/a/1190000006703543

https://segmentfault.com/a/1190000006679917

https://segmentfault.com/a/1190000006614695

**实例**

首先是头文件：

```C++
#include <iostream>
#include <string>
#include <thread>
#include <mutex>
#include <condition_variable>
```

然后是两个线程共享的全局变量：

```C++
std::mutex mutex;
std::condition_variable cv;
std::string data;
bool ready = false;  // 条件
bool processed = false;  // 条件
```

工作线程：

```C++
void Worker() {
  std::unique_lock<std::mutex> lock(mutex);

  // 等待主线程发送数据。
  //等待前先加锁。等待时，如果条件不满足，wait 会原子性地解锁并把线程挂起。
  //条件变量被通知后，挂起的线程就被唤醒，但是唤醒也有可能是假唤醒，或者是因为超时等异常情况，所以被唤醒的线程仍要检查条件是否满足，所以 wait 是放在条件循环里面。cv.wait(lock, [] { return ready; }); 相当于：while (!ready) { cv.wait(lock); }。
  cv.wait(lock, [] { return ready; });

  // 等待后，继续拥有锁。
  std::cout << "工作线程正在处理数据..." << std::endl;
  // 睡眠一秒以模拟数据处理。
  std::this_thread::sleep_for(std::chrono::seconds(1));
  data += " 已处理";

  // 把数据发回主线程。
  processed = true;
  std::cout << "工作线程通知数据已经处理完毕。" << std::endl;

  // 通知前，手动解锁以防正在等待的线程被唤醒后又立即被阻塞。
  lock.unlock();

  cv.notify_one();
}
```

主线程：

```C++
int main() {
  std::thread worker(Worker);

  // 把数据发送给工作线程。
  {
    std::lock_guard<std::mutex> lock(mutex);
    std::cout << "主线程正在准备数据..." << std::endl;
    // 睡眠一秒以模拟数据准备。
    std::this_thread::sleep_for(std::chrono::seconds(1));
    data = "样本数据";
    ready = true;
    std::cout << "主线程通知数据已经准备完毕。" << std::endl;
  }
  cv.notify_one();

  // 等待工作线程处理数据。
  {
    std::unique_lock<std::mutex> lock(mutex);
    cv.wait(lock, [] { return processed; });
  }
  std::cout << "回到主线程，数据 = " << data << std::endl;

  worker.join();

  return 0;
}
```

输出：

```C++
主线程正在准备数据...
主线程通知数据已经准备完毕。
工作线程正在处理数据...
工作线程通知数据已经处理完毕。
回到主线程，数据 = 样本数据 已处理
```

**总结：**

- 与条件变量搭配使用的「锁」，必须是 `unique_lock`，不能用 `lock_guard`。这个前面文章中已有说明。

- 等待前先加锁。等待时，如果条件不满足，`wait` 会原子性地解锁并把线程挂起。

- 条件变量被通知后，挂起的线程就被唤醒，但是唤醒也有可能是假唤醒，或者是因为超时等异常情况，所以被唤醒的线程仍要检查条件是否满足，所以 `wait` 是放在条件循环里面。`cv.wait(lock, [] { return ready; });` 相当于：`while (!ready) { cv.wait(lock); }`。
- **条件变量用于同步，mutex用于系统资源保护（唯一访问）**

 reference：https://segmentfault.com/a/1190000006614695#articleHeader1

https://segmentfault.com/a/1190000006679917

https://segmentfault.com/a/1190000006679917

## C++对象模型

#### 1、拷贝构造函数的参数（const A&）,const可以省略吗

​	拷贝构造函数和赋值运算符用于创建对象的副本，在C++中，下面三种对象需要调用拷贝构造函数！

1. 对象以值传递的方式传入函数参数
2. 对象以值传递的方式从函数返回
3. 对象需要通过另外一个对象进行初始化

**const可以省略吗？**

​	虽然我们可以定义一个接受非const引用的拷贝构造函数，但此参数几乎总是一个const的引用

**为什么函数返回值是类实例时，没有调用拷贝构造函数？**

​	**对于原生类型，如int，short，double，指针等，作为返回值时，大多数编译器都是寄存器传参，**准确一点，就是寄存器eax来传递返回值。这是导师告诉我的，我没验证过，你有兴趣的话，可以去读编译出来的汇编码。

​	但是，如果返回值是一个结构体，或者是一个类本身（以下都称为**结构体**），这种传递返回值的方式就不行了，因为寄存器位数有限（比如现在的64位电脑， 一个寄存器也就能传递一个64位的数据），而结构体可以很大。就需要其它的方式来传递参数。通过看汇编码，GCC是这么干的。**凡是需要返回一个结构体的函数，调用这个函数的地方，会额外传给这个函数一个地址。之后该函数就将返回值直接构造到这个地址那里。**这样的好处在于，返回值直接就构造在了合适的地方，不需要进行额外的拷贝构造。算是一个非常巧妙的实现方式，避免了不必要的拷贝构造。给GCC点个赞！！

​	*********题主这个问题要稍微复杂一点*******

​	题主的getStudent()函数的返回值实现机制已经在上文介绍过了。但是，如果题主用这个返回值直接去构造一个新的变量，GCC就会做另外一个优化。

​	他发现，你既然是用这个返回值去构造新的变量，那我直接就把这个新变量的地址传给函数，让函数的返回值直接构造在这个变量这里就好了。

​	虽然编译器可以略过拷贝/移动构造函数，但是拷贝/移动构造函数必须是存在且可访问的（非private）

**&可以省略吗**

​	不可以省略，拷贝构造函数被用来初始化 非引用类类型参数，这一特性解释了为什么拷贝构造函数自己的参数必须是引用类型，，如果参数不是引用类型，则拷贝构造函数永远不会调用成功，为了调用拷贝构造函数，我们必须拷贝他的实参，但是为了拷贝实参，又需要调用拷贝构造函数，如此无限循环。

#### 2、拷贝赋值运算符

​	运算符函数表示为 operator 后面接运算符，赋值运算符就是一个名为operator = 的函数

​	拷贝赋值运算符实际上是对赋值运算符进行重载

​	某些运算符函数包括赋值运算符，必须定义为成员函数，如果一个运算符是成员函数，其左侧运算对象就绑定到隐式的this参数，对于一个二元运算符，例如赋值运算符，其右侧对象作为显示参数进行传递

~~~ C++
Class Foo{
    public:
    Foo& operator=（ Foo&）{
   		。。。
        return *this;//返回的是引用
    }
}；
~~~

​	值得注意的是，标准库通常要求保存在容器中的类型要具有赋值运算符，且其返回值是左侧运算对象的引用

**A a;A  b = a; A c,c = a;分别调用什么函数**

​	默认构造函数，赋值运算符，默认构造函数，赋值运算符

#### 3、**A *p = new A 和 A a;有啥区别**

​	第一个：在堆上分配一个A大小的空间，并指针p指向该内存空间，且p在栈中

~~~ C++
当遇到new关键字时，编译器将进行如下转换：
int *p = new int(5);
事实上将会转换为两个步骤来完成
1.通过new运算符函数实例，配置所需的内存
	int *p = __new(sizeof(int));
2.将配置得来的数据设立初值
	*p = 5;

如果是类对象时，将由编译器自动安插调用构造函数的代码

A *a= new A;
会被编译器转换为：
A *a；
if(a = __new(sizeof(XA
    a = A::A(a);//此处相当于是编译器安插代码完成A的构造器的调用
~~~

​	第二个：A a，a对象在栈上，调用默认构造函数完成栈上a的初始化

~~~ C++
X bar（）{
    X xx;
    //处理xx
    return xx;
}
会被编译器转换为：
void bar(X & __result){
	X xx;
	//编译器所产生的default constructor调用操作
	xx.X::X();
	//处理xx
	//编译器产生的copy constructor调用操作
	__result.X::XX(xx);
	return;
}
声明类对象X xx的过程中，并没有出现new关键字，所以并不会在堆中为xx对象分配空间，而是在栈中由编译器根据sizeof(X)的大小，自动在栈中分配空间，那么栈内对象的初始化操作，主要是根据编译器将出现X xx声明的地方自动转换为xx.X::X(),完成构造函数的调用
note：编译器在转换的过程中，存在一个判断过程
	1.该class有没有自定义的构造函数
	2.如果没有，是否满足生成默认构造函数的四个条件
	3.如果满足其中之一，将生成默认构造函数，并在转换过程中生成调用默认构造函数的代码
	4.如果不满足条件，将不为该class生成默认构造函数，并不会调用默认构造函数

note：编译器只在认为需要生成默认构造函数的时候生成
	1. 如果一个类没有任何构造函数，且包含类对象数据成员，且该对象数据成员包含默认构造函数，则编译器需要为该类生成一个默认构造函数
	2. 如果一个没有任何构造器的类继承自一个含有默认构造器的基类，则编译器会为其生成一个有用的默认构造函数
	3. class声明或继承了一个虚函数，class继承体系中包含虚基类，编译器存在两个扩张动作，1、构造虚拟函数表，2、给每个对象合成一个额外的vptr
	4、带有虚基类的类
	除了上述4个条件下，编译器生成的默认构造函数都是无用的，什么都不做
~~~

#### 4、vptr是怎么进行赋值的

​	当一个类中含有虚函数或者继承了虚函数时，编译器首先会生成一个存放虚函数的表

​	每一个类对象生成的过程中，需要指定vptr的初值，使其指向虚函数表

​	对于用户自定义的构造器，编译器会自动安插一些代码完成vptr的初始化，如果class没有构造器，编译器会生成一个默认构造器，正确完成vptr的初始化

#### 5、虚基类的偏移是怎么进行赋值的

​	虚基类在派生类中的数据成员的位置根据派生类数据成员的变化而变化，需要指定一个指针或引用（偏移）来完成虚基类数据成员的调用，这个指针或引用的赋值类似于vptr。

​	如果程序员为class实现了构造器，那么编译器将会自动安插一些代码，完成赋值，否则会生成默认构造器，完成正确初始化。

#### 6、手写定义一个空类

​	我认为空类指的是只包含静态变量，常量，普通成员函数的类

~~~ C++
class Empty{}；
这就是一个空类
~~~

​	即使客户要求0bytes，operator new也会返回一个合法指针

~~~ C++
void * operator new(std::size_t size) throw(std::bad_alloc){
    using namespace std;
    if(size==0){
        size==1;//此处表明了为什么空类会有一个字节，且这个字节可以表示空类的各个实例地址不同了
    }
    while(true){
        尝试分配size bytes；
        if(分配成功)
            return(一个指针，指向分配得来的内存);
        //分配失败，找出目前的的new_handling函数
        new_handler_globalHandler = set_new_handler(0);
        set_new_handler(gllobalHandler);
        if(globalHandler)(*globalHandler);
        else throw std::bad_alloc();
        //此时 operator new实际上不止一次尝试分配内存，并在每次失败后调用new_handling函数，假设new_handling函数也许能够做某些侗族瓯江某些内存释放出来，只有当指向nre_handlilng函数的指针是null，operator new才会抛出异常
    }
}
~~~

​	**空类的应用**

​	在stl各类迭代器的使用中，会设计各个空类，在函数调用中，空类作为标志，标识此次函数调用中使用的是哪类迭代器。

~~~ C++
struct input_iterator_tag{};
struct output_iterator_tag{};
struct forward_iterator_tag: pblic input_iterator_tag{};
...
    这些calsses只用作标记用，所以不需要任何成员
template<class InputIterator,class Distancee
inline void __advance(InputIterator &i,Distance n,input_iterator_tag){}

template<class InputIterator,class Distancee
inline void __advance(ForwardIterator &i,Distance n,forward_iterator_tag){}

...
    
注意上述语法，每一个__advance()的最后一个参数都只声明型别，并为指定参数名称，因为他纯粹只是用来激活重载机制，函数之中根本不使用该参数
行进至此，还需要一个对外开放的上层控制接口，调用上述各个重载的__advance(),这一上层接口只需两个参数，当他准备将工作转给上述的__advance（）时，才自行加上第三个参数：迭代器类型，因此，这个上层函数必须有能力从他所获得的迭代器中推导出其类型，这份工作自然是交给traits机制。
~~~

 #### 7、纯虚函数

​	虚函数，在类成员方法的声明（不是定义）语句前加“virtual”, 如 virtual void func()

​	纯虚函数，在虚函数后加“=0”，如 virtual void func()=0，纯虚函数相当于是java中的接口定义

​	对于虚函数，子类可以（也可以不）重新定义基类的虚函数，该行为称之为复写Override。

​	对于纯虚函数，子类必须提供纯虚函数的个性化实现。实现了纯虚函数的子类，该纯虚函数在子类中就变成了虚函数。

​	因为纯虚函数在类的内部无须定义，但是我们也可以为纯虚函数提供定义，不过函数体必须定义在类的外部，也就是说我们不能在函数内部为一个=0的函数提供函数体

​	含有纯虚函数的类成为抽象基类，他不能生成对象，只能创建他的派生类实例，如果派生类中没有重新定义纯虚函数，而只是继承基类的纯虚函数，则这个派生类仍然还是一个抽象类。如果派生类中给出了基类纯虚函数的实现，则该派生类就不再是抽象类了，它是一个可以建立对象的具体的类。

**虚函数 vs 纯虚函数，如何选用？**

1. 当基类中的某个成员方法，在大多数情形下都应该由子类提供个性化实现，但基类也可以提供缺省备选方案的时候，该方法应该设计为虚函数。
2. 当基类中的某个成员方法，必须由子类提供个性化实现的时候，应该设计为纯虚函数。

reference：https://zhuanlan.zhihu.com/p/37331092

#### 8、构造函数和析构函数可以是虚函数吗？

​	答案是：构造函数不能是虚函数，析构函数可以是虚函数且推荐最好设置为虚函数。

​	首先，我们已经知道虚函数的实现则是通过对象内存中的vptr来实现的。而构造函数是用来实例化一个对象的，通俗来讲就是为对象内存中的值做初始化操作。那么在构造函数完成之前，也即还没有进行初始化，此时vptr是没有值的，也就无法通过vptr找到作为构造函数和虚函数所在的代码区，所以构造函数只能以普通函数的形式存放在类所指定的代码区中。

​	而对于析构函数，当我们delete(a)的时候，如果析构函数不是虚函数，那么调用的将会是基类base的析构函数。而当继承的时候，通常派生类会在基类的基础上定义自己的成员，此时我们当然希望可以调用派生类的析构函数对新定义的成员也进行析构。

reference：https://zhuanlan.zhihu.com/p/37331092

#### 9、重载，重写，隐藏

C++的多态性包含：编译时多态性，运行时多态性。

1. 编译时多态性（静态多态）**重载**：通过重载函数实现：先期联编 early binding
2. 运行时多态性（动态多态）**重写**：通过虚函数实现 ：滞后联编 late binding

**重载：**允许有多个同名的函数，而这些函数的参数列表不同，允许参数个数不同，参数类型不同，或者两者都不同。编译器会根据这些函数的不同参数列表，将同名的函数的名称做修饰，从而生成一些不同名称的预处理函数，来实现同名函数调用时的重载问题。

**重写：**C++运行时多态性是通过虚函数来实现的，虚函数允许子类重新定义父类中的虚函数，该做法称为覆盖(Override)，或者称为重写。可以声明基类类型的指针，利用该指针指向任意一个子类对象，调用相应的虚函数，可以根据指向的子类的不同而实现不同的方法。（相当于是一个接口，多种方法）

**隐藏：**隐藏是指在某些情况下派生类的函数屏蔽了与其同名的基类函数。隐藏规则如下：

1. 如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual 关键字，基类的函数将被隐藏（注意别与重载混淆，重载是在同一个类中发生）。
2. 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual 关键字。此时，基类的函数被隐藏（注意别与覆盖混淆，覆盖有virtual关键字）。

**Note:**

1. 参数相同、有virtual关键字：多态重写；
2. 参数相同、无virtual关键字：隐藏；与重写区分。
3. 参数不同、有virtual关键字：隐藏；与重载区分。
4. 参数不同、无virtual关键字：隐藏；与重载区分。

#### 10、封装、继承、多态

**封装：** 封装可以隐藏实现细节，把过程和数据包围起来，使得代码模块化，如类的设计，将相关的数据和成员函数抽象为一个类实际上就是封装，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。

**继承：** 继承指基类派生子类，子类可以继承基类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。封装和继承的目的都是为了——代码重用。

**多态：** 多态的目的主要是为了接口重用，通过指向子类类型的指针或引用来初始化指向父类类型的指针或引用，不论传递过来的究竟是哪个子类对象，都可以通过父类中的虚函数接口调用到适应各自对象的实现方法

#### 11、成员变量的初始化顺序+静态变量的初始化顺序

1. 类中含有静态变量时，初始化顺序为:1 基类的静态变量2 派生类的静态变量3 基类的成员变量4 派生类的成员变量
2. 成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。因为成员变量的初始化次序与变量在内存中次序有关，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。这点在EffectiveC++中有详细介绍。
3. 如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。  

~~~ C++
class A  
{  
private:  
    int n1;  
    int n2;  
      
public:  
    A():n2(0),n1(n2+2){}  
  
    void Print(){  
        cout << "n1:" << n1 << ", n2: " << n2 <<endl;    
    }  
};  
  
int main()  
{  
  
    A a;  
    a.Print();  
  
    return 1;  
}  
~~~

![img](https://img-my.csdn.net/uploads/201304/11/1365642600_5468.jpg)

~~~ C++
A()  
{  
    n2 = 0;  
    n1 = n2 +2;  
}  

~~~

![img](https://img-my.csdn.net/uploads/201304/11/1365642705_2778.jpg)

**扩展**

​	如果一个对象定义在匿名的名字空间中，是具有永久生命期的静态变量。

~~~ C++
namespace {
    const unsigned int NovelBookStartId = 1;
    const unsigned int NovelBookEndId = 500;
    IdGenerator generator(NovelBookStartId, NovelBookEndId);
}
~~~

~~~ C++
#include <iostream>
#include "NovelBookIdGenerator.h"
#include "IdDefine.h"
using namespace std;

int novelBookId = getNovelBookId();
int main(void) {
    
}
novelBookId则是定义在main.cpp里静态变量，它需要调用函数getNovelBookId()来做初始化。
~~~

​	从trace的结果来看`generate`的调用竟然是在`IdGenerator`的构造之前！也就是说我们在通过函数`getNovelBookId`调用`generator`的`generate`方法时，`generate`对象本身竟然没有被构造！引用一个未初始化的变量，后果很严重啊！！！

​	那么有没有办法指定静态的初始化顺序呢？

​	译单元内，静态变量初始化的顺序就是定义的顺序，跨编译单元的静态变量的初始化顺序未定义！！！具体的初始化顺序取决于编译器的实现。

**编译单元**

​	(当一个c或cpp文件在编译时，预处理器首先递归包含头文件，形成一个含有所有 必要信息的单个源文件，这个源文件就是一个编译单元。这个编译单元会被编译成为一个与cpp 文件名同名的目标文件(.o或是.obj) 。连接程序把不同编译单元中产生的符号联系起来，构成一个可执行程序。)



**类外静态变量的初始化顺序**

静态变量的初始化分为两个过程，一个是静态初始化，一个是动态初始化。

**静态初始化过程**

静态数据有两种：已初始化数据和未初始化数据。在映像文件里,它们分别被放入 data 段和 bss段。只有 data 段的已初始化的数据才会真正被放入映像文件。

静态数据有两种：已初始化数据和未初始化数据。在映像文件里,它们分别被放入 data 段和 bss段。只有 data 段的已初始化的数据才会真正被放入映像文件。

对于有初始值的data中的数据，程序加载器(Program Loader)会根据其大小在内存中分配空间，并根据映像文件里存储的初始值对变量做初始化。
 对于未初始化的bss中的数据，程序加载器(Program Loader)会根据其大小在内存中分配空间，按'ISO IEC14882-1998 8.5 Initializers'里规定，根据类型将变量初始化成默认初值：

~~~ C++
inta=5;//data 段 
int b; // bss 段
~~~

![img](https://upload-images.jianshu.io/upload_images/2031359-8fb3b142431e0bbe.png?imageMogr2/auto-orient/)

**动态初始化过程**

~~~ C++
Foo b = Foo(); // bss 段
~~~

这是因为，对象的初始化依靠其构造函数的执行，所以一个对象的初始值是无法在编译是确定的。静态对象被放在 bss 段，加载时首先被清零。然后，程序在进入 main 函 数之前，静态对象的构造函数会被调用。但跨编译单元的静态变量的初始化顺序是未定义的。

**结果分析**

1. 静态初始化过程中，a被初始化为0，x被初始化为22
2. 触发a的动态初始化过程，调用函数f()，a被初始化成22，x被赋值成23

~~~ C++
#include <iostream>
using namespace std;
int f();

int a = f();
int x = 22;
int f() {
    int result = x;
    x++;
    return result;
}
int main(void) {
    cout << "a is:" << a << endl;
    cout << "x is:" << x << endl;
}
~~~

~~~ C++
a is: 22
x is: 23
//静态初始化过程中，a被初始化为0，x被初始化为22
//触发a的动态初始化过程，调用函数f()，a被初始化成22，x被赋值成23
~~~

**防范措施**

避免跨编译单元的初始化依赖

如果一个静态对象被定义在函数内，直到它所在的函数被第一次调用时才会被初始化。利用这样的特性,我们可以确保一个静态实例被读取时已被 初始化。这就消除了跨编译单元的静态对象的构造顺序不确定问题。

**总结**

​	静态初始化在系统加载后执行第一条语句之前就已经完成。所以，可以认为所有的静态初始化过程是同步完成的。

​	而动态初始化，则在main函数之前完成，对于同一个编译单元内的静态变量，动态初始化顺序等同于定义顺序，而对于跨编译单元的静态变量，初始化顺序未定义。

reference：https://www.jianshu.com/p/dd34cee5242c

#### 12、多继承、多重继承的问题，详解，对比一些开源框架中使用的多重继承来说？

**多继承**

​	在多继承中，任何父类的指针都可以指向子类的对象，在实例化子类时，先根据继承的顺序依次调用父类的构造函数，然后再调用该子类自己的构造函数

​	用delete销毁该基类对象时，如果父类的析构函数是虚析构函数，那么销毁的时候会先调用子类的析构函数再调用所有父类的析构函数，注意，此时，子类的父类的析构函数都会被调用！！！

**多重继承**

* 多重继承与多继承不同，当B类从A类派生，C类从B类派生，此时称为多重继承

* 当实例化子类时，会首先依次调用所有基类的构造函数，最后调用该子类的构造函数；销毁该子类时，则相反，先调用该子类的析构函数，再依次调用所有基类的析构函数。

* 无论继承的层级有多少层，只要它们保持着直接或间接的继承关系，那么子类都可以与其直接父类或间接父类构成 is a的关系，并且能够通过父类的指针对直接子类或间接子类进行相应的操作，子类对象可以给直接父类或间接父类的对象或引用赋值或初始化。
  reference：https://blog.csdn.net/hudfang/article/details/50556277

#### 13、C++如何防止类被继承

* 将基类定义为final

* 继承中，子类的构造函数会调用父类的构造函数，子类的析构函数会调用父类的析构函数，因此我们便想办法禁止子类调用父类的构造函数和析构函数即可，因此提出了如下两种方法

  * 构造函数与析构函数设置为私有
  * 使用虚拟继承

  ![1557493915574](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557493915574.png)

  ​	下面我们来看下我们缩写的MyClass类，由于它虚拟继承于Base类，同时作为Base的友元，此时可以访问Base的私有的构造函数和析构函数。

  ​	因此它可以在堆上建立对象，也可以在栈上建立对象。

  ​	那么它能否被继承呢，我便写了一个TestClass的类去继承它，编译器报错了。

  因为在构造对象的时候，由于MyClass是虚拟继承，派生类会直接访问基类也就是Base类的构造函数和析构函数，而Base类里面的构造函数和析构函数是私有的，所以无法继承。
  reference：https://blog.csdn.net/ArchyLi/article/details/78567876 

  

#### 14、静态函数访问普通成员变量和静态成员变量/普通成员函数访问普通成员变量和静态成员变量

​	静态成员函数只能访问静态变量和静态函数

​	普通变量可以随意访问普通成员变量、成员函数和静态成员变量、成员函数。

​	**静态成员函数也可以通过设计来调用普通成员！！！**

​	类的成员变量只有类对象能够访问，所以可以为静态成员函数添加一个类指针或引用作为参数，从而实现在静态函数中对普通成员的调用。

```C++
class Foo
{
    int m_f;
public:
    static void f()
    {
        m_f=666;   //这是非法的，这个等价于this->m_f=666,而静态方法没有this
    }
    static void f(Foo&a)
    {
        a.m_f=666;   //这样就可以
    }
};

```

* 数据成员：

  静态数据成员是类的一部分，为类的所有实例共享(静态区)；非静态数据成员，类的每个实例都有一份拷贝(动态区)。

  静态数据成员的访问：

  静态数据成员是类的一部分，在产生任何实例之前已经存在，通过类名::静态成员变量名访问。

* 函数成员(都在代码区)：

  静态函数成员与非静态函数成员都为类所有，对象并不存在函数的拷贝。

  静态成员函数和非静态成员函数的根本区别在于非静态函数由对象名.或者对象指针->调用，调用时编译器会向函数传递this指针；

  静态成员函数则由类名::或者对象名.调用，编译器不向函数传递this指针，**不识别对象个体，经常用来操作类的静态数据成员，要访问类的非静态成员可以通过对象来实现。** 
  reference：https://blog.csdn.net/xiong452980729/article/details/71079827 

  

#### 15、全局变量，局部变量，静态全局变量，静态局部变量，静态函数，普通函数

**面向过程的static关键字**

​	变量用static告知编译器，自己仅在变量的作用范围内可见。这一点是它与全局变量的区别。

​	static静态变量声明符。在声明它的程序块，子程序块或函数内部有效，值保持，在整个程序期间分配存储器空间，[编译器](http://baike.baidu.com/view/487018.htm)默认值0。

　　是C++中很常用的修饰符，它被用来控制变量的存储方式和可见性

* 静态全局变量：仅在单个C文件中访问

* 静态局部变量：仅由单个函数访问

​	按存储区域分，全局变量、静态全局变量和静态局部变量都存放在内存的静态存储区域，局部变量存放在内存的栈区。 

​	按作用域分，全局变量在整个工程文件内都有效；静态全局变量只在定义它的文件内有效；静态局部变量只在定义它的函数内有效，并且程序仅分配一次内存，函数返回后，该变量不会消失；局部变量在定义它的函数内有效，但是函数返回后失效。

**普通静态函数：**

​	static函数与普通函数作用域不同，只在定义该变量的源文件内有效。只在当前源文件中使用的函数应该说明为内部函数(static)，内部函数应该在当前源文件中说明和定义。对于可在当前源文件以外使用的函数，应该在一个头文件中说明，要使用这些函数的源文件要包含这个头文件。 
reference：https://blog.csdn.net/mm_hh/article/details/77126878 

**面向过程的static总结：**
	隐藏作用。当我们同时编译多个文件时，所有未加static前缀的全局变量和函数都具有全局可见性。如果加了static，就会对其它源文件隐藏。利用这一特性可以在不同的文件中定义同名函数和同名变量，而不必担心命名冲突。Static可以用作函数和变量的前缀，对于函数来讲，static的作用仅限于隐藏，而对于变量，static还有下面两个作用。
	保持变量内容的持久。存储在静态数据区的变量会在程序刚开始运行时就完成初始化，也是唯一的一次初始化。共有两种变量存储在静态存储区：全局变量和static变量，只不过和全局变量比起来，static可以控制变量的可见范围，说到底static还是用来隐藏的。
	默认初始化为0。其实全局变量也具备这一属性，因为全局变量也存储在静态数据区。在静态数据区，内存中所有的字节默认值都是0x00，某些时候这一特点可以减少程序员的工作量。比如初始化一个稀疏矩阵，我们可以一个一个地把所有元素都置0，然后把不是0的几个元素赋值。如果定义成静态的，就省去了一开始置0的操作。再比如要把一个字符数组当字符串来用，但又觉得每次在字符数组末尾加’\ 0’太麻烦。如果把字符串定义成静态的，就省去了这个麻烦，因为那里本来就是’\0’。

​	总之，首先static的最主要功能是隐藏，其次因为static变量存放在静态存储区，所以它具备持久性和默认值0。

**面向对象的static关键字：**

​	**c++中重新实现了这个关键字**

​	 **static对象如果出现在类中，那么该对象即使从未被使用到，它也会被构造以及析构。而函数中的static对象，如果该函数从未被调用，这个对象也就绝不会诞生，但是在函数每次被调用时检查对象是否需要诞生。**

**什么时候用static**

　　需要一个数据对象为整个类而非某个对象服务,同时又力求不破坏类的封装性,即要求此成员隐藏在类的内部，对外不可见。

**static的优势**

　　可以节省内存，因为它是所有对象所公有的，因此，对多个对象来说，静态数据成员只存储一处，供所有对象共用。静态数据成员的值对每个对象都是一样，但它的值是可以更新的。只要对静态数据成员的值更新一次，保证所有对象存取更新后的相同的值，这样可以提高时间效率

**注意事项**

(1)类的静态成员函数是属于整个类而非类的对象，所以它没有this指针，这就导致了它仅能访问类的静态数据和静态成员函数。

(2)不能将静态成员函数定义为虚函数。(注意：如果在static函数加上virtual关键字就会报出这样子的错误error: Semantic Issue: 'virtual' can only appear on non-static member functions，大家懂了吧！)

(3)由于静态成员声明于类中，操作于其外，所以对其取地址操作，就多少有些特殊，变量地址是指向其数据类型的指针，函数地址类型是一个“nonmember函数指针”。

(4)由于静态成员函数没有this指针，所以就差不多等同于nonmember函数，结果就产生了一个意想不到的好处：成为一个callback函数，使得我们得以将C++和C-based X Window系统结合，同时也成功的应用于线程函数身上。

**类内静态数据成员：**

​	在类内数据成员的声明前加上关键字static，该数据成员就是类内的静态数据成员

~~~ C++
class Myclass
　　{
　　public:
　　Myclass(int a,int b,int c);
　　void GetSum();
　　private:
　　int a,b,c;
　　static int Sum;//声明静态数据成员
　　};
~~~

**可以看出，静态数据成员有以下特点：**

　　对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当作是类的成员。无论这个类的对象被定义了多少个，静态数据成员在程序中也只有一份拷贝，由该类型的所有对象共享访问。也就是说，静态数据成员是该类的所有对象所共有的。对该类的多个对象来说，静态数据成员只分配一次内存，供所有对象共用。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新；

​	静态数据成员存储在全局数据区。静态数据成员定义时要分配空间，所以不能在类声明中定义。在示例中，语句int Myclass::Sum=0;是定义静态数据成员；

**静态数据成员和普通数据成员一样遵从public,protected,private访问规则**；

类的静态数据成员有两种访问形式：

　　<类对象名>.<静态数据成员名> 或 <类类型名>::<静态数据成员名>

**同全局变量相比，使用静态数据成员有两个优势：**

　　静态数据成员没有进入程序的全局名字空间，因此不存在与程序中其它全局名字冲突的可能性；

　　可以实现信息隐藏。静态数据成员可以是private成员，而全局变量不能；

**静态成员函数;**

​	与静态数据成员一样，我们也可以创建一个静态成员函数，它为类的全部服务而不是为某一个类的具体对象服务。静态成员函数与静态数据成员一样，都是类的内部实现，属于类定义的一部分。普通的成员函数一般都隐含了一个this指针，this指针指向类的对象本身，因为普通成员函数总是具体的属于某个类的具体对象的。通常情况下，this 是缺省的。如函数fn()实际上是this->fn()。但是与普通函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this指针。从这个意义上讲，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，它只能调用其余的静态成员函数。

**关于静态成员函数，可以总结为以下几点：**

* 出现在类体外的函数定义不能指定关键字static；

* 静态成员之间可以相互访问，包括静态成员函数访问静态数据成员和访问静态成员函数；

* 非静态成员函数可以任意地访问静态成员函数和静态数据成员；

* 静态成员函数不能访问非静态成员函数和非静态数据成员；

* 由于没有this指针的额外开销，因此静态成员函数与类的全局函数相比速度上会有少许的增长；

  

  调用静态成员函数，可以用成员访问操作符(.)和(->)为一个类的对象或指向类对象的指针调用静态成员函数，也可以直接使用如下格式：

　　<类名>::<静态成员函数名>（<参数表>）调用类的静态成员函数。

reference：https://blog.csdn.net/dqjyong/article/details/7976735 



## 编译、连接与加载

#### 1、C++写的动态链接库能不能直接给C用，为什么

​	c和c++不能直接相互调用，主要是因为c++有重载函数的功能，为了区分重载函数，编译器会在函数名上加上一些修饰用符号，而c不这么做。为了让c与c++的程序能够相互调用对方的库，就有了extern “C”。注意，extern “C” 是c++的规范，所以只能出现在c++的代码里面，加在函数声明前，表示函数是用c的规范。

1. c代码调用c++dll

   1. 编译c++dll的要点

      * 供c调用的c++的函数接口不能包含c++特有的东西。
      * 在编译生成供c代码调用的dll时，头文件的中的函数声明前要加上extern “C” 告诉编译器按照c规范处理函数名。
      * 编译完成后，提供给c使用的头文件里面不能包含extern “C”，可以使用宏开关解决，也可以重新写个头文件。

   2. c代码调用c++dll的要点

      和正常调用c函数一样

2. c++调用c语言的dll

   1. 编译c语言dll的要点
      * c语言dll正常编写，不需要做额外处理
   2. c++调用c语言dll的要点
      * 在包含c的头文件或声明来自c的函数时需要加上extern "C", 建议这么做

>  总结，不管谁调用谁，c代码不需要特殊处理，只要在c++代码的正确位置加上extern ”C" 即可。

#### 2、函数模板的分离编译

**分离编译模式**

​	一个程序（项目）由若干个源文件共同实现，而每个源文件单独编译生成目标文件，最后将所有目标文件连接起来形成单一的可执行文件的过程称为分离编译模式。

​	分离式编译主要强调在一个头文件中进行声明，然后在另一个cpp文件中进行实现

**使用函数模板在链接时出错**

~~~ C++
/***func.h***/
template<class T> void func(const T&);
/***end func.h***/

/***func.cpp***/
#include "func.h"
#include <iostream>
using namespace std;

template<class T> void func(const T& t)
{
	cout<<t<<endl;
}
/***end func.cpp***/

/***main.cpp***/
#include <stdio.h>
#include "func.h"

int main()
{
	func(3);
}
/***end main.cpp***/
~~~

​	在分离编译模式下，func.cpp会生成一个目标文件为func.obj，由于在func.cpp文件中，并没有发生函数模板调用，所以不会将函数模板func<T>实例化为模板函数func<int>，也就是说，在func.obj中无法找到关于模板函数func<int>的实现代码。在源文件main.cpp中，虽然函数模板被调用，但由于没有模板代码，也不能将其实例化。也就是说，在main.obj中也找不到模板函数func<int>的实现代码。这样，在链接的时候就会出现func<int>没有定义的错误。

**解决办法**

* 将函数模板的定义放到头文件
   	一个简单的解决办法就是将函数模板func<T>的定义写到头文件func.h中。这样的话，只要包含了这个头文件，就会把函数模板的代码包含进来，一旦发生函数调用，就可以依据函数模板代码将其实例化。这个办法虽然简单可行，但是有如下不足。
  （1）函数模板的定义写进了头文件，暴露了函数模板的实现细节。

  （2）不符合分离编译模式的规则，因为分离编译模式要求函数原型申明放在头文件，定义放在源文件。

* 仍然采用分离编译模式
          有什么办法可以让函数模板实例化时能够找到相应的模板函数的代码呢？一个可能的解决办法就是使用关键字export。也就是说，在func.cpp里定义函数模板的时候，将函数模板头写成：

~~~ C++
export template<class T> void func(const T& t);
~~~


​	这样做的目的是告诉编译器，这个函数模板可能再其他源文件中被实例化。这是一个对程序员来说负担最轻的解决办法，但是，目前几乎所有的编译器都不支持关键字export，包括VC++和GNU C++。

reference：https://blog.csdn.net/K346K346/article/details/49500635

#### 3、cmake和makefile的区别

1. make 是用来执行Makefile的
2. Makefile是类unix环境下(比如Linux)的类似于批处理的"脚本"文件。其基本语法是: **目标+依赖+命令**，只有在**目标**文件不存在，或**目标**比**依赖**的文件更旧，**命令**才会被执行。由此可见，Makefile和make可适用于任意工作，不限于编程。比如，可以用来管理latex。
3. cmake支持跨平台，cmake的做法是生成指定编译器的工程文件。cmake是跨平台项目管理工具，它用更抽象的语法来组织项目。虽然，仍然是目标，依赖之类的东西，但更为抽象和友好，比如你可用math表示数学库，而不需要再具体指定到底是math.dll还是libmath.so，在windows下它会支持生成visual studio的工程，在linux下它会生成Makefile，甚至它还能生成eclipse工程文件。也就是说，从同一个抽象规则出发，它为各个编译器定制工程文件。
4. cmake是抽象层次更高的项目管理工具，cmake命令执行的CMakeLists.txt文件
5. qmake是Qt专用的项目管理工具，对应的工程文件是*.pro，在Linux下面它也会生成Makefile

reference：https://www.zhihu.com/question/27455963/answer/36722992



**Makefile与Cmake的使用与介绍：**

**Makefile：**

​	Makefile描述了整个工程的编译、连接等规则，makefile定义了一些列规则来指定，哪些文件需要编译以及如何编译、需要创建哪些库文件以及如何创建这些库文件、如何产生我们想要的可执行文件。使用Makefile，整个工程都可以完全自动化编译。而且Makefile 可以有效的减少编译和连接的程序，只编译和连接那些修改的文件。

* Makefile语法

   Makefile包含了五个重要的东西：显示规则、隐晦规则、变量定义、文件指示和注释。
1. 显示规则：显示规则说明了，如何生成一个或多个目标。这是由Makefile指出要生成的文件和文件依赖的文件。
2. 隐晦规则：基于Makefile的自动推导功能
3. 变量的定义：一般是字符串
4. 文件指示：一般是在Makefile中引用另外一个makefile文件；根据某些规则指定Makefile中有效的部分；多行
5. 注释：#指示注释

   Makefile有三个非常重要的变量：$@、$^、$#，它们的含义如下：
          $@    ---目标文件
          $^      ---所有依赖文件
          $<      ---第一个依赖文件
          .PHONY  ---伪目标文件

   Makefile的执行过程如下：

1. 在当前目录下寻找Makefile或makefile。
2. 找到第一个文件中的第一个目标文件，和目标文件依赖的.o文件。
3. 如果.o文件不存在，或是后面.o文件比target文件更新，那么它就会执行后面的语句来生成这个文件。

4. 最后makefile会根据.o文件依赖的.h和.c文件生成.o文件。

 **注意：**

1. clean不要放在target前面。
2. -rm edit  $(objects)  忽略某些文件的问题。
3.  Makefile中的命令，必须以[Tab]键分割。文件之间最好使用空格分割。
4. -I 或 --include-dir 参数，那么make就会在这些目录下去寻找
5. -L 相当于load lib dir， -lfb303  相当于libfb303.so

**g++编译命令:**

1. -g  相当于debug
2. -Wall 相当于忽略warnning
3. -O1~3 相当于优化级别
4.  -lpthread多线程
5. -j8 多线程编译
6.  -D相当于宏定义，-D_YUQIANG，那么#ifdef _YUQIANG就是True的。

**Makefile示例**

~~~ C++
CC = gcc  
RM = rm  
  
CFLAGS += -D _YUQIANG  
TARGETS := myapp  
all:$(TARGETS)  
  
$(TARGETS):main.c  
$(CC) $(CFLAGS) $^ -o $@  
  
clean:  
-$(RM) -f *.o  
-$(RM) -f $(TARGETS)  
~~~

* Cmake

  CMake是一个夸平台的安装（编译）工具，可以简单的语句描述所有平台的安装（编译过程）。它能输出各种各样的makefile或者project文件，能测试编译器所支持的c++特性，类似UNIX下的automake。

**Cmake语法**

1. project name 

​                 PROJECT( project name )

2. 头文件路径
             INCLUDE_DIRECTORIES( include )

3. 设置环境变量的值
             SET( TEST_DIR ${DIR_SRCS})

4. 设置外部库
             SET(LIBRARIES libm.so)

5. 设置可执行文件路径
             ADD_EXECUTABLE( ../bin/bin ${TEST_DIR})

6. 设置链接库
             TARGET_LINK_LIBRARIES(../bin/bin ${LIBRARIES})

7. 设置代码子目录
            ADD_SUBDIRECTORY

**CMake示例**

~~~ C++
#project name  
PROJECT(test_math)  
#head file path  
INCLUDE_DIRECTORIES(  
include  
)  
#source directory  
AUX_SOURCE_DIRECTORY(src DIR_SRCS)  
#set environment variable  
SET(TEST_MATH  
${DIR_SRCS}  
)  
#set extern libraries  
SET(LIBRARIES  
libm.so  
)  
#add executable file  
ADD_EXECUTABLE(../bin/bin ${TEST_MATH})  
#add link library  
TARGET_LINK_LIBRARIES(../bin/bin ${LIBRARIES}  
~~~

reference：https://blog.csdn.net/qq_36983118/article/details/79213543



#### 4、动态链接与静态链接

​	应用程序有两种链接方式，一种是静态链接，一种是动态链接，这两种链接方式各有好处。

​	程序的静态连接还是动态连接是根据编译器的连接参数指定的。

**静态链接**

* 为什么要进行静态链接

  在我们的实际开发中，不可能将所有代码放在一个源文件中，所以会出现多个源文件，而且多个源文件之间不是独立的，而会存在多种依赖关系，如一个源文件可能要调用另一个源文件中定义的函数，但是每个源文件都是独立编译的，即每个*.c文件会形成一个*.o文件，为了满足前面说的依赖关系，则需要将这些源文件产生的目标文件进行链接，从而形成一个可以执行的程序。这个链接的过程就是静态链接

* 静态链接的原理

  所谓静态链接就是在编译链接时直接将需要的执行代码拷贝到调用处，优点就是在程序发布的时候就不需要依赖库，也就是不再需要带着库一块发布，程序可以独立执行，但是体积可能会相对大一些。（所谓库就是一些功能代码经过编译连接后的可执行形式。）

  以下面这个图来简单说明一下从静态链接到可执行文件的过程，根据在源文件中包含的头文件和程序中使用到的库函数，如stdio.h中定义的printf()函数，在libc.a中找到目标文件printf.o(这里暂且不考虑printf()函数的依赖关系)，然后将这个目标文件和我们hello.o这个文件进行链接形成我们的可执行文件。

  ![img](https://img-blog.csdn.net/20180505235327609)

  ​	这里有一个小问题，就是从上面的图中可以看到静态运行库里面的一个目标文件只包含一个函数，如libc.a里面的printf.o只有printf()函数，strlen.o里面只有strlen()函数。

  ​	我们知道，链接器在链接静态链接库的时候是以目标文件为单位的。比如我们引用了静态库中的printf()函数，那么链接器就会把库中包含printf()函数的那个目标文件链接进来，如果很多函数都放在一个目标文件中，很可能很多没用的函数都被一起链接进了输出结果中。由于运行库有成百上千个函数，数量非常庞大，每个函数独立地放在一个目标文件中可以尽量减少空间的浪费，那些没有被用到的目标文件就不要链接到最终的输出文件中。

* 优缺点：

  静态链接的缺点很明显，一是浪费空间，因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，如多个程序中都调用了printf()函数，则这多个程序中都含有printf.o，所以同一个目标文件都在内存存在多个副本；另一方面就是更新比较困难，因为每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快

**动态链接**

​	所谓动态链接就是在编译的时候不直接拷贝可执行代码，而是通过记录一系列符号和参数，在程序运行或加载时将这些信息传递给操作系统，操作系统负责将需要的动态库加载到内存中，然后程序在运行到指定的代码时，去共享执行内存中找到已经加载的动态库可执行代码，最终达到运行时连接的目的。优点是多个程序可以共享同一段代码，而不需要在磁盘上存储多个拷贝，缺点是由于是运行时加载，可能会影响程序的前期执行性能。

​	假设现在有两个程序program1.o和program2.o，这两者共用同一个库lib.o,假设首先运行程序program1，系统首先加载program1.o，当系统发现program1.o中用到了lib.o，即program1.o依赖于lib.o，那么系统接着加载lib.o，如果program1.o和lib.o还依赖于其他目标文件，则依次全部加载到内存中。当program2运行时，同样的加载program2.o，然后发现program2.o依赖于lib.o，但是此时lib.o已经存在于内存中，这个时候就不再进行重新加载，而是将内存中已经存在的lib.o映射到program2的虚拟地址空间中，从而进行链接（这个链接过程和静态链接类似）形成可执行程序。

​	虽然动态链接把链接过程推迟到了程序运行时，但是在形成可执行文件时（注意形成可执行文件和执行程序是两个概念），还是需要用到动态链接库。比如我们在形成可执行程序时，发现引用了一个外部的函数，此时会检查动态链接库，发现这个函数名是一个动态链接符号，此时可执行程序就不对这个符号进行重定位，而把这个过程留到装载时再进行。

**动态链接与静态链接的比较：**

​	动态链接的优点显而易见，就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；另一个优点是，更新也比较方便，更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。但是动态链接也是有缺点的，因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

​	据估算，动态链接和静态链接相比，性能损失大约在5%以下。经过实践证明，这点性能损失用来换区程序在空间上的节省和程序构建和升级时的灵活性是值得的。

**windows:**

​	在windows上大家都是DLL是动态链接库，里面是一系列可执行的代码，开发过windows程序的人可能还知道有另外一种形式的库，就是LIB，大家可能普遍认为LIB就是静态库，至少我之前是这么认为的，但是在实际的开发过程中，纠正了我这个错误的想法。LIB形式的文件可能会有两种形式，这里并不排除第三种形式。1：包括符号表和二进制可执行代码，也就是传统意义上理解的静态库，可以被静态连接。2：只有符号表，也就是只有动态库的符号导出信息，通过这些信息可以在程序运行时定位到动态库中，最终实现动态连接。

**linux:**

​	在linux上大家也都知道SO是动态库，类似于windows下的DLL，实现方式也是大同小异，同时开发过linux下程序的人也都知道另外一种形式的库就是A库，同样道理普遍认为是和SO对立的，也就是静态库，不然没道理存在啊，呵呵。但是事实区却不是如此，A文件的作用和windows下的LIB文件作用几乎一样，也可能会有两种形式，和windows下的lib文件一样，在此就不在赘述。

**动态链接库、静态库、import库区别**

* 动态链接库(Dynamic Linked Library)：
  Windows为应用程序提供了丰富的函数调用，这些函数调用都包含在动态链接库中。其中有3个最重要的DLL，Kernel32.dll，它包含用于管理内存、进程和线程的各个函数；

  User32.dll，它包含用于执行用户界面任务(如窗口的创建和消息的传送)的各个函数；

  GDI32.dll，它包含用于画图和显示文本的各个函数。

* 静态库(Static Library)：

  函数和数据被编译进一个二进制文件(通常扩展名为.LIB)。 由很多目标文件进行链接形成的是静态库，反之静态库也可以简单地看成是一组目标文件的集合，即很多目标文件经过压缩打包后形成的一个文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件(.EXE文件)。

* 导入库(Import Library)：

  在使用动态链接库的时候，往往提供两个文件：一个引入库和一个DLL。引入库包含被DLL导出的函数和变量的符号名，DLL包含实际的函数和数据。在编译链接可执行文件时，只需要链接引入库，DLL中的函数代码和数据并不复制到可执行文件中，在运行的时候，再去加载DLL，访问DLL中导出的函数。

**静态库与导入库的区别：**
       导入库和静态库的区别很大，他们实质是不一样的东西。静态库本身就包含了实际执行代码、符号表等等，而对于导入库而言，其实际的执行代码位于动态库中，导入库只包含了地址符号表等，确保程序找到对应函数的一些基本地址信息。

**静态库与动态库的区别：**

​	简单的说，静态库和应用程序编译在一起，在任何情况下都能运行，而动态库是动态链接，顾名思义就是在应用程序启动的时候才会链接，所以，当用户的系统上没有该动态库时，应用程序就会运行失败。

​	**动态库：**

- 类库的名字一般是 libxxx.so
- 共享：多个应用程序可以使用同一个动态库，启动多个应用程序的时候，只需要将动态库加载到内存一次即可；
- 开发模块好：要求设计者对功能划分的比较好。
- 动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便。

 	**静态库：**

- 类库的名字一般是libxxx.a
- 代码的装载速度快，执行速度也比较快，因为编译时它只会把你需要的那部分链接进去。
- 应用程序相对比较大，如果多个应用程序使用的话，会被装载多次，浪费内存。
- 如果静态函数库改变了，那么你的程序必须重新编译。

**静态链接方法：**

​	#pragma comment(lib, "test.lib") ，静态链接的时候，载入代码就会把程序会用到的动态代码或动态代码的地址确定下来
​	静态库的链接可以使用静态链接，动态链接库也可以使用这种方法链接导入库

**动态链接方法：**

​	LoadLibrary()/GetProcessAddress()和FreeLibrary()，使用这种方式的程序并不在一开始就完成动态链接，而是直到真正调用动态库代码时，载入程序才计算(被调用的那部分)动态代码的逻辑地址，然后等到某个时候，程序又需要调用另外某块动态代码时，载入程序又去计算这部分代码的逻辑地址，所以，这种方式使程序初始化时间较短，但运行期间的性能比不上静态链接的程序。

**示例：**

文件目录树如下:

1. libtest/
2. |-- myjob.c
3. |-- myjob.h
4. |-- test.c

**静态库**

A.做成静态库 libmyjob.a

```
$ gcc -c myjob.c -o myjob.o 
$ ar -c -r -s libmyjob.a myjob.o
//ar可让您集合许多文件，成为单一的备存文件。在备存文件中，所有成员文件皆保有原来的属性与权限。
//c 　建立备存文件
//-r 　将文件插入备存文件中
//s 　若备存文件中包含了对象模式，可利用此参数建立备存文件的符号表
```

B.链接

```
$ gcc test.o libmyjob.a -o test 
```

C.引用库情况（无所要信息）

```
$ ldd test 
linux-gate.so.1 => (0xffffe000) 
libc.so.6 => /lib/libc.so.6 (0xb7e29000) 
/lib/ld-linux.so.2 (0xb7f6e000) 
```

**静态库的创建于使用详细用法：**可参考：https://blog.csdn.net/u010977122/article/details/52958330

**动态库**

A.做成动态库libmyjob.so

```
$ gcc -Wall –fPIC -c myjob.c -o myjob.o   
$ gcc -shared -o libmyjob.so myjob.o   
```

> - -shared:  该选项指定生成动态连接库（让连接器生成T >类型的导出符号表，有时候也生成弱连接 W >类型的导出符号），不用该标志外部程序无法连接。相当于一个可执行文件。
> - -fPIC： 表示编译为位置独立的代码，不用此选项的话编译后的代码是位置相关的所以动>>态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的>。
> - -L.： 表示要连接的库在当前目录中。
>    LD_LIBRARY_PATH： 这个环境变量指示动态连接器可以装载动态库的路径。

B.链接
 链接方法一、拷贝到系统库里再链接，让 gcc 自己查找：

```
$ cp libmyjob.so /usr/lib 
$ gcc -o test test.o -lmyjob 
```

这里我们可以看到了 -lmyjob  选项， -l[lib_name]  指定库名，他会主动搜索。 lib[lib_name].so 这个搜索的路径可以通过  gcc --print-search-dirs 来查找。

链接方法二 ，手动指定库路径

```
$  gcc -o test test.o -lmyjob -B /path/to/lib
```

> -B  选项就添加 /path/to/lib  到 gcc 搜索的路径之中。这样链接没有问题但是方法 II 中手动链接好的程序在 执行 时候仍旧需要指定库路径（ 链接和执行是分开的 ）。需要添加系统变量 LD_LIBRARY_PATH :

```
   1. $ export LD_LIBRARY_PATH=/path/to/lib 
这个时候再来检测一下test 程序的库链接状况 ( 方法 I 情况 )
   1. $ ldd test 
   2. linux-gate.so.1 => (0xffffe000) 
   3. libmyjob.so => /usr/lib/ libmyjob .so (0xb7f58000) 
   4. libc.so.6 => /lib/libc.so.6 (0xb7e28000) 
   5. /lib/ld-linux.so.2 (0xb7f6f000) 
```

​	是不是比静态链接的程序多了一个 libmyjob.so?  这就是静态与动态的最大区别，静态情况下，它把库直接加载到程序里，而在动态链接的时候，它只是保留接口，将动态库与程序代码独立。这样就可以提高代码的可复用度，和降低程序的耦合度。
 另外，运行时，要保证主程序能找到动态库，所以动态库一般发布到系统目录中，要么就在跟主程序相对很固定的路径里，这样不管主程序在本机何时何地跑，都能找得到动态库。而静态库只作用于链接时，运行主程序时静态库文件没存在意义了。

**动态链接库的详细使用：**

可参考：https://blog.csdn.net/u010977122/article/details/52958330

动态链接主要要两种实现方式：

1、动态链接：修改配置文件，/etc/ld.so.cache，/lib、/usr/lib或/etc/ld.so.conf所指定的任何一个目录

2、动态加载：一套Linux提供的标准API，头文件：dlfcn.h中



reference：https://blog.csdn.net/kang___xi/article/details/80210717

reference：https://www.jianshu.com/p/8743a0edb1ee

#### 5.动态库管理命令 ldconfig

​	ldconfig是一个动态链接库管理命令。为了让动态链接库为系统所共享,需运行动态链接库的管理命令--ldconfig。 ldconfig 命令的用途,主要是在默认搜寻目录(/lib和/usr/lib)以及动态库配置文件/etc/ld.so.conf内所列的目录下,搜索出可共享的动态链接库(格式lib*.so*),进而创建出动态装入程序(ld.so)所需的连接和缓存文件。缓存文件默认为 /etc/ld.so.cache,此文件保存已排好序的动态链接库名字列表，为了让动态链接库为系统所共享，需运行动态链接库的管理命令ldconfig，此执行程序存放在/sbin目录下。ldconfig通常在系统启动时运行,而当用户安装了一个新的动态链接库，修改了ld.so.conf时,就需要手工运行这个命令。

​	linux下的共享库机制采用了类似于高速缓存的机制，将库信息保存在/etc/ld.so.cache里边。程序连接的时候首先从这个文件里边查找，然后再到ld.so.conf的路径里边去详细找

**ldconfig几个需要注意的地方： **

1. 往/lib和/usr/lib里面加东西，是不用修改/etc/ld.so.conf的，但是完了之后要调一下ldconfig，不然这个library会找不到 
2. 想往上面两个目录以外加东西的时候，一定要修改/etc/ld.so.conf，然后再调用ldconfig，不然也会找不到 
    比如安装了一个MySQL到/usr/local/mysql，mysql有一大堆library在/usr/local/mysql/lib下面，这时 就需要在/etc/ld.so.conf下面加一行/usr/local/mysql/lib，保存过后ldconfig一下，新的library才能在 程序运行时被找到。 
3. 如果想在这两个目录以外放lib，但是又不想在/etc/ld.so.conf中加东西（或者是没有权限加东西）。那也可以，就是export一个全局变 量LD_LIBRARY_PATH，然后运行程序的时候就会去这个目录中找library。一般来讲这只是一种临时的解决方案，在没有权限或临时需要的时 候使用。 
4. ldconfig做的这些东西都与运行程序时有关，跟编译时一点关系都没有。编译的时候还是该加-L就得加，不要混淆了。 
5. 总之，就是不管做了什么关于library的变动后，最好都ldconfig一下，不然会出现一些意想不到的结果。不会花太多的时间，但是会省很多的事。

reference：https://blog.csdn.net/u010977122/article/details/52993560



#### 6、简述cmake到可执行文件的过程

源文件经过以下几步生成可执行文件：

1、预处理（preprocessor）：对#include、#define、#ifdef/#endif、#ifndef/#endif等进行处理
2、编译（compiler）：将源码编译为汇编代码
3、汇编（assembler）：将汇编代码汇编为目标代码
4、链接（linker）：将目标代码链接为可执行文件

​	编译分为3步，首先对源文件进行预处理，这个过程主要是处理一些#号定义的命令或语句（如宏、#include、预编译指令#ifdef等），生成*.i文件；然后进行编译，这个过程主要是进行词法分析、语法分析和语义分析等，生成 * .s的汇编文件；最后进行汇编，这个过程比较简单，就是将对应的汇编指令翻译成机器指令，生成可重定位的二进制目标文件（汇编语言和二进制的机器代码是一一对应的）。连接是指将汇编生成的多段机器代码组合成一个可执行程序，连接器的作用就是将这些目标文件组合起来，组合的过程包括了代码段、数据段等部分的合并，以及添加相应的文件头。链接方式主要有两种--静态链接和动态链接。

​	编译器和汇编器创建的目标文件包含：二进制代码（指令）、源码中的数据；链接器将多个目标文件链接成一个；装载器把目标文件加载到内存。

![1557732203510](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557732203510.png)



**从Cmake开始到可执行文件的流程简介：**

* 快速开始

1. 创建项目文件夹：Tutorial
2. 在Tutorial目录下创建目录build

~~~ bash
$ cd build
$ cmake ..
//由于在CMake构建过程中会生成很多中间文件，所以在顶层目录下新建一个build文件夹来存放产生的中间文件。
~~~

可以看到在build目录中生成了一个Makefile文件，接下里可以直接使用make指令生成可执行文件。

3. cmake的功能简介

~~~ cmake
cmake_minimum_required(VERSION 2.6)
project(Tutorial)
# The version number.
set(Tutorial_VERSION_MAJOR 1)
set(Tutorial_VERSION_MINOR 0)

# Configure a header file to pass some of the CMake settings
# to the source code
configure_file(
    "${PROJECT_SOURCE_DIR}/TutorialConfig.h.in"
    "${PROJECT_BINARY_DIR}/TutorialConfig.h"
    )

# Add the binary tree to the search path for include files
# to the source code
include_directories("${PROJECT_BINARY_DIR}")

# Add the executable
add_executable(Tutorial tutorial.cxx)
~~~

​	我们要使用的第一个CMake功能就是为我们的项目添加一个版本号。当然可以直接在源代码中配置，但是在`CMakeLists.txt`中配置更加灵活。为了添加一个版本号，我们需要修改`CMakeLists.txt`文件

​	在CMake中set指令用来定义变量，上面这个文件中定义了两个变量`Tutorial_VERSION_MAJOR`和`Tutorial_VERSION_MINOR`。

​	`PROJECT_SOURCE_DIR`和`PROJECT_BINARY_DIR`是CMake中预先定义的两个变量，前者表示的是顶层CMakeLists.txt所在目录，后者是执行cmake的目录，对我们而言就是build目录

​	configure_file命令根据第一个参数所指的文件在构建目录中生成一个头文件，由于我们需要使用这个头文件，所以要用include_directories命令包含这个目录。

​	我们需要创建一个`TutorialConfig.h.in`文件来构建头文件:

~~~ cmake
// The configured options and settings for Tutorial
#define Tutorial_VERSION_MAJOR @Tutorial_VERSION_MAJOR@
#define Tutorial_VERSION_MINOR @Tutorial_VERSION_MINOR@
~~~

* 连接到库

​        我们将在项目中添加一个包含计算平方根功能的库。最终生成的可执行文件可以使用这个库而不是使用标准数学库中的函数。

​        **我们会在项目中创建一个`MathFunctions`的子目录来存放我们库的源代码，这个子目录中应该有一个这样的`CMakeLists.txt`文件:**

~~~ cmake
add_library(MathFunctions mysqrt.cxx)
~~~

​	这条命令添加了一个叫MathFunctions的库，这个库依赖mysqrt.cxx这个源文件。默认会生成静态库，如果要使用动态库的话需要添加SHARED属性:

~~~ cmake
# Use shared library
add_library(MathFunctions SHARED mysqrt.cxx)

# Use static library
add_library(MathFunctions STATIC mysqrt.cxx)
~~~

​	这里的SHARED和STATIC必须要使用大写。之后就会在构建目录下生成MathFunctions文件夹，其中包含了需要的动态库`libMathFunctions.so`或者静态库`libMathFunctions.a`。

​	**我们需要在`MathFunctions`目录下创建一个`mysqrt.cxx`文件，它需要包含一个`mysqrt`函数去实现求平方根的功能:**

~~~ c++
#include "MathFunctions.h"
#include <math.h>

double mysqrt(double inputValue)
{
    return sqrt(inputValue);
}
~~~

​	**接着还需要创建`MathFunctions.h`这个头文件:**

~~~ C++
#ifndef MATHFUNCTIONS_H
#define MATHFUNCTIONS_H

double mysqrt(double inputValue);

#endif
~~~

​	**我们需要在顶层的CMakeLists.txt文件中使用add_subdirectory来使库得到构建，我们还需包含一下这个目录，以便`MathFunctions.h`能够被搜索到:**

~~~ cmake
include_directories("${PROJECT_BINARY_DIR}")
include_directories("${PROJECT_SOURCE_DIR}/MathFunctions")
add_subdirectory(MathFunctions)

# Add the executable
add_executable(Tutorial tutorial.cxx)
target_link_libraries(Tutorial MathFunctions)
~~~

​	`target_link_libraries`是用来给项目链接库用的，第一个参数必须使用add_executable指令，第二个参数是要连接到的库。

详见reference：https://www.jianshu.com/p/0fc0e1613587

#### 7、一个源程序到可执行文件的过程

reference：https://blog.csdn.net/kang___xi/article/details/79571137

* 基本概念

**1.什么是数据**
        大家平时口中经常说程序是由程序代码、数据和进程控制块组成，但是很多人却不知道什么是数据。这里我们搞清楚两件事情，一是什么是数据，二是数据存放在哪里。

(1)数据

​	数据指的是称序中定义的全局变量和静态变量。还有一种特殊的数据叫做常量。所以上面的的gdata1、gdata2、gdata3、gdata4、gdata5、gdata6、d、e和f均是数据。

(2)数据存放在哪里

​	数据存放的区域有三个地方：.data段、.bss段和.rodata段。那么你肯定想知道数据是如何放在这三个段中的，怎么区分。

​	对于初始化不为0的全局变量和静态变量存放在.data段，即gdata1、gdata4和d存放在.data段；对于未初始化或者初始化值为0的段存放在.bss段中，而且不占目标文件的空间，即gdata2、gdata3、gdata5、gdata6、e和f存放在.bss段。文章下面有一张关于符号表的图，大家可以看到确实是这样的分布。

​	而对于字符串常量则存放在.rodata段中，而且对于字符串而言还有一个特殊的地方，就是它在内存中只存在一份。

**2.什么是指令**

  说完了数据，那什么是指令呢？也就是什么是程序代码。很简单，程序中除了数据，剩下的就都是指令了。这里有一个容易混淆的地方，如下面的代码：

~~~ C++
#include<stdio.h>
int main()
{
    int a = 10;
    int b = 20;
    printf("a+b=%d\n", a + b);
    return 0;
}
~~~

​	大家可能会有一个疑问，就是对于上面的代码，a和b明明是局部变量，难道不是数据吗？嗯，它真的不是数据，它是一条指令，这条指令的功能是在函数的栈帧上开辟四个字节，并向这个地址上写入指定值。

**3. 什么是符号**

​	说完数据和指令，接下来是另一个基础而且重要的概念，那就是符号。我们在编写程序完，进行链接时会碰到这样的错误："错误       LNK1169    找到一个或多个多重定义的符号	"，即符号重定义。那什么是符号，什么东西会产生符号，符号的作用域又是怎样的呢？

​	在程序中，所有数据都会产生符号，而对于代码段只有函数名会产生符号。而且符号的作用域有global和local之分，对于未用static修饰过的全局变量和函数产生的均是global符号，这样的变量和函数可以被其他文件所看见和引用；而使用static修饰过的变量和函数，它们的作用域仅局限于当前文件，不会被其他文件所看见，即其他文件中也无法引用local符号的变量和函数。

​	对于上面的 “找到一个或多个多重定义的符号” 错误原因有可能是多个文件中定义同一个全局变量或函数，即函数名或全局变量名重了。

**4.虚拟地址空间布局**

​	对于32位操作系统，每个操作系统都有2^32字节的虚拟地址空间，即4G的虚拟地址空间。这4G的虚拟地址空间分为两个大部分：每个进程独立的3G的用户空间，和所有进程共享的1G的内核空间。具体分布如下图：

![img](https://img-blog.csdn.net/20180408174128923)

* 编译过程

  整个编译分为四个步骤：首先编写源文件main.c/main.cpp；编写好代码以后进行预编译成main.i文件，预编译过程中去掉注释、进行宏替换、增加行号信息等；然后将main.i文件经过语法分析、代码优化和汇总符号等步骤后，编译形成main.S的汇编文件，里面存放的都是汇编代码；最后一个编译步骤是进行汇编，从main.S变成二进制可冲定位目标文件main.o。

* 链接过程

  链接过程分为两步，第一步是合并所有目标文件的段，并调整段偏移和段长度，合并符号表，分配内存地址；第二步是链接的核心，进行符号的重定位。

(1)合并段

​	所有相同属性的段进行合并，组织在一个页面上，这样更节省空间。如.text段的权限是可读可执行，.rodata段也是可读可执行，所以将两者合并组织在一个页面上；同理合并.data段和.bss段。

(2)合并符号表

​	链接阶段只处理所有obj文件的global符号，local符号不作任何处理。

(3)符号解析

​	符号解析指的是所有引用符号的地方都要找到符号定义的地方。

(4)分配内存地址

​	在编译过程中不分配地址（给的是零地址和偏移），直到符号解析完成以后才分配地址。

(5)符号重定位

​	因为在编译过程中不分配地址，所以在目标文件所以数据出现的地方都给的是零地址，所有函数调用的地方给的是相对于下一条指令的地址的偏移量。在符号重定位时，要把分配的地址回填到数据和函数调用出现的地方，而且对于数据而言填的是绝对地址，而对函数调用而言填的是偏移量。

* 可执行程序

  链接完成后将生成可执行文件，在linux系统中，可执行文件以elf格式存储，包含可执行文件（所有文件）的头部headers，headers包含函数入口地址，存放代码段的属性为可读可执行的load项，存放数据段的可读可写的load项，这两个load项的意义在于他指示了哪些段将会被加载到同一个页面中。

  当双击一个可执行程序时，首先解析其文件头部ELF header获取entry point address程序入口点地址，然后按照两个load项的指示将相应的段通过mmap()函数映射到虚拟页面中（虚拟页面存在于虚拟地址空间中），最后再通过多级页表映射将虚拟页面映射到物理页面中。

  整个过程总结如下：

  1.首先是创建虚拟地址到物理内存的映射（创建内核地址映射结构体），创建页目录和页表；

  2.再就是加载代码段和数据段

  3.把可执行文件的入口地址写到CPU的PC寄存器中

* 地址映射过程

  实验环境是在32位Linux操作系统下的虚拟地址映射过程。先将逻辑地址通过GDTR/LDTR转换为线性地址（也叫虚拟地址），然后再通过多级页表映射（32位地址需要两级页表映射）将线性地址转换为物理地址。

  具体转换过程后续记录。

reference：https://blog.csdn.net/kang___xi/article/details/79571137



## GDB调试

#### 1、C++程序运行过程中crash掉时，怎么去分析错误

- 添加崩溃捕获的代码
- log记录的信息足够详细。当崩溃dmp文件定位不到问题或定位的位置，不能有效地帮助我们确定问题所在的时候。详细的log记录的重要性就突显出来了
- 用vs2013等相关软件进行分析拍拆。利用异常调用栈信息。帮助我们定位问题。如果和log结合起来进行协同分析，可能效果就更好了。

reference：https://blog.csdn.net/n_fly/article/details/80426268

#### 2、程序运行与调试

reference：Hello WinuxGEAR.pdf

gcc       +       g++       +       Makefile      +      gdb      +      ldd      +      ps      +     grep      +      source Insight

+补充的一些命令（jobs、bg、fg、&、ctrl+z）



## STL函数或者数据结构的理解与实现

#### 1、vector的emplace和emplace_back

​	在C++开发过程中，我们经常会用STL的各种容器，比如vector，map，set等，这些容器极大的方便了我们的开发。在使用这些容器的过程中，我们会大量用到的操作就是插入操作，比如vector的push_back，map的insert，set的insert。这些插入操作会涉及到两次构造，首先是对象的初始化构造，接着在插入的时候会复制一次，会触发拷贝构造。但是很多时候我们并不需要两次构造带来效率的浪费，如果可以在插入的时候直接构造，就只需要构造一次就够了。

​	C++11标准已经有这样的语法可以直接使用了，那就是emplace。vector有两个函数可以使用：emplace，emplace_back。emplace类似insert，emplace_back类似push_back。通过示例代码可以更清晰的了解到他们的区别。

reference：https://blog.csdn.net/windpenguin/article/details/75581552

#### 2、reserve()与resize()

~~~ C++
void reserve( size_type new_cap );
~~~

​	增加 vector 的容量到大于或等于 `new_cap` 的值。若 `new_cap` 大于当前的 [capacity()](https://zh.cppreference.com/w/cpp/container/vector/capacity) ，则分配新存储，否则该方法不做任何事。`reserve()` 不更改 vector 的 size 。

  	vector 的reserve增加了vector的capacity，但是它的size没有改变！而resize改变了vector的capacity同时也增加了它的size！
**原因如下：**
      reserve是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对象之前，不能引用容器内的元素。加入新的元素时，要调用push_back()/insert()函数。

​      resize是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了，因此当加入新的元素时，用operator[]操作符，或者用迭代器来引用元素对象。此时再调用push_back()函数，是加在这个新的空间后面的。

​      两个函数的参数形式也有区别的，reserve函数之后一个参数，即需要预留的容器的空间；resize函数可以有两个参数，第一个参数是容器新的大小， 第二个参数是要加入容器中的新元素，如果这个参数被省略，那么就调用元素对象的默认构造函数  

reference:https://www.cnblogs.com/qlee/archive/2011/05/16/2048026.html

#### 3、怎么判断两个struct相等？

重载==运算符，逐一比较成员变量是否相等

那能不能用内存比较memcmp来判断呢？

不能，涉及字节对齐，可能有内存间隙，这里的值是随机的

#### 4、STL结构与扩容

STL 指的是标准模板库（Standard Template Library），包括容器、算法、迭代器三个主要部分（也包括仿函数、适配器等其他部分）

![img](https://upload-images.jianshu.io/upload_images/10118224-ee23dafe96babb08.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/778/format/webp)

reference：https://www.jianshu.com/p/834cc223bb57

![1558506681711](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558506681711.png)

**内存基本处理工具：**

![1558508649856](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508649856.png)

![1558508663396](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508663396.png)

![1558508677309](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508677309.png)

![1558508693894](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508693894.png)

![1558508714674](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508714674.png)

![1558508729092](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508729092.png)

reference：STL源码剖析一书



#### 关联式容器

![1558580821084](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580821084.png)



#### 5、树

*　二叉搜索树

![1558581255394](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558581255394.png)

![1558581341576](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558581341576.png)

![1558581383270](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558581383270.png)

* 平衡二叉树

![1558581601281](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558581601281.png)

​	要求左右子树高度相差最多为1

![1558581997310](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558581997310.png)

![1558582170573](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558582170573.png)

![1558582225300](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558582225300.png)

![1558582957677](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558582957677.png)

![1558582969571](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558582969571.png)



* RB_Tree

![1558583008271](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558583008271.png)

![1558593592404](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558593592404.png)

![1558593635164](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558593635164.png)

**红黑二叉树与平衡二叉树的比较：**

​	AVL树是带有平衡条件的二叉查找树，一般是用平衡因子差值判断是否平衡并通过旋转来实现平衡，左右子树树高不超过1，和红黑树相比，AVL树是严格的平衡二叉树，平衡条件必须满足（所有节点的左右子树高度差不超过1）。不管我们是执行插入还是删除操作，只要不满足上面的条件，就要通过旋转来保持平衡，由此我们可以知道**AVL树适合用于插入与删除次数比较少，但查找多的情况**

​	由于维护这种高度平衡所付出的代价比从中获得的效率收益还大，故而实际的应用不多，更多的地方是用追求局部而不是非常严格整体平衡的红黑树。当然，**如果应用场景中对插入删除不频繁，只是对查找要求较高，那么AVL还是较优于红黑树。**

​	一种二叉查找树，但在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树（由于是弱平衡，可以看到，在相同的节点情况下，AVL树的高度低于红黑树），相对于要求严格的AVL树来说，它的旋转次数少，所以对于搜索，插入，删除操作较多的情况下，我们就用红黑树。

​	红黑树**并不追求“完全平衡**”——它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。红黑树能够以**O(log2 n)** 的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。

![img](https://img-blog.csdn.net/20180710095739968?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4OTk5ODU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



reference：https://blog.csdn.net/u010899985/article/details/80981053 




#### 6、map(RB_Tree)

* **map与multimap**

  **底层结构：**红黑树

  **特性：**

  1. 可以实现**O(lgn)**的查找，插入和删除
  2. map不允许关键字重复，multimap允许关键字重复
  3. 均以key为序进行排列

![1558598345622](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558598345622.png)

![1558599448023](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558599448023.png)

![1558599504645](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558599504645.png)

![1558600092996](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558600092996.png)



**map的基本函数操作：**

**insert():**

![1558599623420](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558599623420.png)

![1558599951752](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558599951752.png)

![1558600026214](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558600026214.png)



**删除map的方式：**

~~~ C++
//删除键为bfff指向的元素
cmap.erase("bfff");
 
//删除迭代器 key所指向的元素
map<string,int>::iterator key = cmap.find("mykey");
  if(key!=cmap.end())
 {
	cmap.erase(key);
 }
 
//删除所有元素
cmap.erase(cmap.begin(),cmap.end());

原文：https://blog.csdn.net/zvall/article/details/52267007 
~~~

在使用map的erase函数时，需要注意使用的哪个版本，有些版本的stl-map没有返回值，比如SGI版，但vc版的有
所以在利用迭代器进行删除时

~~~ C++
std::map<int, int>:: iterator it = mmap.begin();
    for( ; it!=mmap.end(); it++)
    {
        if(it->first == 2)
        {
            it = mmap.erase(it); // erase的返回值是指向被删除元素的后继元素的迭代器
        }
    }

或者
std::map<int, int>:: iterator it = mmap.begin();
    for( ; it!=mmap.end(); it++)
    {
        if(it->first == 2)
        {
            mmap.erase(it++); // erase之后，令当前迭代器指向其后继。
        }
    }

原文：https://blog.csdn.net/gcq1992/article/details/77011901 
~~~



#### 7、map(HashTable)

* **unordered_map与unordered_multimap 或者成为hash_map  hash_mulitimap**

  **底层结构：**hash_table

  **特性：**

  1. 两者中的key为无序排列
  2. 其查找时间复杂度理论上达到了**O(n)**，之所以说理论上是因为在理想无碰撞的情况下，而真实情况未必如此。

![1558617318635](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558617318635.png)

![1558617409668](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558617409668.png)



#### 8、set(RB_Tree)

* ##### set & multiset

  **底层结构：** **红黑树**

  **特性:**

   	1. 有序存储元素
   	2. O(lgn)的查找，插入，删除操作

![1558597975020](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558597975020.png)

![1558597993114](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558597993114.png)

![1558598284805](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558598284805.png)



#### 9、set(HashTable)

* hashtable

![1558614134971](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558614134971.png)

![1558614651247](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558614651247.png)

![1558614722368](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558614722368.png)

![1558614739829](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558614739829.png)

![1558615063846](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615063846.png)

![1558615001997](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615001997.png)

![1558615600007](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615600007.png)

![1558615674116](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615674116.png)



**hashtable的实现：**

![1558615804720](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615804720.png)

![1558615892653](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615892653.png)

![1558616148919](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558616148919.png)



**整个hashtable由vector和linked_list组合而成 **



**hashtable的迭代器：**

![1558615963616](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615963616.png)

![1558615978852](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558615978852.png)



**hashtable的执行样例图：**

![1558616927821](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558616927821.png)

![1558616955501](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558616955501.png)

![1558617010767](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558617010767.png)



**思考：**

​	用拉链法设计一个哈希类，要求把链换成STL中的map。注意实现线程安全



* **hash_set 、 hash_multiset**

![1558617182118](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558617182118.png)

![1558617382062](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558617382062.png)



#### 10、序列式容器

![1558580789480](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580789480.png)

#### 11、vector

**底层结构： ** 连续的线性空间

**迭代器：**

![1558509085055](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558509085055.png)

**特性：**

1. O(1)时间的快速访问；

2. 顺序存储，所以插入到非尾结点位置所需时间复杂度为O(n)，删除也一样
3. 动态空间，随着元素的加入，他的内部机制会自行扩充空间来容纳新元素

**扩容：**

​	当我们新建一个vector的时候，会首先分配给他一片连续的内存空间，如`std::vector<int> vec`，当通过push_back向其中增加元素时，如果初始分配空间已满，就会引起vector扩容，其扩容规则在gcc下以2倍方式完成：
​	首先重新申请一个2倍大的内存空间；然后将原空间的内容拷贝过来；最后将原空间内容进行释放，将内存交还给操作系统

![1558507058903](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558507058903.png)

​	vector采用的数据结构非常简单那：线性连续空间，它以两个迭代器start和finish分别指向配置得来的连续空间中目前已被使用的范围，并以迭代器end_of_storage指向整块连续空间（包含备用空间）的尾端

​	所谓动态增加大小，并不是在原空间之后接续新空间，而是以原大小的两倍另外配置一块较大空间，然后将原内容拷贝过来，然后才开始在原内容之后构造新元素，并释放原空间，因此，对vector的任何操作，一旦引起空间重新配置，指向原vector的所有迭代器就都失效了。

**注意事项：**

​	根据vector的插入和删除特性，以及扩容规则，我们在使用vector的时候要注意，**在插入位置和删除位置之后的所有迭代器和指针引用都会失效，同理，扩容之后的所有迭代器指针和引用也都会失效。**

**基本函数：**



**erase()函数：**



![1558507705747](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558507705747.png)



**insert()函数：**



![1558507867694](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558507867694.png)

![1558508060797](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508060797.png)

![1558508128859](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558508128859.png)



**clear():**

Removes all elements from the vector (which are destroyed), leaving the container with a size of 0. 
看清楚了吗，英文中提到的是size=0，而非capacity。

~~~ C++
#include<iostream>
#include<vector>
using namespace std;
int main()
{
    vector<int> v;
    v.push_back(1);
    v.push_back(2);
    v.push_back(3);
    v.push_back(4);
    v.push_back(5);

    cout << "size:" << v.size() << endl;
    cout << "capacity:" << v.capacity() << endl;

    v.clear();
    cout << "after clear size:" << v.size() << endl;
    cout << "after clear capacity:" << v.capacity() << endl;
    return 0;
}
//输出
size:5
capacity:6
after clear size:0
after clear capacity:6

原文链接：https://blog.csdn.net/wangshubo1989/article/details/50359750
~~~



**vector().swap(x); // clear x reallocating**

~~~ C++
#include <iostream>
#include <vector>

int main()
{
    std::vector<int> foo;
    foo.push_back(1);
    foo.push_back(2);
    foo.push_back(3);
    foo.push_back(4);
    foo.push_back(5);

    std::vector<int> bar;  
    bar.push_back(1);
    bar.push_back(2);


    std::cout << "foo size:" << foo.size() << std::endl;
    std::cout << "foo capacity:" << foo.capacity() << std::endl;

    std::cout << "bar size:" << bar.size() << std::endl;
    std::cout << "bar capacity:" << bar.capacity() << std::endl;
    foo.swap(bar);

    std::cout << "after swap foo size:" << foo.size() << std::endl;
    std::cout << "after swap foo capacity:" << foo.capacity() << std::endl;

    std::cout << "after swap bar size:" << bar.size() << std::endl;
    std::cout << "after swap bar capacity:" << bar.capacity() << std::endl;

    return 0;
}
//输出：
foo size:5
foo capacity:6
bar size:2
bar capacity:2
after swap foo size:2
after swap foo capacity:2
after swap bar size:5
after swap bar capacity:6
~~~



**shrink_to_fit()也可以帮助释放vector内存**

~~~ C++
#include<iostream>
#include<vector>
using namespace std;
int main()
{
    vector<int> v;
    v.push_back(1);
    v.push_back(2);
    v.push_back(3);
    v.push_back(4);
    v.push_back(5);

    cout << "size:" << v.size() << endl;
    cout << "capacity:" << v.capacity() << endl;

    v.clear();
    v.shrink_to_fit();
    cout << "after swap size:" << v.size() << endl;
    cout << "after swap capacity:" << v.capacity() << endl;
    return 0;
}
//输出：
size:5
capacity:6
after swap size:0
after swap capacity:0
~~~



**vector的实现：**

~~~ C++
// Date   : 2016.07.22
// Author : yqtao
// https://github.com/yqtaowhu
/********************************
* 实现自己的vector
* 注意vector中的迭代器只是普通的指针，因此不必进行重载操作
* 它是Random Access Iterator
********************************/
#ifndef MY_VECTOR_H
#define MY_VECTOR_H

#include <memory>
#include <iostream>
#include <algorithm>
template <class T, class Alloc=std::allocator<T>> class myVector
{
public:
	//vector的嵌套类型
	typedef T						value_type;
	typedef value_type*				iterator;
	typedef const value_type*		const_iterator;
	typedef value_type&				reference;
	typedef value_type*				pointer;
	typedef	size_t					size_type;    
	typedef ptrdiff_t				difference_type; //表示两个迭代器之间的距离 ,c++内置定义 typedef int ptrdiff_t;
protected:
	std::allocator<value_type> _alloc;  //空间分配器,这里使用stl标准写法，而不是sgi标准写法
	iterator _start;					//数组的首元素
	iterator _end;					//目前使用空间的尾
	iterator _end_of_storage;			//目前可用空间的尾
public:
	myVector() :_start(0), _end(0), _end_of_storage(0){}//默认构造函数
	myVector(size_type n, const T& value);
	myVector(size_type n);  
	myVector(iterator first, iterator last);
	myVector(const myVector& v);			//复制构造函数
	myVector& operator=(const myVector& rhs);  //赋值操作符函数
	~myVector() { _destroy(); }

	
	iterator begin() { return _start; }
	iterator end()	 { return _end; }
	const_iterator cbegin() const { return _start; }    //常量迭代器
	const_iterator cend() const { return _end; }

	size_type size()  { return size_type(end() - begin()); }  //注意转换成size_t类型
	size_type capacity() { return size_type(_end_of_storage - begin()); }
	bool empty() { return begin() == end(); }
	void swap(myVector &other);
	

	reference front() { return *begin(); }
	reference back() { return *(end() - 1); }
	reference operator[] (size_type n) { return *(begin() + n); }           //重载[],这样可以用a[n]进行访问元素

																			//删除数组中的元素，并且释放内存
	 
	void insert_aux(iterator positon, const T& x);  //一个插入辅助的函数，在向量为满的时候用到
	void push_back(const T& value);
	void pop_back();
	void insert(iterator position, size_type n, const T& x);  

	iterator erase(iterator position);
	iterator erase(iterator first, iterator last);  //删除[first,last)的元素
	void clear() { erase(begin(), end()); }
private:
	
	void _destroy();   //删除数组中的元素，并且释放内存
	
};



template <class T, class Alloc = std::allocator<T>>
myVector<T, Alloc>::myVector(size_type n, const T& value) {
	_start = _alloc.allocate(n);						 //调用配置器函数分配内存
	std::uninitialized_fill(_start, _start + n, value);  //调用c++内置函数进行初始化
	_end = _end_of_storage = _start + n;                 //修改迭代器的指针
}
//构造函数n 个0
template <class T, class Alloc = std::allocator<T>>
myVector<T, Alloc>::myVector(size_type n) {
	_start = _alloc.allocate(n);
	std::uninitialized_fill(_start, _start + n, 0);
	_end = _end_of_storage = _start + n;              
}
//
template <class T, class Alloc = std::allocator<T>>
myVector<T, Alloc>::myVector(iterator first, iterator last) {
	_start=_alloc.allocate(last - first);  //分配空间
	_end=_end_of_storage=std::uninitialized_copy(first, last, _start);
}
//
template <class T, class Alloc = std::allocator<T>>
myVector<T, Alloc>::myVector(const myVector& v) {
	size_type n= v.cend() - v.cbegin();
	_start=_alloc.allocate(n);    //分配空间
	_end = _end_of_storage = std::uninitialized_copy(v.cbegin(), v.cend(), _start);
}
//
template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::swap(myVector &other) {
		std::swap(_start, other._start);
		std::swap(_end, other._end);
		std::swap(_end_of_storage, other._end_of_storage);
}
//
template <class T, class Alloc = std::allocator<T>>
myVector<T, Alloc> &myVector<T, Alloc>::operator=(const myVector &rhs) {
	if (this == &rhs)
		return *this;
	size_type n = rhs.cend() - rhs.cbegin();
	_start=_alloc.allocate(n);
	_end = _end_of_storage = std::uninitialized_copy(rhs.cbegin(), rhs.cend(), _start);
}
//

template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::insert(iterator position, size_type n, const T& x) {
	if (n >= 0) {
		if (_end_of_storage - _end >= n) {   //剩余空间够用,分两种情况
			T x_copy = x;
			const size_type elem_after = _end - position;   //计算插入点之后的元素个数
			iterator old_end = _end;       
			if (elem_after >n) {
				uninitialized_copy(_end - n, _end, _end);
				_end = _end + n;        //将尾端后移
				copy_backward(position, old_end - n, old_end);
				fill(position, position + n, x_copy);
			}
			else {                      //要插入的元素大于等于插入点之后元素
				uninitialized_fill_n(_end, n - elem_after, x_copy);
				_end += n - elem_after;
				uninitialized_copy(position, old_end, _end);
				_end += elem_after;
				fill(position, old_end, x_copy);
			}
		}
		else {            //如果剩余空间不足
			const size_type old_size = size();
			const size_type len = old_size + max(old_size, n);
			iterator new_start = _alloc.allocate(len);
			iterator new_end = new_start;
			new_end =uninitialized_copy(_start, position , new_start);   //将position之前的元素复制到新容器
			new_end=uninitialized_fill_n(new_end, n, x);    //插入元素
			new_end=uninitialized_copy(position, _end, new_end);
			_destroy();   //调用成员函数进行释放空间
			//重新调整迭代器，使其指向新的位置
			_start = new_start;
			_end = new_end;
			_end_of_storage = new_start + len;
		}
	}
}
//
template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::insert_aux(iterator positon, const T& x) {
	if (_end != _end_of_storage) {

	}
	else {
		const size_type old_size = size();                    //需要注意，如果开始长度为0
		const size_type len = old_size ? 2 * old_size : 1;    //则配置长度1，否则，加倍
		iterator new_start = _alloc.allocate(len);            //重新分配空间
		iterator new_end = new_start;
	    
		new_end = uninitialized_copy(_start, positon, new_start);   //对于push_back来说position=_end,将其拷贝出来
	    _alloc.construct(new_end, x);                     //插入元素
		++new_end;
		new_end = uninitialized_copy(positon, _end, new_end);     //将插入点后的元素也拷贝过来

		_destroy();                    //执行自定义函数
		//add by cy，this对象自行调用_destroy(),相当于自行销毁之前的空间
		//调整迭代器，指向新的指针

		//重新调整迭代器，使其指向新的位置
		_start = new_start;
		_end = new_end;
		_end_of_storage = new_start + len;

	
	}
}
//
template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::push_back(const T& value) {
	if (_end != _end_of_storage) {        //如果还有剩余的空间
		_alloc.construct(_end, value);        //在_end处调用配置器插入value
		++_end;                               //迭代器后移
	}
	else
		insert_aux(end(), value);                //如果空间已满		
}
//
template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::pop_back() {
	--_end;               //这里要注意的是，删除尾部，要让_end先移动到最后一个元素
	_alloc.destroy(_end);
}
//
template <class T, class Alloc = std::allocator<T>>
typename myVector<T, Alloc>::iterator myVector<T, Alloc>::erase(iterator position) {
	if (position + 1 != end())   //也就是说要删除的这个元素不是最后一个元素
		copy(position + 1, end(), position);
	--_end;
	_alloc.destroy(_end);
	return position;
}
//
template <class T, class Alloc = std::allocator<T>>
typename myVector<T, Alloc>::iterator myVector<T, Alloc>::erase(iterator first, iterator last) {
	difference_type left = _end - last;   
	std::copy(last, _end, first);         //first last avail 向前迁移元素
	iterator it(first + left);
	while (_end != it)                   //需要析构，有可能不需要析构，这要看在last后元素与删除元素的比较
		_alloc.destroy(--_end);
	return first;
}


template <class T, class Alloc = std::allocator<T>>
void myVector<T, Alloc>::_destroy() {
	//先执行析构函数
	if (_start)
	{
		iterator it(_end); //初始
		while (it != _start)
			_alloc.destroy(--it);
	}

	//释放内存
	_alloc.deallocate(_start, _end_of_storage - _start);
	_start= _end_of_storage = _end = NULL;
}
#endif
~~~

**note：**

每一次删除之后，后边的元素都会向前移动。

所以当前迭代器实际已经指向下一个元素，若再+1，实际上是指向了下一个元素的下一个元素

所以对vector进行删除时代码为：

~~~ C++
vector<int>::iterator itr = v.begin();
   while (itr!=v.end())
   {
    	if (*v==1)
    	{
          	itr=v.erase(itr);
     	}
		else
    		itr++;
   }
~~~



reference:https://blog.csdn.net/taoyanqi8932/article/details/52014421

#### 12、queue

* queue

  单向队列，先入先出

  ![1558528563203](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528563203.png)

**底层数据结构：**

![1558528644655](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528644655.png)

![1558528687107](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528687107.png)



**queue的迭代器：**

![1558528668690](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528668690.png)





* **deque**

  双向队列，对比queue可以实现在头尾两端高效的插入和删除操作

**deque的介绍：**

![1558526061491](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526061491.png)

![1558526151024](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526151024.png)![1558526170657](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526170657.png)

![1558526218915](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526218915.png)

![1558526314822](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526314822.png)

![1558526348837](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526348837.png)

![1558526391104](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526391104.png)

​	上图本质上相当于deque的扩容方式

**deque的数据结构：**

![1558526752324](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526752324.png)



**deque的迭代器：**

​	![1558526497748](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526497748.png)

![1558526516042](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526516042.png)

![1558526617526](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558526617526.png)



**deque的基本函数操作：**

**push_back()：**

![1558527117645](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527117645.png)

![1558527198948](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527198948.png)

![1558527211265](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527211265.png)

![1558527226864](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527226864.png)

![1558527266040](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527266040.png)

![1558527300739](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527300739.png)

![1558527387929](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527387929.png)

**find（）：**

![1558527514768](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558527514768.png)



* priority_queue

  **底层数据结构：**max_heap

  优先级队列相当于一个**有权值**的单向队列queue，在这个队列中，所有元素是按照优先级排列的

  ![1558529890068](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529890068.png)

  ![1558529943280](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529943280.png)

**priority_queue的迭代器：**

![1558530013730](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558530013730.png)

~~~ C++
//VS2008中 priority_queue的定义 MoreWindows整理( http://blog.csdn.net/MoreWindows )
template<class _Ty, class _Container = vector<_Ty>, class _Pr = less<typename _Container::value_type> > //默认以vector为容器的
class priority_queue
{	// priority queue implemented with a _Container
public:
	typedef _Container container_type;
	typedef typename _Container::value_type value_type;
	typedef typename _Container::size_type size_type;
	typedef typename _Container::reference reference;
	typedef typename _Container::const_reference const_reference;
 
	priority_queue() : c(), comp()
	{	// construct with empty container, default comparator
	}
 
	explicit priority_queue(const _Pr& _Pred) : c(), comp(_Pred)
	{	// construct with empty container, specified comparator
	}
 
	priority_queue(const _Pr& _Pred, const _Container& _Cont) : c(_Cont), comp(_Pred)
	{	// construct by copying specified container, comparator
		make_heap(c.begin(), c.end(), comp); //参见《STL系列之四 heap 堆的相关函数》
	}
 
	template<class _Iter>
	priority_queue(_Iter _First, _Iter _Last) : c(_First, _Last), comp()
	{	// construct by copying [_First, _Last), default comparator
		make_heap(c.begin(), c.end(), comp);
	}
 
	template<class _Iter>
	priority_queue(_Iter _First, _Iter _Last, const _Pr& _Pred) : c(_First, _Last), comp(_Pred)
	{	// construct by copying [_First, _Last), specified comparator
		make_heap(c.begin(), c.end(), comp);
	}
 
	template<class _Iter>
	priority_queue(_Iter _First, _Iter _Last, const _Pr& _Pred, const _Container& _Cont) : c(_Cont), comp(_Pred)
	{	// construct by copying [_First, _Last), container, and comparator
		c.insert(c.end(), _First, _Last);
		make_heap(c.begin(), c.end(), comp);
	}
 
	bool empty() const
	{	// test if queue is empty
		return (c.empty());
	}
 
	size_type size() const
	{	// return length of queue
		return (c.size());
	}
 
	const_reference top() const
	{	// return highest-priority element
		return (c.front());
	}
 
	reference top()
	{	// return mutable highest-priority element (retained)
		return (c.front());
	}
 
	void push(const value_type& _Pred)
	{	// insert value in priority order
		c.push_back(_Pred);
		push_heap(c.begin(), c.end(), comp);
	}
 
	void pop()
	{	// erase highest-priority element
		pop_heap(c.begin(), c.end(), comp);
		c.pop_back();
	}
 
protected:
	_Container c;	// the underlying container
	_Pr comp;	// the comparator functor
};
~~~

#### 13、list

**底层结构：**双向链表

![1558510218546](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558510218546.png)

​	SGI list 不仅是一个双向链表，而且还是一个环状双向链表，所以他只需要一个指针，便可以完整表现整个链表。

![1558511159938](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558511159938.png)



**特性：**

 	1. 支持快速的增删



**list的迭代器：**

![1558510141831](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558510141831.png)

![1558510168152](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558510168152.png)

**基本函数操作：**

* push_back()：（内含insert()）

![1558511536642](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558511536642.png)

* erase()

![1558511855725](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558511855725.png)

* transfer:将某连续范围的元素迁移到某个特定位置之前

  ![1558525857810](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558525857810.png)

![1558512095038](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558512095038.png)

​	上述的transfer并非公开接口，list公开提供的是所谓的接合操作splice，将某连续范围的元素从一个list移动到另一个（或同一个）list的某个定点。

* splice()

![1558512235197](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558512235197.png)



#### 14、stack

![1558528346629](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528346629.png)

**底层结构：**

![1558528403860](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528403860.png)

![1558528521641](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528521641.png)



**stack的迭代器：**

![1558528491693](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528491693.png)



#### 15、heap

**底层结构：**vector

![1558528974580](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528974580.png)

![1558528986599](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558528986599.png)

![1558529028448](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529028448.png)



**heap的迭代器：**

![1558529133604](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529133604.png)



**heap的基本函数操作：**

**push_heap():**

![1558529419107](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529419107.png)

**pop_heap():**

![1558529631317](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529631317.png)

![1558529660059](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529660059.png)

**sort_heap():**

![1558529741293](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558529741293.png)



#### 16、slist

![1558530742091](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558530742091.png)



**slist基本函数操作:**

insert();erase()

![1558580119459](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580119459.png)

![1558580129400](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580129400.png)

![1558580142634](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580142634.png)

![1558580154796](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580154796.png)

![1558580352412](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580352412.png)

![1558580366566](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558580366566.png)





#### 17、迭代器的++it和it++哪个好

![1558510627516](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558510627516.png)

​	携带参数int的函数是迭代器后置++，需要先将本身的值保存下来，然后调用前置++，再返回++前的值

​	所以在前置++和后置++效果一致的情况下，建议使用前置++



#### 18、swap()函数

先来看第一段程序：

~~~ C++
void swap(int x, int y) {
    int temp = y;
    y = x;
    x = temp;
}
~~~

通过main函数的调用，我们发现x,y并未实现交换：

~~~ C++
int main()
{
    int x = 1;
    int y = 37;

    swap(x, y);

    cout << x << ":" << y << endl;
    return 0;
}
~~~

​	原因是整形x和y在函数swap内为按值传递，按值传递时，函数不会访问当前调用的实参。函数处理的值是它本地的拷贝，这些拷贝被存储在运行栈中，因此改变这些值不会影响实参的值。一旦函数结束了，函数的活动记录将从栈中弹出，这些局部值也就消失了。

​	另外，如果作为实参的变量是一个大型类的对象，分配并拷贝到栈中的时间和空间开销往往过大。

要实现swap函数的效果，我们应如何处理呢？第一个可行的做法是将形参声明成指针

~~~ C++
void pswap(int *x, int *y) {
    int temp = *y;
    *y = *x;
    *x = temp;
}
~~~

​	在pswap函数中，由于传递的是两个变量的内存地址（指针）使得我们可以直接操作对应的值。实际上这里还是存在按值传递的问题，只是由原先的整形传递变成了指针传递。我们可以修改指针指向的内存却依然无法修改指针本身。第二个可行的做法是想形参声明为指针的引用：

~~~ C++
void prswap(int *&x, int *&y) {
    int temp = *y;
    *y = *x;
    *x = temp;
}

void prswap(int *&x, int *&y) {
    int *temp = y;
    y = x;
    x = temp;
}
~~~

**note：**In your case, you pass a pointer by reference. The effect is the same as in the number example. The value of the pointer (a memory address: a number) can be changed in the function and the changes will be visible outside the function.

​	上述函数相当于传递了一个指针的引用，可以修改指针的内容，并修改后的效果在函数调用的外围依旧可见

​	请注意，同一个函数原型下我提供了两种函数定义。可无论哪一种，在实参传递的阶段都不会发生按值传递的问题。那么两种定义到底哪一种更满足我们需求：

（1）交换内存中的值

![img](https://images2018.cnblogs.com/blog/871676/201803/871676-20180311122240452-1160750927.png)

（2）交换指针地址

![img](https://images2018.cnblogs.com/blog/871676/201803/871676-20180311122349941-929540824.png)

​	如果单独考虑本文的需求，第一种方法更满足。但是，如果我们需要交换的是一个大型类对象，第二种的效率则更高。

​	总结：内存管理是C++学习的一个难点，初学者往往不容易掌握。但越是如此就越能体现一个开发者的语言内功。

reference：https://www.cnblogs.com/learnhow/p/8543822.html



## 拷贝函数

#### **1、手写memcopy**（考虑内存重叠特殊情况）

```
void * memcpy ( void * destination, const void * source, size_t num );
1. source指向源数组的首地址，destination指向目标数组的首地址，num：复制移动的byte数目
2.为避免溢出，source和destination指向的数组不能重叠，且size至少为num
  两个对象都被转译成 unsigned char 的数组
3.destination is returned

note：
	标准库函数中的memcpy()函数不考虑src与dst重叠的情况，memmove()考虑了内存重叠的情况，但是该函数把源字符串拷贝到临时buf里，然后再从临时buf里写到目的地址，增加了一次不必要的开销，存在效率问题
	那么我们在重写memcpy()函数的时候需要添加内存重叠的情况
```

~~~ C++
  1 #include <stdio.h>                                                                     2 #include <stdlib.h>
  3 #include <string.h>
  4 
  5 void * myMemcopy(void *dst,void* src, size_t num);
  6 
  7 int main(int argc,char* argv[]){
  8   char buf[100] = "hi~baby!";
  9   myMemcopy(buf+2,buf,9);
 10   printf("%s\n",buf+2);
 11 }
 12 
 13 void * myMemcopy(void *dst, void* src,size_t num){
 14   char * psrc;
 15   char * pdst;
 16   if(nullptr==dst || nullptr==src){
 17     return nullptr;
 18   }
 19 
 20   if((src<dst)&&((char*)src+num>(char*)dst)){
 21     //自后向前拷贝
 22     psrc = (char *)src + num-1;
 23     pdst = (char *)dst +num -1;
 24     while(num--){
 25       *pdst-- = *psrc--;
 26     }
 27   }else{
 28     psrc = (char *)src;
 29     pdst = (char *)dst;
     //注意：此处的while(num--)的执行顺序：
     //先在while中判断num，然后执行num--，然后执行while循环体
     //while(--num)的执行顺序是：先--num，然后对--后的num进行while判断，然后执行循环体
 30     while(num--){
 31       *pdst++ = *psrc++;
 32     }
 33   }
 34 
 35   return dst;
 36 
 37 }
~~~



#### **2、实现strcpy，要考虑内存重叠和特殊情况处理**

```
char * strcpy ( char * destination, const char * source );
参数解释：source：C string to be copied
返回值：destination is returned.
des 和 src 所指内存区域不可以重叠且 des 必须有足够的空间来容纳 src 的字符串
且包括字符串的结束符

note:
	源指针所指的字符串内容是不能修改的，因此应该声明为 const 类型。
	要判断源指针和目的指针为空的情况，思维要严谨，这里使用assert。
	要用一个临时变量保存目的串的首地址，最后返回这个首地址。
```

~~~ C++
  1 #include <stdio.h>                                                                     2 #include <stdlib.h>
  3 #include <string.h>
  4 #include <assert.h>
  5 
  6 char * myStrcpy(char *dst,const char * src);
  7 
  8 int main(int argc,char* argv[]){
  9   char buf[100] = "hi~baby!";
 10   myStrcpy(buf+2,buf);
 11   printf("%s\n",buf+2);
 12 }
 13 
 14 char * myStrcpy(char *dst, const char* src){
 15   const char * psrc;
 16   char * pdst;
 17 
 18   assert((nullptr!=dst)||(nullptr!=src));
 19 
 20   size_t num = strlen(src)+1;
 21 
 22   if((src<dst)&&(src+num>dst)){
 23     //自后向前拷贝
 24     psrc = src + num-1;
 25     pdst = dst +num -1;
 26     while(num--){
 27       *pdst-- = *psrc--;
 28     }
 29   }else{
 30     psrc = src;
 31     pdst = dst;
 32     while(num--){
 33       *pdst++ = *psrc++;
 34     }
 35   }
 36 
 37   return dst;
 38 
 39 }
~~~

> ### 附：assert()断言
>
> `assert`是宏，而不是函数。它的原型定义在头文件 assert.h 中：
>
> ```
> void assert( int expression );
> ```
>
> 
>
> 宏 assert 经常用于在函数开始处检验传入参数的合法性，可以将其看作是异常处理的一种高级形式。**assert 的作用是**先计算表达式expression，然后判断：
>
> - 如果表达式值为假，那么它先向stderr打印错误信息，然后通过调用 abort 来终止程序运行。
> - 如果表达式值为真，继续运行后面的程序。
>
> 注意：`assert`只在 DEBUG 下生效，在调试结束后，可以通过在`#include <assert.h>`语句之前插入`#define NDEBUG`来禁用assert调用。



#### **3、strcpy实现方法及其缺点**

标准函数库中的strcpy不能处理内存重叠的特殊情况

传统的实现方法是：

~~~ C++
#include <assert.h>
#include <stdio.h>

char* strcpy(char* des, const char* src)
{
	assert((des!=NULL) && (src!=NULL)); 
	char *address = des;  
	while((*des++ = *src++) != '\0')  
		;  
	return address;
}
~~~



#### **4、strcpy和memcpy的区别**

* 复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。 
* 复制的方法不同。strcpy不需要指定长度，它遇到被复制字符的串结束符”\0”才结束，**所以容易溢出**。memcpy则是根据其第3个参数决定复制的长度，不论是否遇到了”\0“，一定会复制完n个byte。 
* 执行效率不同，memcpy最高，strcpy次之（因为标准库中的这两个函数并不考虑特殊情况的处理）

#### 5、strncpy

~~~ C++
char  *strncpy(char *dst, const char *src, size_t n);

函数strncpy从src指向的数组中最多复制n个字符（不复制空字符后面的字符）到dst指向的数组中。如果复制发生在两个重叠的对象中，则这种行为未定义。

如果s1指向的数组是一个比n短的字符串，则在s2定义的数组后面补空字符，直到写入了n个字符。

返回值：dst的值
~~~

​	memcpy和strncpy都是可以指定要复制的字符个数n，只是strncpy遇到'\0'时就会停止字符串的复制，并在后面添加'\0'以使得总复制的字符数为n。



> **note:**
>
> * 在s1小于s2或者s1小于n的时候，strcpy,memcpy和strncpy都可以正常运行，如果s2的长空间不足以存储s1的内容，s2分配空间后面的数据将会被覆盖
>
> * s2指向的空间要足够拷贝；使用strcpy时，s2指向的空间要大于等于s1指向的空间（包含”＼０“）；使用strncpy或memcpy时，s2指向的空间要大于或等于n。
>
> * 使用strncpy或memcpy时，n应该大于strlen(s1)，或者说最好n >= strlen(s1)+1；这个1 就是最后的“\0”。
> * 使用strncpy时，确保s2的最后一个字符是“\0”。



## 字符串函数（C库）

#### 1、strlen

reference：https://github.com/arkingc/note/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E9%A2%98%E6%80%BB%E7%BB%93.md

* 迭代

~~~ C++
#include <cassert>

//字符串长度计算
int strlen(const char *str)
{
    assert(str);

    int len = 0;
    while(*str++)   len++;
    return  len;
}
~~~

* #### 递归

~~~ C++
//如果要求不使用额外变量就需要用递归版
#include <cassert>

//字符串长度计算
int strlen(const char *str)
{
    assert(str);

    return (*str == 0) ? 0 : 1 + strlen(str + 1);  
}
~~~

#### 2、strcmp

~~~ C++
#include <cassert>

//字符串比较
int strcmp(const char *str1,const char *str2)
{
    assert(str1 && str2);

    //在判断是否相等时不一定要转换为unsigned char
    while((*str1 == *str2) && *str1){
        str1++;
        str2++;
    }

    if(*str1 == *str2)//说明上面循环退出时*str等于0
        return 0;

    //128种扩展ascii码使用最高位来标识，
    //所以在判断返回大于0还是小于0是，要转换为unsigned char，否则结果相反

    return *(unsigned char*)str1 > *(unsigned char*)str2 ? 1 : -1;
}
~~~

#### 3、strcat

~~~ C++
#include <cassert>

//字符串拼接
char* strcat(char *strDest,const char *strSrc)
{
    assert(strDest && strSrc);

    char *p = strDest;
    while(*p) p++;

    while(*p++ = *strSrc++);
    return strDest;
}
~~~

#### 4、strcpy

~~~ C++
#include <cassert>

//字符串拷贝
char* strcpy(char *strDest,const char *strSrc)
{
    assert(strDest && strSrc);

    char *p = strDest;
    while(*p++ = *strSrc++);
    return strDest;
}
~~~



## 算法

### github 关于leetecode的各类算法总结：

reference：https://github.com/arkingc/note/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E9%A2%98%E6%80%BB%E7%BB%93.md



### 查找

​	**一般基于递归实现的采用DFS的思想，基于迭代实现的是BFS的思想**

#### 1、BFS

​	**辅助数据结构：**queue

​	对于每个顶点，在访问其它顶点前，检查当前节点所有邻接点。和树的广度优先遍历类似

​	BFS执行过程将产生一棵**BFS(广度优先搜索)树**：

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-6.png)

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-7.png)



#### 2、DFS

​	**辅助数据结构：**stack

​	树的中根遍历类似于DFS

* DFS执行过程：

  DFS会递归地访问它的所有未被访问的相邻顶点：

1. 先访问顶点v，把所有与v相关联的边存入栈中；
2. 弹出栈顶元素，栈顶元素代表的边所关联的另一个顶点就是要访问的下一个元素k；
3. 对k重复对v的操作；
4. 重复，直至栈中所有元素都被处理完毕

DFS的执行过程将产生一棵**DFS(深度优先搜索)树**：

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-4.png)

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-5.png)



#### **3、二分查找**

要准确实现二分查找，首先要把握下面几个要点：

关于right的赋值
right = n-1 => while(left <= right) => right = middle-1;
right = n => while(left < right) => right = middle;

middle的计算不能写在while循环外，否则无法得到更新。

~~~ C++
int BinarySearch(int array[], int n, int value)
{
    int left = 0;
    int right = n - 1;
    //如果这里是int right = n 的话，那么下面有两处地方需要修改，以保证一一对应：
    //1、下面循环的条件则是while(left < right)
    //2、循环内当 array[middle] > value 的时候，right = mid
 
    while (left <= right)  //循环条件，适时而变
    {
        int middle = left + ((right - left) >> 1);  //防止溢出，移位也更高效。同时，每次循环都需要更新。
 
        if (array[middle] > value)
        {
            right = middle - 1;  //right赋值，适时而变
        }
        else if(array[middle] < value)
        {
            left = middle + 1;
        }
        else
            return middle;
        //可能会有读者认为刚开始时就要判断相等，但毕竟数组中不相等的情况更多
        //如果每次循环都判断一下是否相等，将耗费时间
    }
    return -1;
}
~~~

~~~ C++
int left = 0;
int right = n-1;
while(left<=right){
    ...
    left = mid+1;
    ...
    right = mid-1;
    ...
}


int left = 0;
int right = n;
while(left<right){
    ...
    left = mid+1;
    ...
    right = mid;
    ...
}
~~~

当利用二分查找，find二元元组对之间的关系时：

题目：

> Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.
>
> (i.e.,  `[0,1,2,4,5,6,7]` might become  `[4,5,6,7,0,1,2]`).
>
> Find the minimum element.
>
> You may assume no duplicate exists in the array.

~~~ C++
class Solution {
public:
    int findMin(vector<int>& nums) {
        //二分查找，只有nums[mid]<nums[right],就说明当前的mid在右subnums中，目标在左边
        int len = nums.size();
        //当旋转的支点就是nums[len-1]
        if(nums[0]<nums[len-1])
            return nums[0];
        int left = 0;
        int right = len-1;
        while(left!=right){
            int mid = (left+right)/2;
            if(nums[mid]<nums[right]){
                //为什么此处是mid，而不是mid-1呢？
                right = mid;
            }else{
                left = mid+1;
            }
        }
        /return left或right都可以
        return nums[left];
    }
};
~~~



### 排序

**内排序**

#### 1.插入排序（稳定）

逐个处理待排序的记录，每个记录与前面已排序的子序列进行比较，将它插入子序列中正确位置

~~~  c++
template<class Elem>
void inssort(Elem A[],int n)
{
    for(int i = 1;i < n;i++)
        for(int j = i;j >= 1 && A[j] < A[j-1];j--)
            swap(A,j,j-1);
}
~~~

**性能：**

​	最佳：升序。时间复杂度为O(n)

​	最差：降序。时间复杂度为O(n^2)

​	平均：对于每个元素，前面有一半元素比它大。时间复杂度为O(n^2)

​	如果待排序数据已经“基本有序”，使用插入排序可以获得接近O(n)的性能

**优化：**

~~~ C++
template<class Elem>
void inssort(Elem A[],int n)
{
    for(int i = 1;i < n;i++){
        int j = i;
        int tp = A[j];
        for(;j >= 1 && tp < A[j-1];j--)
            A[j] = A[j - 1];
        A[j] = tp;
    }
}
~~~



#### 2.冒泡排序（稳定）

​	从数组的底部比较到顶部，比较相邻元素。如果下面的元素更小则交换，否则，上面的元素继续往上比较。这个过程每次使最小元素像个“气泡”似地被推到数组的顶部

![1558925475261](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558925475261.png)

~~~ C++
template<class Elem>
void bubsort(Elem A[],int n)
{
    for(int i = 0;i < n - 1;i++)
        for(int j = n - 1;j > i;j--)
            if(A[j] < A[j-1])
                swap(A,j,j-1);
}
~~~

**性能：**

​	冒泡排序是一种相对较慢的排序，没有较好的最佳情况执行时间。通常情况下时间复杂度都是O(n^2)

**优化：**

​	增加一个变量flag，用于记录一次循环是否发生了交换，如果没发生交换说明已经有序，可以提前结束



#### 3.选择排序（不稳定）

​	第i次“选择”数组中第i小的记录，并将该记录放到数组的第i个位置。换句话说，每次从未排序的序列中找到最小元素，放到未排序数组的最前面

~~~ C++
template<class Elem>
void selsort(Elem A[],int n)
{
    for(int i = 0;i < n - 1;i++){
        int lowindex = i;
        for(int j = i + 1;j < n;j++)
            if(A[j] < A[lowindex])
                lowindex = j;
        swap(A,i,lowindex);//n次交换
    }
}
~~~

**性能：**

​	不管数组是否有序，在从未排序的序列中查找最小元素时，都需要遍历完最小序列，所以时间复杂度为O(n^2)

**优化：**

​	每次内层除了找出一个最小值，同时找出一个最大值（初始为数组结尾）。将最小值与每次处理的初始位置的元素交换，将最大值与每次处理的末尾位置的元素交换。这样一次循环可以将数组规模减小2，相比于原有的方案（减小1）会更快



#### 4.shell排序（不稳定）

shell排序在不相邻的元素之间比较和交换。利用了插入排序的最佳时间代价特性，它试图将待排序序列变成基本有序的，然后再用插入排序来完成排序工作

在执行每一次循环时，Shell排序把序列分为互不相连的子序列，并使各个子序列中的元素在整个数组中的间距相同，每个子序列用**插入排序**进行排序。每次循环增量是前一次循环的1/2，子序列元素是前一次循环的2倍

最后一轮将是一次“正常的”插入排序（即对包含所有元素的序列进行插入排序）

![1558927355720](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558927355720.png)

~~~ C++
const int INCRGAP = 3;

template<class Elem>
void shellsort(Elem A[],int n)
{
    for(int incr = n / INCRGAP;incr > 0;incr /= INCRGAP){//遍历所有增量大小
        for(int i = 0;i < incr;i++){
            /*对子序列进行插入排序，当增量为1时，对所有元素进行最后一次插入排序*/
            for(int j = i + incr;j < n;j += incr){
                for(int k = j; k > i && A[k] < A[k - incr];k -= incr){
                    swap(A,k,k - incr);
                }
            }
        }
    }
}
~~~

**性能：**

​	选择适当的增量序列可使Shell排序比其他排序法更有效，一般来说，增量每次除以2时并没有多大效果，而“增量每次除以3”时效果更好

​	当选择“增量每次除以3”递减时，Shell排序的平均运行时间是O(n^(1.5))



#### 5.快速排序（不稳定）

​	首先选择一个轴值，小于轴值的元素被放在数组中轴值左侧，大于轴值的元素被放在数组中轴值右侧，这称为数组的一个分割(partition)。快速排序再对轴值左右子数组分别进行类似的操作

​	选择轴值有多种方法。最简单的方法是使用首或尾元素。但是，如果输入的数组是正序或者逆序时，会将所有元素分到轴值的一边。较好的方法是随机选取轴值

~~~ C++
template <class Elem>
int partition(Elem A[],int i,int j)
{
    //这里选择尾元素作为轴值,轴值的选择可以设计为一个函数
    //如果选择的轴值不是尾元素，还需将轴值与尾元素交换
    int pivot = A[j];
    int l = i - 1;
    for(int r = i;r < j;r++)
        if(A[r] <= pivot)
            swap(A,++l,r);
    swap(A,++l,j);//将轴值从末尾与++l位置的元素交换
    return l;
}

template <class Elem>
void qsort(Elem A[],int i,int j)
{
    if(j <= i)  return;
    int p = partition<Elem>(A,i,j);
    qsort<Elem>(A,i,p - 1);
    qsort<Elem>(A,p + 1,j);
}
~~~

**性能：**

​	最佳情况：O(nlogn)

​	平均情况：O(nlogn)

​	最差情况：每次处理将所有元素划分到轴值一侧，O(n^2)

​	快速排序平均情况下运行时间与其最佳情况下的运行时间很接近，而不是接近其最坏情况下的运行时间。**快速排序是所有内部排序算法中平均性能最优的排序算法**

**优化：**

1. 最明显的改进之处是轴值的选取，如果轴值选取合适，每次处理可以将元素较均匀的划分到轴值两侧：

   **三者取中法**：三个随机值的中间一个。为了减少随机数生成器产生的延迟，可以选取首中尾三个元素作为随机值

2. 当n很小时，快速排序会很慢。因此当子数组小于某个长度（经验值：9）时，什么也不要做。此时数组已经基本有序，最后调用一次插入排序完成最后处理



#### 6.topK

​	Top-K问题是一个十分经典的问题，一般有以下两种方式来描述问题：在10亿的数字里，找出其中最大的100个数；或者在一个包含n个整数的数组中，找出最大的100个数。

​	前边两种问题描述稍有区别，但都是说的Top-K问题，前一种描述方式是说这里也许没有足够的空间存储大量的数字或其他东西，我们最好可以在一边输入数据，一边求出结果，而不需要存储数据；后一种说法则表示可以存储数据，这种情况下，最简单直观的想法就是对数组进行排序，取后100个数即为所求。

①第一种情况的思路：

​	这种情况下，关键在于不能消耗太大的内存，无法通过数组的简单排序来求取最大的K个数，于是我们应该想到堆排序，求最大的K个数，就采用大小为K的最小二叉堆来实现；我们知道二叉堆可以看作是一颗近似的完全二叉树，其根节点正好就是K个数中最小的一个。

​	**具体算法：**先输入K个数，建立一个大小为K的最小二叉堆，接着每输入一个数，与堆的根节点进行比较，如果比根节点还小，说明不可能为最大的K个数之一，如果比根节点大，那么替换根节点的值，接着下沉根节点，维护二叉堆的性质。这样到成功输入所有数据后，最小二叉堆里剩下的就为最大的K个数。（如果求最小的K个数，同理换成最大二叉堆即可）。

​	时间复杂度：由于算法主要涉及对二叉堆结构的操作，所以总体时间复杂度为O(nlgK)。

~~~ C++
/*
*代码采用STL中的最小优先队列实现，由于STL中自带最小优先队列，其底层就是二叉堆实现，
*所以就不再手写二叉堆了。最小优先队列顶层元素总是队列中最小的元素，也就是二叉堆堆顶。
*/
 
#include <iostream>
#include <queue>
#include <vector>
using namespace std;
 
/*由于STL自带优先队列是默认最大优先的，所以自己写了一个比较函数，将其改为最小优先*/
struct cmp1 {
	bool operator ()(int &a, int &b) {
		return a>b;											//最小值优先
	}
};
 
int main() {
	//这里用来测试，输入格式：先输入需要求的最大K个数中的K值，再依次输入数据流
	int K = 0;
	cin >> K;
	int tmp = 0;
	int i = 0;
	priority_queue<int,vector<int>,cmp1> minHeap;			//建立最小优先队列
	while (cin >> tmp) {									//循环输入数据流
		if (i < K) {										//先建立一个K个大小的优先队列，也就是K大小的二叉堆
			minHeap.push(tmp);
		}
		else {												//算法实现
			if (tmp <= minHeap.top())
				continue;
			else if (tmp > minHeap.top()) {
				minHeap.pop();
				minHeap.push(tmp);
			}
		}
		i++;
	}
	while (!minHeap.empty()) {								//输出最大的K个数
		cout << minHeap.top() << endl;
		minHeap.pop();
	}
	return 0;
}
~~~

②第二种情况

​	这种情况，由于可以操作存储数据的数组，所以我们采用排序的方式进行求解，但一般的排序时间复杂度也挺高，题目只求最大的K个数，不需要完全排序；于是我们想到可以借用快排思想来进行求解。

​	这个解法源于快排（Quick Sort），所以也叫Quick Select，主要基于快排中Partition函数（对堆排和快排不熟悉的可以参照算法导论第6,7章）。

​	**具体算法：**我们知道，每运行一次Partition函数都会确定一个数m的最终位置，且小于m的数均在其左边，大于m的数都在其右边，所以我们的目的就是当数m的右边正好有K-1个数的时候停止算法，得到答案。每次运行Partition函数时，根据前边上述性质，若

​	K<右边数组长度，那么要找的K个数一定在m右边，对m右边的数组运行Partition函数；
​        K=右边数组长度+1，那么正好找到最大的K个数，为数m以及其右边数组，停止算法；
​        其他情况，最大的K个数不仅仅在m数右边数组中，对m左边数组运行Partition函数。

​	**时间复杂度：**与快排类似，Quick Select同样也是不稳定的算法，最坏情况下时间复杂度会达到O(n2)，但平均性能也与快排类似，时间复杂度一般可认为为O(n)。

~~~ C++
/*Quick Select*/
#include <iostream>
#include <vector>
 
using namespace std;
 
int Partition(vector<int> &vec, int p, int r) {				//实现快排中Partition函数，输入原数组引用，以及需要运行的左右下标
	if (p >= r)												//非法输入，Partition具体思想参照快排详解
		return r;
	int tmp = vec[r];
	int i = p;
    //此处的j相当于是low_index
	int j = p;
	while (i < r) {
        //大于temp的放在左边
		if (vec[i] <= tmp) {
			int temp = vec[i];
			vec[i] = vec[j];
			vec[j] = temp;
			i++;
			j++;
		}
		else if (vec[i] > tmp) {
			i++;
		}
	}
	vec[r] = vec[j];
	vec[j] = tmp;
	return j;
}
 
int main() {
	int K = 0;										//测试部分，输入需要求的K值大小，然后再依次输入数组元素
	cin >> K;
	int tmp = 0;
	vector<int> vec;
	while (cin >> tmp)
		vec.push_back(tmp);
	int size = vec.size();
        if (size == 0 || k>size) return vector<int>();
        if (size== k) return input;
        int p = 0;
	int r = vec.size() - 1;
	int index = Partition(vec, p, r);
	while (index != size - K) {						//当Partition返回值及右边部分不是K大小时，继续循环
		int sizeOfRight = size - index - 1;			//记录index右边数组长度大小
		if (K <= sizeOfRight) {
			index = Partition(vec, index + 1, r);
		}
		else if (K == sizeOfRight + 1)				//这一步好像有点多余，while循环保证了这点，但为了对应博客文字描述就加上了
			continue;
		else if (K > sizeOfRight + 1) {
			index = Partition(vec, p, index - 1);
		}
	}
	for (int i = index; i < size; i++) {			//测试部分，输出需要求的K个数
		cout << vec[i] << endl;
	}
	return 0;
}
~~~

reference：https://blog.csdn.net/Hairy_Monsters/article/details/79776744



#### 7.归并排序（稳定）

​	将一个序列分成两个长度相等的子序列，为每一个子序列排序，然后再将它们合并成一个序列。合并两个子序列的过程称为归并

~~~ C++
template<class Elem>
void mergesortcore(Elem A[],Elem temp[],int i,int j)
{
    if(i == j)  return;
    int mid = (i + j)/2;

    mergesortcore(A,temp,i,mid);
    mergesortcore(A,temp,mid + 1,j);

    /*归并*/
    int i1 = i,i2 = mid + 1,curr = i;
    while(i1 <= mid && i2 <= j){
        if(A[i1] < A[i2])
            temp[curr++] = A[i1++];
        else
            temp[curr++] = A[i2++];
    }
    while(i1 <= mid)
        temp[curr++] = A[i1++];
    while(i2 <= j)
        temp[curr++] = A[i2++];
    for(curr = i;curr <= j;curr++)
        A[curr] = temp[curr];
}

template<class Elem>
void mergesort(Elem A[],int sz)
{
    Elem *temp = new Elem[sz]();
    int i = 0,j = sz - 1;
    mergesortcore(A,temp,i,j);
    delete [] temp;
}
~~~

**性能：**

logn层递归中，每一层都需要O(n)的时间代价，因此总的时间复杂度是O(nlogn)，该时间复杂度不依赖于待排序数组中数值的相对顺序。因此，是最佳，平均和最差情况下的运行时间

由于需要一个和带排序数组大小相同的辅助数组，所以空间代价为O(n)

**优化：**

​	原地归并排序不需要辅助数组即可归并

![img](https://github.com/arkingc/note/raw/master/pic/al-sort-3.png)

~~~ C++
//将{2，3,4}插入{1,5}之间，类比考虑：排队站
//左子列翻转，右子列也翻转，从背面看，相当于是将{2,3,4}插入到了{1,5}的前面
//那么将整个序列翻转，则相当于从正面看将{2,3,4}插入到了{1,5}的前面
void reverse(int *arr,int n)
{
    int i = 0,j = n - 1;
    while(i < j)
        swap(arr[i++],arr[j--]);
}

void exchange(int *arr,int sz,int left)
{
    reverse(arr,left);//翻转左边部分
    reverse(arr + left,sz - left);//翻转右边部分
    reverse(arr,sz);//翻转所有
}

void merge(int *arr,int begin,int mid,int end)
{
    int i = begin,j = mid,k = end;
    while(i < j && j <= k){
        int right = 0;
        while(i < j && arr[i] <= arr[j])
            ++i;
        while(j <= k && arr[j] <= arr[i]){
            ++j;
            ++right;
        }
        exchange(arr + i,j - i,j - i - right);
        i += right;
    }
}
~~~



#### 8.堆排序（不稳定）

​	堆排序首先根据数组构建最大堆，然后每次“删除”堆顶元素（将堆顶元素移至末尾）。最后得到的序列就是从小到大排序的序列

![img](https://github.com/arkingc/note/raw/master/pic/al-sort-2.png)

~~~ C++
//直接使用c++ STL中堆的构建与删除函数
template <class Elem>
void heapsort(Elem A[],int n)
{
    Elem mval;
    int end = n;
    make_heap(A,A + end);
    for(int i = 0;i < n;i++){
        pop_heap(A,A + end);
        end--;
    }
}
~~~

~~~ C++
//如果不能使用库函数
/********************************************
 * 向堆中插入元素
 *  hole：新元素所在的位置
 ********************************************/
template <class value>
void _push_heap(vector<value> &arr,int hole){
    value v = arr[hole];//取出新元素，从而产生一个空洞
    int parent = (hole - 1) / 2;
    //建最大堆，如果建最小堆换成 arr[parent] > value
    while(hole > 0 && arr[parent] < v){
        arr[hole] = arr[parent];
        hole = parent;
        parent = (hole - 1) / 2;
    }
    arr[hole] = v;
}

/********************************************
 * 删除堆顶元素
 ********************************************/
template <class value>
void _pop_heap(vector<value> &arr,int sz)
{
    value v = arr[sz - 1];
    arr[sz - 1] = arr[0];
    --sz;
    int hole = 0;
    int child = 2 * (hole + 1); //右孩子
    while(child < sz){
        if(arr[child] < arr[child - 1])
            --child;
        arr[hole] = arr[child];
        hole = child;
        child = 2 * (hole + 1);
    }
    //当从父节点访问子节点时，只有左子节点，而没有右子节点的时候，会需要改if语句的判断
    //v一定会落在叶子节点
    if(child == sz){
        arr[hole] = arr[child - 1];
        hole = child - 1;
    }
    arr[hole] = v;
    _push_heap(arr,hole);
}

/********************************************
 * 建堆
 *  sz：删除堆顶元素后的大小
 *  v： 被堆顶元素占据的位置原来的元素的值
 ********************************************/
template <class value>
void _make_heap(vector<value> &arr)
{
    int sz = arr.size();
    int parent = (sz - 2) / 2;
    while(parent >= 0){
        int hole = parent;
        int child = 2 * (hole + 1); //右孩子
        value v = arr[hole];
        while(child < sz){
            if(arr[child] < arr[child - 1])
                --child;
            arr[hole] = arr[child];
            hole = child;
            child = 2 * (hole + 1);
        }
        if(child == sz){
            arr[hole] = arr[child - 1];
            hole = child - 1;
        }
        arr[hole] = v;
        _push_heap(arr,hole);
        --parent;
    }
}

template <class value>
void heap_sort(vector<value> &arr)
{
    _make_heap(arr);
    for(int sz = arr.size();sz > 1;sz--)
        _pop_heap(arr,sz);
}
~~~

**性能：**

​	根据已有数组构建堆需要O(n)的时间复杂度，每次删除堆顶元素需要O(logn)的时间复杂度，所以总的时间开销为，O(n+nlogn)，平均时间复杂度为O(nlogn)

​	注意根据已有元素建堆是很快的，如果希望找到数组中第k大的元素，可以用O(n+klogn)的时间，如果k很小，时间开销接近O(n)

**堆排序和快排的区别：**

1. 快排的思想是分治，每次选择当前范围的第一个数作为标杆，然后再将这个范围的所有比它小的数放到他左边，大的放到他右边，由这个标杆的现在位置划分出两个范围，分别对这两个范围的数再重复这样的***作，直到范围大小为1

2. 堆排序则是在建堆的时候保证堆顶最小，然后每次取堆顶



**外排序**

#### 1.多路归并

多路归并是**外部排序最常用**的算法：**将原文件分解成多个能够一次性装入内存的部分，分别把每一部分调入内存完成排序。然后，对已经排序的子文件进行归并排序**

![img](https://github.com/arkingc/note/raw/master/pic/al-kmerge.png)

**K的选择：**

假设总共m个子文件，每次归并k个子文件，那么一共需要归并 [![img](https://camo.githubusercontent.com/8bf57cfbb23c4f455a786d9102c8c0fe66f65ea3/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f25354325354324246c6f675f6b6d24)](https://camo.githubusercontent.com/8bf57cfbb23c4f455a786d9102c8c0fe66f65ea3/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f25354325354324246c6f675f6b6d24) 次（扫描磁盘），在k个元素中找出最小值（或最大值）需要比较k-1次。如果总记录数为N，所以时间复杂度就是 [![img](https://camo.githubusercontent.com/dab218cca7dc75a2a7c000fc10a9c87f176b82de/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f2535432535432424286b2d31294e6c6f675f6b6d3d25354366726163253742286b2d31292537442537426c6f676b2537444e6c6f676d24)](https://camo.githubusercontent.com/dab218cca7dc75a2a7c000fc10a9c87f176b82de/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f2535432535432424286b2d31294e6c6f675f6b6d3d25354366726163253742286b2d31292537442537426c6f676b2537444e6c6f676d24)， 由于 [![img](https://camo.githubusercontent.com/0afdb467eeddc91672e420c24fc3a1f911cc866b/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253543253543242425354366726163253742286b2d31292537442537426c6f676b25374424)](https://camo.githubusercontent.com/0afdb467eeddc91672e420c24fc3a1f911cc866b/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253543253543242425354366726163253742286b2d31292537442537426c6f676b25374424) 随k的增大而增大，所以比较次数的增加会逐步抵消“低扫描次数”带来的性能增益，所以对于k值的选择，主要涉及两个问题：

1. **每一轮归并会将结果写回到磁盘，那么k越小，磁盘与内存之间数据的传输就会越多，增大k可以较少扫描次数**
2. **k个元素中选取最小的元素需要比较k-1次，如果k越大，比较的次数就会越大**

**优化：**

可以利用下列方法**减少比较次数**：

1. **败者树**
2. **建堆**：使用一个k个元素的数组，第一次将k个文件中最小的元素读入数组（并且记录每个元素来自哪个文件），然后建最小堆，将堆顶元素删除，并从堆顶元素的源文件中取出下一个数，插入堆中，调整后重复上述操作。虽然第一次需要遍历k个文件取出最小元素，加上建堆需要一定时间，但是后续操作可以很快完成



#### 稳定性：

​	稳定性：相同的元素在排序前和排序后的前后位置是否发生改变，没有改变则排序是稳定的，改变则排序是不稳定的 

​	排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj，Ai原来在位置前，排序后Ai还是要在Aj位置前

(1)冒泡排序

冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。

(2)选择排序

选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n - 1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。

(3)插入排序 
插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。

(4)快速排序 
快速排序有两个方向，左边的i下标一直往右走，当a[i] <= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] > a[center_index]。如果i和j都走不动了，i <= j，交换a[i]和a[j],重复上面的过程，直到i > j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为5 3 3 4 3 8 9 10 11，现在中枢元素5和3（第5个元素，下标从1开始计）交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。

(5)归并排序 
归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素（认为直接有序）或者2个序列（1次比较和交换），然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。

(6)希尔排序(shell) 
希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。

(8)堆排序 
我们知道堆的结构是节点i的孩子为2 * i和2 * i + 1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n / 2开始和其子节点共3个值选择最大（大顶堆）或者最小（小顶堆），这3个元素之间的选择当然不会破坏稳定性。但当为n / 2 - 1， n / 2 - 2， ... 1这些个父节点选择元素时，就会破坏稳定性。有可能第n / 2个父节点交换把后面一个元素交换过去了，而第n / 2 - 1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。

综上，得出结论: **选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法**

reference：https://www.cnblogs.com/codingmylife/archive/2012/10/21/2732980.html



### 树

#### 1、最小生成树

最小生成树：在连通网的所有生成树中，所有边的代价和最小的生成树，称为最小生成树。

![img](https://upload-images.jianshu.io/upload_images/7398603-d307e91d05233322.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/592/format/webp)

生成最小树的算法：

​	1.Kruskal算法（加边）

![img](https://upload-images.jianshu.io/upload_images/7398603-f3abe060ddc905a8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

2.Prim算法（加点）

​	此算法可以称为“加点法”，每次迭代选择代价最小的边对应的点，加入到最小生成树中。算法从某一个顶点s开始，逐渐长大覆盖整个连通网的所有顶点。

![img](https://upload-images.jianshu.io/upload_images/7398603-a2ca453e871fa485.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/764/format/webp)

#### 2、哈夫曼树（最优生成树）

哈夫曼树又称最优二叉树。它是 n 个带权叶子结点构成的所有二叉树中，带权路径长度 WPL 最小的二叉树。

![img](https://upload-images.jianshu.io/upload_images/7398603-154752b58e45d780.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

注意：为了使得到的哈夫曼树的结构尽量唯一，通常规定生成的哈夫曼树中每个结点的左子树根结点的权小于等于右子树根结点的权。



* 哈夫曼树的应用：哈夫曼编码

例：如果需传送的电文为 ‘ABCACCDAEAE’，即：A, B, C, D, E 的频率（即权值）分别为0.36, 0.1, 0.27, 0.1, 0.18，试构造哈夫曼编码。

![img](https://images0.cnblogs.com/blog2015/682679/201504/071119483365384.png)

编码： A：11，C：10，E：00，B：010，D：011

出现频率越高的字符，编码长度越短，这样可以保证编码总长度越短

译码

从哈夫曼树根开始，对待译码电文逐位取码。若编码是“0”，则向左走；若编码是“1”，则向右走，一旦到达叶子结点，则译出一个字符；再重新从根出发，直到电文结束。

![img](https://images0.cnblogs.com/blog2015/682679/201504/071120393525832.png)

电文为 “1101000” ，译文只能是“CAT”



#### 3、二叉树+递归实现+迭代实现

两种特殊的二叉树

- **满二叉树**（下图左）：除叶子节点外的所有分支节点都含有2个非空子节点的二叉树
- **完全二叉树**（下图右）：除了最后一层，其余层都是“满”的，这样的二叉树是完全二叉树

![1558667961312](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558667961312.png)

* 前中后序遍历
  * **前序**遍历：根->左->右
  * **中序**遍历：左->根->右
  * **后序**遍历：左->右->根

* 代码实现

  * 递归版

  ~~~ C++
  //前序遍历
  void preorderTraversalRecursion(TreeNode *node)
  {
      if(!node) return;
      cout << node->val << " ";//操作当前节点
      preorderTraversalRecursion(node->left);
      preorderTraversalRecursion(node->right);
  }
  
  //中序遍历
  void inorderTraversalRecursion(TreeNode *node)
  {
      if(!node) return;
      inorderTraversalRecursion(node->left);
      cout << node->val << " ";//操作当前节点
      inorderTraversalRecursion(node->right);
  }
  
  //后序遍历
  void postorderTraversalRecursion(TreeNode *node)
  {
      if(!node) return;
      postorderTraversalRecursion(node->left);
      postorderTraversalRecursion(node->right);
      cout << node->val << " ";//操作当前节点
  }
  ~~~

  

  * 迭代版

  ~~~ C++
  //前序遍历
  void preorderTraversalIteration(TreeNode *root)
  {
      stack<TreeNode*> st;
      if(root)
          st.push(root);
  
      while(!st.empty()){
          TreeNode *nd = st.top();
          st.pop();
  
          cout << nd->val << " ";//操作当前节点
  
          if(nd->right)
              st.push(nd->right);
          if(nd->left)
              st.push(nd->left);
      }
  }
  
  //中序遍历：
  void inorderTraversalIteration(TreeNode *root)
  {
      stack<TreeNode*> st;
  
      TreeNode *curr = root;
  
      while(curr || !st.empty()){
          //把左子节点全部入栈
          if(curr){
              st.push(curr);
              curr = curr->left;
          }
          else{
              curr = st.top();
              st.pop();
  
              cout << curr->val << " ";//操作当前节点
  	        //左子节点全部入栈后，弹出的top节点时最左节点，继续访问该节点的right node，然后从该node开始，继续将左子节点入栈
              curr = curr->right;
          }
      }
  }
  
  //后序遍历
  void postorderTraversalIteration(TreeNode *root)
  {
      stack<TreeNode*> st;
      TreeNode *pre;
  
      if(root)
          st.push(root);
  
      while(!st.empty()){
          TreeNode *nd = st.top();
          /*
           * 出栈条件：
           * 对于叶子节点：直接弹出
           * 对于非叶子节点：如果已经遍历过其左子节点或右子节点，则弹出
           */
          //add by cy
          //因为入栈的顺序一定是根右左，那么弹出时，如果此时是node，且pre是node其中的一个孩子，则按照栈的顺序，node的孩子一定都弹出过了，所以符合左右根的顺序
          if((!nd->left && !nd->right) || (pre && (nd->left == pre || nd->right == pre))){
              st.pop();
              cout << nd->val <<" ";//操作当前节点
              pre = nd;
          }
          else{//说明是一个非叶子节点，并且还未访问其左右孩子
              if(nd->right)
                  st.push(nd->right);
              if(nd->left)
                  st.push(nd->left);
          }
      }
  }
  ~~~

  

#### 4、B树

​	B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构，让我们来看看他有什么特点

​	（1）排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则

​	（2）子节点数：非叶节点的子节点数>1，且<=M ，且M>=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；

​	（3）关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);

​	（4）所有叶子节点均在同一层

![preview](https://pic2.zhimg.com/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg)

- **B树的查询流程：**



如上图我要从上图中找到E字母，查找流程如下

（1）获取根节点的关键字进行比较，当前根节点关键字为M，E<M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）；

（2）拿到关键字D和G，D<E<G 所以直接找到D和G中间的节点；

（3）拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；

- **B树的插入节点流程**



定义一个5阶树（平衡5路查找树;），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来;

遵循规则：

（1）节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须<=5-1（这里关键字数>4就要进行节点拆分）；

（2）排序规则：满足节点本身比左边节点大，比右边节点小的排序规则;



先插入 3、8、31、11

![preview](https://pic4.zhimg.com/v2-e1d65c9c6236d4768c89e8e103e12583_r.jpg)

再插入23、29

![img](https://pic1.zhimg.com/80/v2-66cdb6187cbc5227fd8c4aabe7282e6c_hd.jpg)

再插入50、28

![img](https://pic1.zhimg.com/80/v2-3057eaab2b1764dd51c2a8658791cc98_hd.jpg)

- **B树节点的删除**



**规则：**



（1）节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数<2就要进行节点合并）；

（2）满足节点本身比左边节点大，比右边节点小的排序规则;

（3）关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放；

![img](https://pic2.zhimg.com/80/v2-a0f981fc847772cb28869927cd4fe66d_hd.jpg)

**特点：**

B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度



#### 5、B+树

​	B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。

​	

- **规则**

（1）B+跟B树不同B+树的**非叶子**节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个**非叶子**节点所能保存的关键字大大增加；

（2）B+树**叶子**节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；

（3）B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。

![img](https://pic4.zhimg.com/80/v2-5f069fd820637db1b877fdd6799a2b67_hd.jpg)
* **特点**

1、B+**树的层级更少**：相较于B树B+每个**非叶子**节点存储的关键字数更多，树的层级更少所以查询数据更快；

2、B+**树查询速度更稳定**：B+所有关键字数据地址都存在**叶子**节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;

3、B+**树天然具备排序功能：**B+树所有的**叶子**节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。

4、B+**树全节点遍历更快：**B+树遍历整棵树只需要遍历所有的**叶子**节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。

​	**B树**相对于**B+树**的优点是，如果经常访问的数据离根节点很近，而**B树**的**非叶子**节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比**B+树**快。



#### 6、B*树

* **规则**

  ​	B*树是B+树的变种，相对于B+树他们的不同之处如下：

  （1）首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b*树的初始化个数为（cei(2/3*m)）

  （2）B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；

* **特点**

  ​	在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少；

![img](https://pic3.zhimg.com/80/v2-e8bf8ee3230f3d39d59ce5e76a2ee32e_hd.jpg)

* **总结**

  **1、相同思想和策略**

  从平衡二叉树、B树、B+树、B*树总体来看它们的贯彻的思想是相同的，都是采用二分法和数据平衡策略来提升查找数据的速度；

  **2、不同的方式的磁盘空间利用**

  不同点是他们一个一个在演变的过程中通过IO从磁盘读取数据的原理进行一步步的演变，每一次演变都是为了让节点的空间更合理的运用起来，从而使树的层级减少达到快速查找数据的目的；

reference：https://zhuanlan.zhihu.com/p/27700617

### 图

#### 1、 图的表示

图有两种常用的表示方法：

- **邻接矩阵**

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-2.png)

​	(i,j)=1，表示顶点i到顶点j之间有一条边（**非带权图**）

​	(i,j)=n，表示顶点i到顶点j之间有一条权重为n的边（**带权图**）

- **邻接表**

![img](https://github.com/arkingc/note/raw/master/pic/al-graph-3.png)

​	数组的元素i表示顶点i的指针，它是一个链表的头结点

​	链表其余的顶点表示与顶点i之间存在边的顶点

#### 2、最短路径

![img](https://upload-images.jianshu.io/upload_images/7398603-6c9ef783b45ead77.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/719/format/webp)

初始状态：S是已计算出最短路径的顶点集合，U是未计算除最短路径的顶点的集合！
 第1步：将顶点D加入到S中。
 此时，S={D(0)}, U={A(∞),B(∞),C(3),E(4),F(∞),G(∞)}。     注:C(3)表示C到起点D的距离是3。

第2步：将顶点C加入到S中。
 上一步操作之后，U中顶点C到起点D的距离最短；因此，将C加入到S中，同时更新U中顶点的距离。以顶点F为例，之前F到D的距离为∞；但是将C加入到S之后，F到D的距离为9=(F,C)+(C,D)。
 此时，S={D(0),C(3)}, U={A(∞),B(23),E(4),F(9),G(∞)}。

第3步：将顶点E加入到S中。
 上一步操作之后，U中顶点E到起点D的距离最短；因此，将E加入到S中，同时更新U中顶点的距离。还是以顶点F为例，之前F到D的距离为9；但是将E加入到S之后，F到D的距离为6=(F,E)+(E,D)。
 此时，S={D(0),C(3),E(4)}, U={A(∞),B(23),F(6),G(12)}。

第4步：将顶点F加入到S中。
 此时，S={D(0),C(3),E(4),F(6)}, U={A(22),B(13),G(12)}。

第5步：将顶点G加入到S中。
 此时，S={D(0),C(3),E(4),F(6),G(12)}, U={A(22),B(13)}。

第6步：将顶点B加入到S中。
 此时，S={D(0),C(3),E(4),F(6),G(12),B(13)}, U={A(22)}。

第7步：将顶点A加入到S中。
 此时，S={D(0),C(3),E(4),F(6),G(12),B(13),A(22)}。

此时，起点D到各个顶点的最短距离就计算出来了：A(22) B(13) C(3) D(0) E(4) F(6) G(12)。



reference：https://www.jianshu.com/p/cb5af6b5096d



### 其他算法

#### 1、一致性hash算法原理与应用

* 背景：

  **Redis**是一个使用[ANSI C](https://zh.wikipedia.org/wiki/ANSI_C)编写的[开源](https://zh.wikipedia.org/wiki/%E5%BC%80%E6%BA%90)、支持[网络](https://zh.wikipedia.org/wiki/%E7%94%B5%E8%84%91%E7%BD%91%E7%BB%9C)、基于[内存](https://zh.wikipedia.org/wiki/%E5%86%85%E5%AD%98)、可选[持久性](https://zh.wikipedia.org/w/index.php?title=%E6%8C%81%E4%B9%85%E6%80%A7_(%E6%95%B0%E6%8D%AE%E5%BA%93)&action=edit&redlink=1)的键值对存储数据库，根据月度排行网站DB-Engines.com的数据，Redis是最流行的键值对存储数据库

  **redis的主从复制：**

  ​	redis的复制功能是支持多个数据库之间的数据同步。一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库

  ​	通过redis的复制功能可以很好的实现数据库的读写分离，提高服务器的负载能力。主数据库主要进行写操作，而从数据库负责读操作

  **主从复制过程：**

  ![img](https://img-blog.csdn.net/20160503192249524)

  注意：redis2.8之前的版本：当主从数据库同步的时候从数据库因为网络原因断开重连后会重新执行上述操作，不支持断点续传。

  redis2.8之后支持断点续传

  

  **redis集群：**

  ​	redis集群是一个无中心的分布式Redis存储架构，可以在多个节点之间进行数据共享，解决了Redis高可用、可扩展等问题。redis集群提供了以下两个好处

  1、将数据自动切分(split)到多个节点

  2、当集群中的某一个节点故障时，redis还可以继续处理客户端的请求

  **主要包括哈希*Slot*和节点主从**

  

  **Hashslot：**

  ​	一个 Redis 集群包含 16384 个哈希槽（hash slot），数据库中的每个数据都属于这16384个哈希槽中的一个。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽。集群中的每一个节点负责处理一部分哈希槽

  ​	

  **集群中的主从复制：**

  ​	集群中的每个节点都有1个至N个复制品，其中一个为主节点，其余的为从节点，如果主节点下线了，集群就会把这个主节点的一个从节点设置为新的主节点，继续工作。这样集群就不会因为一个主节点的下线而无法正常工作

  ![img](https://img-blog.csdn.net/20171113151113823?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveWVqaW5ndGFvNzAz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

   **使用hash分表分库带来的问题;**

  ​	使用普通Hash算法（hash(a.png) % 4 = 2）（4是redis服务器的个数）进行缓存时，会出现一些缺陷，主要体现在服务器数量变动的时候，所有缓存的位置都要发生改变！

  ​	从而诞生了hash一致性算法

  **hash算法：**

  ​	哈希算法是一致性哈希算法中重要的一个组成部分，你可以借助 Java 中的 `int hashCode()`去理解它。 说到哈希算法，你想到了什么？Jdk 中的 hashCode、SHA-1、MD5，除了这些耳熟能详的哈希算法，还存在很多其他实现，详见 [HASH 算法一览](https://www.oschina.net/translate/state-of-hash-functions)。可以将他们分成三代：

  - 第一代：SHA-1（1993），MD5（1992），CRC（1975），Lookup3（2006）
  - 第二代：MurmurHash（2008）
  - 第三代：CityHash， SpookyHash（2011）

  CRC、MD5、SHA1都是通过对数据进行计算，来生成一个校验值，该校验值用来校验数据的完整性

  reference：https://www.cnkirito.moe/consistent-hash-lb/

  

  **一致性hash算法：**

  ​	一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模，什么意思呢？简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下：

  ![img](https://pic1.zhimg.com/80/v2-fd44ab71c834f3fe458a6f76f3997f98_hd.jpg)

  ​	整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。

  ​	下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用IP地址哈希后在环空间的位置如下：

  ![img](https://pic1.zhimg.com/80/v2-509993a49d447b378273e455a095de3c_hd.jpg)

  ​	接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器！

  ​	例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：

  ![img](https://pic4.zhimg.com/80/v2-4fab60735dfae0bf511709e9d337789b_hd.jpg)

  ​	根据一致性Hash算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。

  **一致性hash算法的容错性和可扩展性：**

  ​	现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响，如下所示：

  ![img](https://pic1.zhimg.com/80/v2-4ebcb8c23bb64a60896bde87dd546214_hd.jpg)

  下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：

  ![img](https://pic2.zhimg.com/80/v2-9cdb1adc37eb1a54c114232120da1485_hd.jpg)

  ​	此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X ！一般的，在一致性Hash算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。

  ​	综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

  

  **Hash环的数据倾斜问题**

  ​	一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下：

  ![img](https://pic3.zhimg.com/80/v2-d499324a9aa067915bbb3f5f3416b032_hd.jpg)

  ​	此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。

  ​	例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：

  ![img](https://pic3.zhimg.com/80/v2-0368841e5020dd07f1e67f449b49a1ba_hd.jpg)

  ​	同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

  reference：https://blog.csdn.net/tanqian351/article/details/79262618

  reference：https://blog.csdn.net/u011204847/article/details/51307044

  reference：https://zhuanlan.zhihu.com/p/34985026（总概）

  

#### 2、背包算法





## 数据结构相关问题

1、栈在实际编程的时候有哪些应用场景

 	1. 逆序输出
 	2. 语法检查，符号成对出现
 	3. 数制转换：比如100的八进制，100首先除以8商12余4,4首先进栈，然后12除以8商1余4，第二个余数4进栈，接着1除以8，商0余1，第三个余数1进栈，最后将三个余数出栈，就得到了100的八进制数144
 	4. 函数调用栈

reference：https://blog.csdn.net/kuangsonghan/article/details/79499380



2、堆和栈的区别
	堆是一颗二叉树、栈是一个单向进出的线性结构



3、如何用数组实现链表的功能

​	数组中存放一个结构体，一个表示数据，另外一个表示其下一个节点在数组中的index，以便于快速插入删除



4、用数据结构模拟浏览器前进后退的操作

​	问题描述：假如当你依次访问完一串页面a-b-c之后，点击浏览器的后退按钮，就可以查看之前浏览的页面b和a,当你后退到a,点击前进按钮，就可以重新看到页面b和c。但是，如果你后退到b后，点击了新的页面d,那就无法再通过前进、后退功能查看页面c了

**解答：**

​	我们使用两个栈，X和Y，我们把首次浏览的页面依次压入栈x,当点击后退时，在依次从X中出栈，并将出栈的数据依次放入栈Y。当我们点击前进按钮时，我们依次从栈Y中取出数据，放入栈X中。

​	比如我们按顺序a , b ,c 三个页面，我们就依次把a b c 压入栈，这个时候，栈的数据如下图

![å¾](https://img-blog.csdnimg.cn/2019030722141529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbG9nZW5pdXM=,size_16,color_FFFFFF,t_70)

当我们通过浏览器的后退按钮，从页面c后退到页面a之后，我们就依次把c和b 从栈X种弹出，并且依次放入栈y。这个时候，两个栈的数据就是这个样子：

![img](https://img-blog.csdnimg.cn/20190307221439844.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbG9nZW5pdXM=,size_16,color_FFFFFF,t_70)

这个时候你又想看页面b,于是点击前进按钮回到b页面，我们就把b从栈Y中出栈，放入栈X中，此事两个栈的数据如下图

![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20190307221522760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbG9nZW5pdXM=,size_16,color_FFFFFF,t_70)

这个时候，你通过页面b又跳转到新的页面b，页面c就无法再通过前进，后退按钮重复查看了，所以清空栈Y，此时两个栈的数据这个样子：

![å¨è¿éæå¥å¾çæè¿°](https://img-blog.csdnimg.cn/20190307221536304.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbG9nZW5pdXM=,size_16,color_FFFFFF,t_70)

reference：https://blog.csdn.net/Milogenius/article/details/88045802



5、哈希表 如何实现 冲突解决
	整个hashtable由vector和linked_list组合而成

​	解决冲突的方法：线性探测、二次探测、开链法



6、图如何表示，图广度遍历用什么结构

​	邻接矩阵、邻接表

​	广度遍历用什么结构：如下，但我本人认为可以用邻接表做图的广度遍历会更简单吧

~~~ C++
//在邻接矩阵下，图的广度遍历算法

/*
广度优先搜索
从vertex开始遍历，visit是遍历顶点的函数指针
*/
void Graph::bfs(int vertex, void(*visit)(int))
{
	//使用队列
	queue<int> q;
	//visited[i]用于标记顶点i是否被访问过
	bool *visited = new bool[numV];
	//count用于统计已遍历过的顶点数
	int i, count;
	for (i = 0; i < numV; i++)
		visited[i] = false;
	q.push(vertex);
	visit(vertex);
	visited[vertex] = true;
	count = 1;
	while (count < numV)
	{
		if (!q.empty())
		{
			vertex = q.front();
			q.pop();
		}
		else
		{
			for (vertex = 0; vertex < numV && visited[vertex]; vertex++);
			visit(vertex);
			visited[vertex] = true;
			count++;
			if (count == numV)
				return;
			q.push(vertex);
		}
		//代码走到这里，vertex是已经访问过的顶点
		for (int i = 0; i < numV; i++)
		{
			if (!visited[i] && matrix[vertex][i] > 0 && matrix[vertex][i] < MAXWEIGHT)
			{
				visit(i);
				visited[i] = true;
				count ++;
				if (count == numV)
					return;
				q.push(i);
			}
		}
	}
	delete[]visited;
}

原文：https://blog.csdn.net/zhangxiangDavaid/article/details/38323633 
~~~



7、vector越界访问下标

~~~ C++
std::vector<int> list;
for (int i = 0; i < 5; i++) {
  list.push_back(i);
}
for (int i = 0; i < 6; i++) {
  std::cout << list[i];
}
~~~

​	首先以上的代码可以正确编译通过并运行的，不过list[5]是0，在vector中，如果通过[i]下标访问元素，是不会进行越界检查的。所以一般情况不要通过下标来直接访问，建议使用

~~~ c++
list.ai[i];    //返回索引idx所指的数据，如果idx越界，抛出out_of_range。
~~~



8、map越界访问下标

​	map元素访问 对于map使用下标操作，如果该关键字不存在容器，容器则会添加该关键字到容器中 用find来代替下标操作

~~~ C++
auto it = maps.find(id);
 if (it == maps.end())  //not find
~~~



9、深度优先遍历和广度优先遍历的应用场景

​	递归主要体现了深度优先 遍历的思想

​	迭代主要体现了广度优先遍历的思想



10、如何删除map中的奇数节点

~~~ C++
void initMap(map<int, int>& m, int arr[], int arrLen)
{
	for(int i = 0; i < arrLen; i++)
		m[i] = arr[i];
}
 
void Remove_map(map<int, int>& m)
{
	map<int, int>::iterator it;
 
	for(it = m.begin(); it != m.end();)
	{
		if (it->second %2 ！= 0)
			m.erase(it++);
		else
			it++;
	}
}

原文：https://blog.csdn.net/JoeBlackzqq/article/details/40623149 
~~~



11、 如何设计一个线程安全的hashmap

**线程安全：**

​	线程安全就是如果你的代码块所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。

​	如果代码块中包含了对共享数据的更新操作，那么这个代码块就可能是非线程安全的。但是如果代码块中类似操作都处于临界区之中，那么这个代码块就是线程安全的。

​	通常有以下两类避免竞争条件的方法来实现线程安全



链接：https://juejin.im/post/59d8d7cc6fb9a00a496e93b2





 ## 海量数据问题

#### 1、两个文件共同的url

可以估计每个文件的大小为5Gx64B=320GB，远远大于内存限制的4GB。所以不可能将其完全加载到内存中处理。考虑分治法

1. 遍历文件a，对每个url求取hash(url)%1024，然后根据所取得的值将url分别存储到1024个小文件中，这样每个小文件大约为300MB

> - **为什么要做hash**？每个文件中可能包含相同的url，同一文件中相同的url可能分布在同一文件的不同位置。不同文件中相同的url可能也分布在不同位置。hash可以保证相同url映射到同一个小文件中
> - **为什么是1024个小文件**？这里1024应该不是唯一值，分成1024个小文件，每个只有300多M，在后面查找过程中，将小文件中的url存储set时不会超过4G的限制

1. 遍历文件b，采取和a相同的方式，将url分别存储到1024个小文件中。这样处理后，所有可能相同的url都在对应的小文件[(a0,b0),(a1,b1),...,(a1023,b1023)]中，不对应的小文件不可能有相同的url（**也就是hash的目的**）
2. 求出1024对小文件中相同的url：把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url



#### 2、按频率排序多个文件中的query记录

有10个文件，每个文件1GB，每个文件的每一行存放的都是用户的query，每个文件中的query都有可能重复。请按照query的频度排序

1）方案一

顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件中，记为[a0,a1,...,a9]，这样新生成的文件每个大小约为1GB

找到一台内存在2GB左右的机器，依次对[a0,a1,...,a9]用hash_map(query,query_count)来统计每个query出现的次数，并利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_count输出到文件中。这样得到了10个排好序的文件，记为[b0,b1,...,b9]。对这10个文件进行归并排序（可利用败者树进行多路归并）

2）方案二

一般query的总量是有限的，只是重复的次数比较多，若所有的query一次性就可以加入到内存中，就可以采用Trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序



#### 3、找出文件中频率最高的100个词

有一个1GB大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1MB。返回频数最高的100个词

**解答:**

采用分治的思想

顺序读文件，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件中，记为[x0,x1,...,x4999]。这样每个文件为200KB左右（**如果文件里面全是同一个词？**）。如果其中有的文件超过了1MB，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1MB

对每个小文件，统计每个文件中出现的词以及相应的频度（可以采用Trie树或hash_map等），并分别取出出现频度最大的100个词（可以用含100个结点的最小堆），并把这100个词及相应的频率存入文件，这样又得到了5000个有序(逆序)文件（每个文件有100个词）。下一步就是把这5000个文件进行归并排序（可利用败者树采用多路归并）



#### 4、海量日志中提取访问百度次数最多的IP

海量日志数据，提取出某日访问百度次数最多的那个IP，假设当前机器可用内存较小，无法一次性读入日志文件

**解答**

采用分治的思想

使用hash(ip)%n将日志记录分到n个小文件中，在每个小文件中使用hash_map的方法统计每个ip的频度，再利用堆排序按频度对ip进行排序：

1. IP地址最多有2^32=4G种可能的取值，按照IP地址的hash(IP)%1024值，将海量日志存储到1024个小文件中。每个小文件最多包含4M个IP地址
2. 对于每个小文件，可以构建一个IP作为key，出现次数作为value的hash_map，并记录当前出现次数最多的1个IP地址
3. 有了1024个小文件中的出现次数最多的IP，就可以得到总体上出现次数最多的IP



#### 5、实现位图

实现Bit-map，要求能够表示的最大值为10,000,000

**解答:**

位图(Bit-map)的原理就是使用位数组来表示某些元素是否存在，由于采用了bit为单位来存储数据，因此在存储空间方面，可以大大节省，故适用于海量数据的快速查找、判断、删除等

假设数值范围是[0,7]，有5个元素(4,7,2,5,3)。需要对这5个元素排序，如果使用位图来排序，总共需要8位，因为0~7一共8个数字，处理步骤如下：

- **设置位图状态**：遍历数组，如果包含0~7中某个元素，则设置位图8个位中相应的位为1
- **遍历位图，输出结果**：遍历位图，输出排序结果

![img](https://github.com/arkingc/note/raw/master/pic/al-bitmap.png)

- 假设有100亿个数(10,000,000,000)，如果使用int(4字节)数组实现位图，每个int可以表示32个数，那么可以使用100亿/8，大约1GB左右的空间就能存下所有100亿个数（此处100亿/32指代的是对应多少个int的空间,/8指代的是对应多少个（一个字节）的空间）
- **注意，由于位图每位只有0和1，所以只能表示1个元素是否存在，如果数组包含相同元素，位图没有办法记录。位图很适合在海量数值中查找某个数值是否存在。如果希望用位图记录一个数字是否多次出现，可以用2bit位图（00不存在，01存在，10出现多次，11无意义）**

~~~ C++
#define BITWORD 32
#define SHIFT 5   
#define MASK 0x1F //000..0011111(31)
#define N 10000000

int a[1+N/BITWORD];//一个int 32位（32位、64位平台）

/*将第i位设置为1，i>=0*/
void set(int i)
{
    //右移1位相当于除以2，右移SHIFT位相当于除以2^5=32，a[i >> SHIFT]相当于找到了i所在的那个int数组中的元素（32位）
    //i & MASK相当于 i % 32得到余数，1 << (i & MASK)将从右至左的(i & MASK)偏移量位设为1
    //不太理解此处？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？
    a[i >> SHIFT] |= (1 << (i & MASK));
}

/*将第i位设置为0*/
void clr(int i)
{
    //右移1位相当于除以2，右移SHIFT位相当于除以2^5=32，a[i >> SHIFT]相当于找到了i所在的那个int数组中的元素
    //1 << (i & MASK)是i的bit位偏移位置，对其取反就是该位置为0，其余位置为1
    a[i >> SHIFT] &= ~(1 << (i & MASK));
}

/*返回第i位的状态*/
int test(int i)
{
    return a[i >> SHIFT] & (1 << (i & MASK));
}
~~~



#### 6、统计不同号码的个数

已知某文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数

**解答**

8位数字表示的最大数为99999999，可以理解为从[0,99999999]的数字，用位图解决，则每个数字对应一个bit，只需要约12MB，依次读入每个号码，然后将位图相应位置设为1，最后统计位图中1的位数的个数



#### 7、查找某个数是否在40亿个数当中

给40亿个不重复的unsigned int的整数，没排过序，然后再给一个数，如何快速判断这个数是否在40亿个数当中？

**解答**

unsigned int最多有2^32个数，用位图的方法，申请512MB的内存，一个bit位代表一个unsigned int，读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在

（40亿/32   * 4B = 512M）



#### 8、2.5亿整数中只出现一次的整数

在2.5亿个整数中找出只出现一次的整数，内存不足以容纳这2.5亿个整数

**解答**

**方案一**：采用2bit位图（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义），共需内存(2^32)*2bit=1GB内存，然后依次扫描2.5亿个整数，查看Bitmap中对应位，如果是00则变为01，01变为10，10保持不变。扫描结束后，查看bitmap，把对应位是01的整数输出

（一个整数占32位，共有2的32次方种整数，一个整数用2bit来描述，所以所占内存大小计算如上）

**方案二**：也可以采用Hash映射的方法，划分成多个小文件。然后在小文件中利用hash_map找出不重复的整数



#### 9、布隆过滤器

布隆过滤器可视为对位图的扩展

如果需要判断一个元素是否在一个集合中，位图的做法是申请一个N位（N为集合中最大整数）的数组，然后每一位对应一个特定整数

布隆过滤器的基本原理是位数组与Hash函数联合使用。具体而言，布隆过滤器是一个包含了m位的位数组，数组的每一位都初始化为0。然后定义k个不同的Hash函数，每个Hash函数都可以将集合中的元素映射到位数组中的某一位

**插入**：当向集合中插入一个元素时，根据k个Hash函数可以得到位数组中的k个位，将这些位全部设置为1

**查询**：当要查询某个元素是否属于集合时，就使用k个哈希函数得到此元素对应的k个位，如果所有点都是1，那么判断为元素在集合内（**注意，这种情况下只能说明元素可能在集合内，并不一定**），如果有0，则元素不在集合内（**因此，其实布隆过滤器的思想是“宁可误杀也不放过”，适用于黑名单网站的查询**）

![img](https://github.com/arkingc/note/raw/master/pic/al-bloomfilter.png)

插入元素时，对任意一个元素x，第i个哈希函数映射的位置hi(x)会被置为1（1<=i<=k）

> **布隆过滤器的位数m通常要比集合中的最大元素小的多，可见，布隆过滤器是一种空间效率和时间效率很高的随机数据结构，但这种高效是有一定代价**：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合。因此，布隆过滤器不适合那些“零错误”应用场合，而在能容忍低错误率的应用场合下，布隆过滤器通过极少的错误换取了存储空间的极大节省



#### 10、倒排索引

**倒排索引**也常被称为**反向索引**、**置入档案**、**反向档案**，是一种索引方法，用来存储在全文检索下某个单词在一个文档或者一组文档中的存储位置的映射。是**文档检索系统中最常用**的数据结构

> 适用范围：搜索引擎的关键字查询

假设存在3个文本T0、T1、T2：

```
T0 = "it is what it is"
T1 = "what is it"
T2 = "it is a banana"
```

能够得到下面的反向文件索引：

```
"a"：{2}
"banana"：{2}
"is"：{0,1,2}
"it"：{0,1,2}
"what"：{0,1}
```

当用户检索的条件为"what"、"is"和"it"时，将分别查询这三个关键词对应的文本集合，然后求对应集合的交集。可见，倒排索引在处理复杂的多关键字查询时，可在倒排表中先完成查询的并、交等逻辑运算，得到结果后再对记录进行存取

> 倒排索引是相对正向索引而言的，正向索引是用来存储每个文档的单词的列表、在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档







## 经典问题

1、玻璃球问题（有网友说是典型的鹰蛋问题吧）



## 手撕代码

1、给一容量较大非法单词词典，如何判断某输入中是否有非法单词

建立字典树--实现一次遍历就可做出判断

3、文件中有大量数字，排序并保存到结果文件中

4、浮点数判断是否相等

5、字符串循环移位 面试官让优化复杂度 没想出来(要用到上一题的字符串反转)

6、统计一篇英文文章出现频率最高的十个单词

7、Q：象棋中马从一个位置跳到另一个位置的最少步数
A：手写BFS

８、一个数组，只有一个数字出现奇数次，其余数字出现偶数次，如何得到这个数字？如果出现奇数次的数字有2个呢？

９、给定一个ip地址，编码使得ip和32位整数呈双射关系

10、1个32位无符号整数，计算二进制格式下有多少个1，不通过循环怎么做

11、A-H中选3个字母，可以重复，求组合数

12、a,b两个文件，a文件存url，有1亿行。b文件存域名，有 1万行。  要求：找出a中不在b文件中的？时间复杂度是多少？  没有内存限制。

回答：1.先提取a文件的url中的域名（这个不会，是用awk吗？）2.hash+字典树。       时间复杂度有老铁会的吗？

13、函数值传递一个百万个元素的vector会怎么样？为什么?

14、一个二维地图，每个格子有不同分数，求机器人从左下到右上的最大分数的路径

15、求一个数组逆序对

17、手撕代码-输出字符串中最长的回文子串长度？

18、手撕代码int atoi(char *str)？

19、数组存中在一个大于n/2次的数，如何以最优方法查找它？

20、用栈实现队列，用队列实现栈？

21、  开始了算法，先问我二叉树学过吗，然后让我设计一个节点，再然后让我比较两棵树是否相同（手写代码）。现在我才明白，大概是在考我用递归怎么遍历树，我当时写的居然是以按层遍历的方式去遍历树，然后两棵树逐个节点作对比。  



24、链表倒转

25、1G内存，4G url，求重复的url

26、如果把访问次数过多的IP拉入黑名单，怎么实现，用什么数据结构，写个伪码

27、来一条设计题。百度搜索的智能提示怎么实现，输入两个字，出来一些热搜

A：字典树+堆吧，然后balabala（第三次。。。感觉面试官不是很满意我的答案)

28、实现一个功能，能检测内存泄漏问题，通过一个指令输出整个进程中哪一行哪个函数申请了多少内存，按照顺序排列出来，还有总的内存数

29、求一个数开根号（二分）

# 智力题

1、50个红球50个蓝球，放到2个袋子里，从两个袋子各取1个球，让2个都是红球的概率最大，怎么放

2、64匹马、8赛道，知识多少轮比赛找出速度最快的4匹马？（在提示下优化到12次，最优解为10或者11次）

3、1瓶毒药999瓶无毒，10只青蛙

4、一栋楼，有136层，给你两个弹珠，测出弹珠在第几层刚好摔破，弹珠摔破后，不可再使用

5、100层楼摔砖石

在一个平面直角坐标系中，有一只蚂蚁从原点开始走，只可以向右边（与X正半轴平行）和上边（与Y轴正半轴平行）爬行，要到达（x,y）坐标，请问有几种走法，推导出一个公式。（开始 时候还没明白面试官的意图，然后我就一直在想，后面我想到是斐波那契数列，然后面试官说我的方向是对的，后面经过无数次提示终于推导出了公式）  



# 网络

## 网络与Linux网络编程

**网络协议模型（我说的是五层模型）**

**如果是五层模型，在下图的基础上添加一层物理层即可**



![1564995319990](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564995319990.png)

![1564995363903](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564995363903.png)

![1564995406694](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564995406694.png)

![1564995497960](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564995497960.png)



### TCP、UDP

#### **1、tcp、udp简述**

TCP是面向连接的可靠的传输层协议，是数据流服务

1. 面向连接
   * 使用TCP协议通信的双方必须先建立连接，然后才能开始数据的读写，双方都必须为该连接分配必要的内核资源，以管理连接的状态和连接上数据的传输
   * 该连接是一对一的，所以不能广播和多播
2. 可靠
   * TCP协议采用发送应答机制，即发送端发送的每个TCP报文段都必须得到接收方的应答后，才认为这个TCP报文段传输成功
   * TCP协议采用超时重传机制，如果在给定时间内未收到应答，他将重发该报文段

![1555406449088](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1555406449088.png)



**TCP编程的服务器端一般步骤是： **
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt(); * 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 
　　4、开启监听，用函数listen()； 
　　5、接收客户端上来的连接，用函数accept()； 
　　6、收发数据，用函数send()和recv()，或者read()和write(); 
　　7、关闭网络连接； 
　　8、关闭监听； 

**TCP编程的客户端一般步骤是： **
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 
　　4、设置要连接的对方的IP地址和端口等属性； 
　　5、连接服务器，用函数connect()； 
　　6、收发数据，用函数send()和recv()，或者read()和write()

​       7、关闭网络连接；



UDP是不可靠的传输层协议，是数据报服务

1. 因为UDP是不可靠服务，所以需要上层协议来处理数据确认和超时重传

![1555406637722](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1555406637722.png)

与之对应的UDP编程步骤要简单许多，分别如下： 
　　UDP编程的服务器端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind(); 
　　4、循环接收数据，用函数recvfrom(); 
　　5、关闭网络连接； 

UDP编程的客户端一般步骤是： 
　　1、创建一个socket，用函数socket()； 
　　2、设置socket属性，用函数setsockopt();* 可选 
　　3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 
　　4、设置对方的IP地址和端口等属性; 
　　5、发送数据，用函数sendto(); 

​        6、关闭网络连接；



**TCP与UDP的基本区别**

* TCP面向连接，UDP是无连接的，即发送数据之前不需要建立连接

* TCP提供可靠的服务。TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）

* 从细节来说，TCP的内核区域会备份用户层的应用数据，从而保证当发生丢包时，可以进行重发，但是UDP对应的内核区域不会备份用户层的数据。

* TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流，UDP是面向报文的
    
    
* 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

    
---------------------


编程时的区别：

* socket()的参数不同 
* UDP Server不需要调用listen和accept 
* UDP收发数据用sendto/recvfrom函数 
* TCP：地址信息在connect/accept时确定 
* UDP：在sendto/recvfrom函数中每次均 需指定地址信息 
* UDP：shutdown函数无效





#### **2、画出TCP报文三次握手的图 **

![1564970445919](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564970445919.png)

- **序号(seq)** ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。
- **确认号** (ack)：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
- **数据偏移** ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
- **确认 ACK** ：当 ACK=1 时确认号(ack)字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
- **同步 SYN** ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。
- **终止 FIN** ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
- **窗口** ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

![1564970499614](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564970499614.png)

假设 A 为客户端，B 为服务器端。

- 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
- A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
- B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
- A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
- B 收到 A 的确认后，连接建立。

**三次握手的原因**

第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。





**TCP三次握手的状态装换图**

![1555412527487](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1555412527487.png)

**三次握手：**

　　第一次握手：客户端发送syn包（syn=x）的数据包到服务器，并进入SYN_SEND状态，等待服务器确认；

　　第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

　　第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=y+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

　　握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP连接都将被一直保持下去。

**四次握手：**

　　第一次挥手：主动关闭方发送一个FIN，用来关闭主动方到被动关闭方的数据传送，也就是主动关闭方告诉被动关闭方：我已经不会再给你发数据了(当然，在fin包之前发送出去的数据，如果没有收到对应的ack确认报文，主动关闭方依然会重发这些数据)，但是，此时主动关闭方还可以接受数据。

　　第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号）。
　　第三次挥手：被动关闭方发送一个FIN，用来关闭被动关闭方到主动关闭方的数据传送，也就是告诉主动关闭方，我的数据也发送完了，不会再给你发数据了。
　　第四次挥手：主动关闭方收到FIN后，发送一个ACK给被动关闭方，确认序号为收到序号+1，至此，完成四次挥手。

![1555412560478](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1555412560478.png)

![1555412596297](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1555412596297.png)

**CLOSED:** 这个没什么好说的了，表示初始状态。

**LISTEN**（服务器）: 这个也是非常容易理解的一个状态，表示服务器端的某个SOCKET处于监听状态，可以接受连接了。

**SYN_RCVD**（服务器）: 这个状态表示接受到了SYN报文，在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，很短暂，基本上用netstat你是很难看到这种状态的，除非你特意写了一个客户端测试程序，故意将三次TCP握手过程中最后一个ACK报文不予发送。因此这种状态时，当收到客户端的ACK报文后，它会进入到ESTABLISHED状态。

**SYN_SENT**: 这个状态与SYN_RCVD遥想呼应，当客户端SOCKET执行CONNECT连接时，它首先发送SYN报文，因此也随即它会进入到了SYN_SENT状态，并等待服务端的发送三次握手中的第2个报文。SYN_SENT状态表示客户端已发送SYN报文。

**ESTABLISHED**：这个容易理解了，表示连接已经建立了。

**FIN_WAIT_1**: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。

**FIN_WAIT_2**：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你，稍后再关闭连接。

**TIME_WAIT**: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。

　　**注:MSL(最大分段生存期)指明TCP报文在Internet上最长生存时间,每个具体的TCP实现都必须选择一个确定的MSL值.RFC 1122建议是2分钟,但BSD传统实现采用了30秒.TIME_WAIT 状态最大保持时间是2 \* MSL,也就是1-4分钟.**

　　**结论：在TIME_WAIT下等待2MSL，只是为了尽最大努力保证四次握手正常关闭。确保老的报文段在网络中消失，不会影响新建立的连接.**

 

**CLOSING**: 这种状态比较特殊，实际情况中应该是很少见，属于一种比较罕见的例外状态。正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，并没有收到对方的ACK报文，反而却也收到了对方的FIN报文。什么情况下会出现此种情况呢？其实细想一下，也不难得出结论：那就是如果双方几乎在同时close一个SOCKET的话，那么就出现了双方同时发送FIN报文的情况，也即会出现CLOSING状态，表示双方都正在关闭SOCKET连接。

**CLOSE_WAIT**: 这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。

LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。



### **思考：**

#### **1、 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？**　　

​	这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可能未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

#### **2、 三次握手的原因**

第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。



#### **3.如果TCP第三次握手中的ack包丢失会怎么办？**

Server 端

    第三次的ACK在网络中丢失，那么Server 端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便Client重新发送ACK包。
    
    而Server重发SYN+ACK包的次数，可以通过设置/proc/sys/net/ipv4/tcp_synack_retries修改，默认值为5.
    
    如果重发指定次数之后，仍然未收到 client 的ACK应答，那么一段时间后，Server自动关闭这个连接。



Client 端

    在linux c 中，client 一般是通过 connect() 函数来连接服务器的，而connect()是在 TCP的三次握手的第二次握手完成后就成功返回值。也就是说 client 在接收到 SYN+ACK包，它的TCP连接状态就为 established （已连接），表示该连接已经建立。那么如果 第三次握手中的ACK包丢失的情况下，Client 向 server端发送数据，Server端将以 RST包响应，方能感知到Server的错误。
---------------------
作者：gochenguowei 
来源：CSDN 
原文：https://blog.csdn.net/gochenguowei/article/details/79649997 
版权声明：本文为博主原创文章，转载请附上博文链接！



#### **4、 如果TCP三次握手中，不断向server端发送SYN连接请求会怎么样？**

​		如果在已成功建立连接的情况下，client持续发送SYN的话，server会不停响应，但是client在收到这个响应后，因为已经建立连接了，所以会自动忽略这个信息，但是在这个过程中，server在不停的接收SYN请求，并作出响应，server的协议栈和缓存会不停保存每次信息，对server的资源造成消耗

​		如果现在还没有建立连接，安全问题，客户端持续发大量连接syn，但故意不发ack，也不发数据，那这个就是简单直接的Syn洪水攻击了，这个就属于安全问题了。



#### **5、TCP 滑动窗口**

​		窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

​		发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

​		接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

![1565052628908](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1565052628908.png)

#### **6、TCP 流量控制**

​		流量控制是为了控制发送方发送速率，保证接收方来得及接收。

​		接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。



#### **7、TCP 拥塞控制**

​		如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

​		TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

​		发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

为了便于讨论，做如下假设：

- 接收方有足够大的接收缓存，因此不会发生流量控制；
- 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。



**慢开始与拥塞避免**

发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。



**快重传与快恢复**

在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

![1565053212606](F:\NoteBook_MD\work_hunting\1565053212606.png)

#### **8、TIME_WAIT**

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

- 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
- 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。



3、 timewait过程如果出现过多拥塞或者网络不稳定导致很多非正常数据该如何解决？



6、DDOS，怎么解决，如何让Server端收到ACK后在分配资源，不改变Client，不封装IP数据包

7、最后答了一下客户端处于TIME_WAIT状态要等2个MSL才会close



![1564971213113](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1564971213113.png)



12、.TCP端口扫描方式

13、TCP已经提供了数据校验了，为什么网上下载一些文件还需要md5之类的来检测数据

A:https://blog.csdn.net/bjrxyz/article/category/6895078

14、UDP发送1M数据怎么发送

 TCP UDP 端口扫描 三次握手中 客户端和服务端主动链接关闭所处状态简述







多个进程同时监听一个UDP端口会怎么样？

A：不懂……

- TCP中的握手与ddos等相关问题

  

存在大量closed_wait有什么危害
4、send函数什么情况下会阻塞

**TCP的粘包怎么解决？**

针对TCP三次握手的缺点可能有什么危害？

blabla......我说了SYN攻击，半连接队列...



### ARP

**1、ARP是什么**

2、ARP解析过程



### DNS

**1.DNS解析过程**





### 网络编程

1、linux网络编程：服务器端接收多个客户端发来的数据，该如何接收

2、 手写判断大小端的代码

3、项目中使用网络编程？简单说下？说下cgi？服务器采用什么结构？使用的epoll模型？

2）epoll（）是用单线程实现（我说是单线程，I/O复用不需要多线程吧）

3）如何及时发现客户端已经和服务器断开连接了（我说的心跳机制）



### 信号

1、linux下有哪些信号

### HTTP

1、https中的pipeline?多个相同请求的时候一次返回

2、http网址访问过程，get post区别，谈到get、post了，get和post的原理和区别？

3、.输入url的过程，知道的协议都说说，IP路由选路，ARP等等

4、http https区别，直到http和http2区别？熟悉https，https中加密实在哪一过程进行了？

5、HTTPS的安全性是怎么实现的？

6、HTTP有哪几种操作？

7、输入[www.baidu.com](http://www.baidu.com/)在浏览器的完整过程，越详细越好

8、HTTP中状态码 302(详细问) 403 400

9、http https 抓包工具原理

10、如何去处理高并发HTTP请求？  

  我: 从接入层(统一接入网关，负载均衡)…..从服务层(服务细分，过载保护)…..从存储层(cache,共享内存，分布式存储组件ceph)……  

  在服务层回答到 过载保护的时候。被打断。 他说你说的过载保护不过是在请求很多的时候去拒绝掉一部分用户。或者延时处理。那么 现在如果出现一个热点事件，百度的搜索可能会达到数十亿次，你去拒绝掉这一部分用户。那这一部分用户的用户体验怎么保证？   

  在存储层回答ceph 分布式存储组件的时候 被问到了映射 为什么ceph要去做三层映射？  

  面试官: 你有没有考虑过流量不干净的情况怎么办？ 用很简单的ddos攻击，你这个服务 我1分钟之内就能让他趴下。这个你考虑过吗？  

  面试官: 你这个底层本质上还是用队列做的。你有没有考虑过队列全满的情况？就是现在你的所有队列全部爆满，你根本没有办法去做请求迁移。这时候怎么处理？

微信获取权限的协议？（这个在百度问到了，后来在阿里又问到了，大家可以搜一下基于token 的后台管理 与普通用户名密码验证有什么具体不同）



#### 1、HTTP长连接 、long polling

数据交互有两种模式：Push（推模式）、Pull（拉模式）。

推模式指的是客户端与服务端建立好网络长连接，服务方有相关数据，直接通过长连接通道推送到客户端。其优点是及时，一旦有数据变更，客户端立马能感知到；另外对客户端来说逻辑简单，不需要关心有无数据这些逻辑处理。缺点是不知道客户端的数据消费能力，可能导致数据积压在客户端，来不及处理。

拉模式指的是客户端主动向服务端发出请求，拉取相关数据。其优点是此过程由客户端发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对客户端来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。



**Polling：**Polling是指不管服务端数据有无更新，客户端每隔定长时间请求拉取一次数据，可能有更新数据返回，也可能什么都没有。



**Long Polling（长轮询）：**

相比Polling，客户端发起Long Polling，此时如果服务端没有相关数据，会hold住请求，直到服务端有相关数据，或者等待一定时间超时才会返回。返回后，客户端又会立即再次发起下一次Long Polling。这种方式也是对拉模式的一个优化，解决了拉模式数据通知不及时，以及减少了大量的无效轮询次数。（所谓的hold住请求指的服务端暂时不回复结果，保存相关请求，不关闭请求连接，等相关数据准备好，写会客户端。）



主要原因是网络传输层主要走的是tcp协议，tcp协议是可靠面向连接的协议，通过三次握手建立连接。但是所建立的连接是虚拟的，可能存在某段时间网络不通，或者服务端程序非正常关闭，亦或服务端机器非正常关机，面对这些情况客户端根本不知道服务端此时已经不能互通，还在傻傻的等服务端发数据过来，而这一等一般都是很长时间。当然tcp协议栈在实现上有保活计时器来保证的，但是等到保活计时器发现连接已经断开需要很长时间，如果没有专门配置过相关的tcp参数，一般需要2个小时，而且这些参数是机器操作系统层面，所以，以此方式来保活不太靠谱，故Long Polling的实现上一般是需要设置超时时间的。

**实现**

Long Polling的实现很简单，可分为四个过程：

- 发起Polling
   发起Polling很简单，只需向服务器发起请求，此时服务端还未应答，所以客户端与服务端之间一直处于连接状态。
- 数据推送
   如果服务器端有相关数据，此时服务端会将数据通过此前建立的通道发回客户端。
- Polling终止
   Polling终止情况有三种：
   若服务端返回相关数据，此时客户端收到数据后，关闭请求连接，结束此次Polling过程。
   若客户端等待设定的超时时间后，服务端依然没有返回数据，此时客户端需要主动终止此次Polling请求。
   若客户端收到网络故障或异常，此时客户端自然也是需要主动终止此次Polling请求。
- 重新Polling
   终止上次Polling后，客户端需要立即再次发起Polling请求。这样才能保证拉取数据的及时性。

代码实现起来也很简单，Http Call按照上述过程就很方便实现LongPolling。



链接：https://www.jianshu.com/p/d3f66b1eb748



**长连接与长轮询：**

**一、长短轮询**
 **1、短轮询：**
 客户端向服务器端发起请求，服务器端立即返回相关信息并且关闭链接。同时客户端再次发起请求，与服务器端建立链接。
 优点：后端程序的编写简单
 缺点：大部分请求是无用的。

------

**2、长轮询**

与轮询不同的是服务器端会hold住链接，等待有数据的情况下返回并且关闭连接。
 区别：服务器端hold住请求，客户端不会再请求数据。
 优点：无消息的情况下不会再次发起请求
 缺点：  会耗费服务端的性能

**3、总结：**
 短轮询和长轮询主要是服务器端的实现方式，如果服务器端挂起请求等待消息则实现长轮询，如果服务器端不管任何条件下都返回数据则为短轮询。这种方式可以称之为编程方式实现短轮询和长轮询。

**二、长短连接**
 首先区分概念，HTTP是基于**请求/响应**模式的无状态协议（属于应用层协议），因此只要服务端做出了反应，则HTTP连接消失。因此，HTTP本身并没有长短连接之分，所以根本没有长短连接这种说法。
 TCP是一个双向通道，它可以保持一段时间不关闭。长连接是指TCP连接。

**1、短连接**
 工作模式： 连接->传输数据->关闭连接
 客户端每一次与服务器端建立连接后进行一次HTTP操作就关闭请求。

**2、长连接**
 工作模式：连接->传输数据->保持连接->传输数据.......->保持连接->传输数据->关闭连接。
 建立连接之后无论是否有数据通信都保持连接状态，存在某种机制可以销毁连接。
 **3、总结**
 长短连接是基于协议的，一个TCP连接是否为长连接，是通过设置HTTP的Connection Header来决定的，而且是需要客户端和服务器端都设置才有效。



链接：https://www.jianshu.com/p/2923b23f51ee





### IP

1、IP地址分为几类？简单说一下分类

2、怎么解决IPv4地址的不足（说了NAT）



### OpenSSH

1、说说ssl加密原理？





### IO

1、linux io和标准io区别

2、谈谈io复用，select

3、Q：epoll和select/poll的区别
A：epoll是实现I/O多路复用的一种方法,有水平触发（level trigger，LT，默认)和边缘触发（edge trigger，ET）两种工作模式，区别在于两种模式的返回就绪状态的时间不同。水平触发和select/poll的方式一样 

4、熟悉句柄么？程序执行后句柄如何处理，如何修改可打开句柄数量？

 5、select和epoll，epoll底层实现，数据的拷贝方式，epoll有几种类型？

6、I/O模型介绍，细说slect和epoll。I/O多路转接阻塞?非阻塞？有什么问题?

7、容器的i/o是如何实现隔离的

### 共享内存

1、谈谈项目***享内存实现方法



### 常用命令

1、netstat，top，free -m 都显示了什么有什么含义

# Unix环境高级编程

linux命令大全查询网站：http://man.linuxde.net/



1、linux 下编译调试方法，如何调试内存泄露问题

2、根据主要用的编译环境，我是windows，他问了debug和release的区别，我就说一个会忽视ass断言一个不会（太激动还把断言说成了警告。。。）。然后又追问另一个问题，我都忘记是啥了。。。

3、Linux下删除同一文件夹下所有满足条件的文件

4、git pull和git fetch的区别

5、文件系统，文件名和文件权限是存在一块的吗？（innode不存文件名，存权限，访问日期，指向数据的指针等等）

6、一个文件的md5码会因为该文件名而更改吗？

7、从网上下载的各种 .ios软件包会改变md5码吗？

8、编写shell脚本  查看一个文件，大小大于10M就删除，否则打印内容

9、linux下如何快速将文件每行倒序输出？shell或者编程都行，说了下python和c++实现方法，结果人考的是tac命令

10、linux下如何查看特定端口有多少tcp连接？

11、讲下文件系统实现吧

12、Linux命令，find，grep，ps，netstat

13、linux的ps命令

14、Linux查看进程某个端口的进程

- `lsof -i`：列出当前系统打开文件的工具
- `lsof -i:端口号`：用于查看某一端口的占用情况，比如查看22号端口使用情况，`lsof -i:22`
- `netstat -tunlp`：用于显示tcp，udp的端口和进程等相关情
- `netstat -tunlp|grep 端口号`：用于查看指定端口号的进程情况，如查看22端口的情况，netstat -tunlp|grep 22

15、Linux如何查看进程的内存使用情况

- /proc/meminfo：列出了所有你想了解的内存的使用情况
- atop命令是一个终端环境的监控命令。它显示的是各种系统资源（CPU, memory, network, I/O, kernel）的综合，并且在高负载的情况下进行了彩色标注
- free命令是一个快速查看内存使用情况的方法，它是对 /proc/meminfo 收集到的信息的一个概述

16、Linux如何查看进程的网络I/O

- iptraf：它可以生成多种网络统计信息包括：TCP信息、UDP数量、ICMP和OSPF信息、以太网负载信息、节点状态、IP校验错误等

Linux命令，延伸：netstat，top，free -m 都显示了什么有什么含义？



 CPU高了怎么看？ 	

 	A：free+pprof，看火焰图 

 	Q：其实C/C++也有类似地工具 

 	A：嗯 

 		Q：coredump有了解过吗？ 	

 		A：只用过，不知道原理 	

 		Q：你可以再了解一下呀。这个还是很重要的。 	

 		A：好的

编译器除了gcc,g++还了解什么？

2.编译选项常用的说说。

3.coredump用过没？

4.gbd如何解决多线程死锁问题。（不会）

# 文件系统

1、内核文件系统中索引节点什么时候被删除

.文件系统，文件名和文件权限是存在一块的吗？（innode不存文件名，存权限，访问日期，指向数据的指针等等）

.一个文件的md5码会因为该文件名而更改吗？

从网上下载的各种 .ios软件包会改变md5码吗？



# 操作系统+体系结构

## 操作系统

### 进程

如何实现守护进程（不会）

1、线程、进程

2、进程间通信

3、Q：进程和线程的区别？

- 资源
- 调度
- 通信
- 健壮

多线程和多进程的优缺点

4、进程同步

5、调度算法有哪些？

6、进程、线程、携程的区别

7、进程创建子进程，fork详解

8、守护进程

​	守护进程（daemon）是指在UNIX或其他多任务操作系统中在后台执行的电脑程序，程序的名称通常以字母“d”结尾。守护进程是生存期长的一种进程。它们不接受电脑用户的直接操控。它们独立于控制终端并且周期性的执行某种任务或等待处理某些发生的事件。他们常常在系统引导装入时启动（进程的启动方式有其特殊之处），在系统关闭时终止。unix系统有很多守护进程，大多数服务器都是用守护进程实现的。比如，网络服务inetd、Web服务http等。守护进程也能够对硬件进行配置（如在某些Linux系统上的devfsd），运行计划任务（例如cron），以及运行其他任务。同时，守护进程完成许多系统任务。比如作业规划进程crond、打印进程lqd等。守护进程及其特性守护进程最重要的特性是后台运行。其次，守护进程必须与其运行前的环境隔离开来。这些环境包括未关闭的文件描述符、控制终端、会话和进程组、工作目录以及文件创建掩码等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的。最后一点，守护进程没有任何存在的父进程（即PPID=1），且在UNIX系统进程层级中直接位于init之下。守护进程程序通常通过如下方法使自己成为守护进程：对一个子进调用fork，然后使其父进程立即终止，使得这个子进程能在init下运行。这种方法通常被称为“脱壳”。

 

Reference; https://blog.csdn.net/g_grp/article/details/51760604

9、互斥的方式

说说你理解的进程、线程？进程的内存分布？孤儿进程？

多个进程同时监听一个UDP端口会怎么样？

A：不懂……

Q：你可以了解一下这方面。进程的内存结构？

A：内核、栈、动态链接库、堆、静态区、代码段、保留区



### 进程间通信

1、进程间的通信有哪些方式？你用过什么？
管道、有名管道、（信号、信号量、）共享内存、消息队列、socket

2、进程间如何实现共享

3、读写锁知道吧，写个多个读者读，阻塞写者的实现

4、读写锁说一下，怎么使用

5、信号量和互斥量的区别，结合消费者问题说一下，互斥量加锁解锁的是用一个进程，信号量可以不同





### 锁

1、死锁是怎么产生的

2、知道互斥锁吗？   

​    他用什么来保证共享数据的安全性？   

​    这个我说信号量，他说如果用信号量来解决，现在出现一个状况，两段进程都被标记为可以访问该共享数据，但我们的共享单元只能支撑一个进程访问。这时候怎么办？   

​    我说用唯一标识符去处理。生成唯一标识符，这样就不会出现这种情况。   

​    他说不对。让我回去好好看看。   

​    回去查了一下，是**原子操作**。。   

​    (这个问题问了好久)

乐观锁、悲观锁、互斥锁、读写锁的原理实现与区别

atomic和锁机制，为什么锁效率低

3、问我了解没了解过递归锁。

4、怎么解决死锁（从理论上答了死锁预防、避免避免、死锁检测的一些方法）

5、自旋锁和互斥量的区别（自旋锁和互斥量是忙等与阻塞的区别）

6、自旋锁是如何实现的

说说map with mutex和sync.Map的区别？

A：Mutex是悲观锁，而且那个粒度比较大。sync.Map是带缓存的，体验和CAS差不多。



### 线程

1、手写简单的一个线程

2、手写多个线程按顺序执行

3、线程与线程之间怎么通信，用的什么机制

4、线程同步方式

5、谈谈项目中的多线程和线程池？

6、多线程操作一个hash表呢？用什么锁？

7、多线程对公共资源同时访问。（线程安全，同步互斥）

线程的生命周期

**两个线程，一个线程打印A，一个线程打印B，如何实现两个线程按顺序打印出ABABAB...?**



#### 1、线程安全

1. 多个线程同时访问时，其表现出正确的行为

2. 无论操作系统如何调度这些线程，无论这些线程的执行顺序如何交织

3. 调用端代码无需额外的同步或者其他协同操作

   c++标准库中大多数的class都不是线程安全的，包括string，vector，map，因为这些clss都需要外部枷锁才能供多个线程同时访问



### 协程



我看你这边github上有一个协程库，能介绍一下协程的概念吗？ 

 	A：协程，用户级，轻量，快，效率高，但是不结合多线程难以利用多核 

 	Q：能说一下怎么实现的吗？ 

 	A：讲了一下基于ucontext怎么切换上下文 

 	Q：协程和线程的区别？ 

 	A：调度比较快，不用进内核。单Schedual难以利用多核？ 

 	Q：内存上有什么区别？ 

 	A：同一个CPU上多个协程不会产生临界区竞争。 

 	Q：协程切换的时机？ 

 	A：定时器，文件阻塞，拿到锁阻塞，函数调用的时候。 

 	Q：你写的库的对于使用者有什么优势？ 

 	A：……你可以用我的APIbalabala…… 

 	Q：给我一个用你的协程库的场景吧？？ 

 	A：YY了一个轮询读文件的场景。 

 	Q：你这个说到了你维护了一个栈，这个栈是干什么的？栈的维护是你自己做的吗？ 

 	A：维护每个协程的上下文。我就只需要管理这块内存就可以。不是很完善…… 

 	Q：上个读文件的场景，什么时候才会阻塞？ 

 	A：设一个NONBLOCK位，在出错读到EAGAIN的时候就切换出去。 

 	Q：如果两个都阻塞了呢？ 

 	A：那就没辙了……举了一个很多fd用epoll轮询的场景。 

 	Q：从你个人角度有没有遇到过比较困难的场景？ 

 	A：balabala……



### cache

1、cache的工作原理

2、

Q：说一下cache吧 

  A：LRU那种？ 

  Q：是的。 

  A：因为java里面有一个数据结构linkedhashmap这个是很符合LRU的，然后按这个的源码说了一下，主要是hash+链表。 

  Q：这个怎么实现同步和互斥，怎么样去加锁 

  A：然后说了一下锁的相关知识，balabala

Buffer 和cache

缓存命中和不命中

关于共享内存 mmap 映射文件。

\3. Dcache

### 内存

怎么理解物理内存、逻辑内存？如果中国每个人都有e-mail，把所有人e-mail都存到内存中，存得下吗？（13亿人，每人20字节，估算共多少内存）



## 计算机体系结构

#### 1、虚拟内存和物理内存的区别

* 物理寻址

![1557905820971](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557905820971.png)

* **虚拟寻址**

![1557906100167](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557906100167.png)

* **物理地址与虚拟地址**

  地址空间是一个非负整数地址的有序集合

![1557906376911](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557906376911.png)



**主存中的每字节都有一个选自虚拟空间的虚拟地址和选自物理空间的物理地址**

* **物理页与虚拟页**

​	在概念上，虚拟内存相当于一个存放在磁盘上的N个连续字节大小的单元组成的数组，每个字节都有一个维系的虚拟地址，作为数组的索引，磁盘上数组的内容被缓存到主存中。磁盘上的数组被分割为块，这些块作为磁盘和主存之间的传输单元，并称为虚拟页(VP)。类似的，物理内存也被分割为物理页(PP)，且两者大小相同。

![1557908230757](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557908230757.png)

未分配：在磁盘上还不存在

未缓存：在磁盘上存在，但是并未缓存在主存中

已缓存：在磁盘上存在，且在主存中



* **DRAM与SRAM**

![1557908353801](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557908353801.png)

![1557908542661](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557908542661.png)

* **页表**

![1557908717315](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557908717315.png)

![1557909080250](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557909080250.png)

* **页命中**

![1557909238653](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557909238653.png)

**MMU地址翻译硬件将虚拟地址作为索引来找到PTE2**

* **缺页**

![1557909910009](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557909910009.png)

![1557909926029](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557909926029.png)

![1557909949608](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557909949608.png)

* **分配页面**

![1557910072070](F:\NoteBook_MD\study_Coding\C++\%5CUsers%5Cchangyan%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1557910072070.png)



​	如图，当我们调用malloc时，需要先在磁盘上创建空间VP5，并更新PTE5，使他指向磁盘上这个新创建的页面。

![1557911468556](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557911468556.png)



* **页面共享**

![1557911344056](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557911344056.png)

![1557911374662](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557911374662.png)



#### 2、内存映射

![1557911301925](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557911301925.png)

​	Linux通过将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射，虚拟内存区域可以映射到两种类型的对象中的一种：Linux文件系统中的普通文件、匿名文件。

​	无论在哪种情况汇总，一旦一个虚拟页面被初始化了，他就在一个由内核维护的专门的交换文件（swap file）之间换来换去，交换文件也叫做交换空间(swap space)或者交换区域(swap area)，需要意识到的很重要的一点是，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。

#### 3、出现段错误的原因

![1557913345899](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557913345899.png)

![1557913366514](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557913366514.png)



**访问一个不存在的页也会导致段错误异常**



#### 4、逻辑地址到物理地址的过程

![1557993577513](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993577513.png)

![1557993597280](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993597280.png)

![1557993615745](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993615745.png)

![1557993630678](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993630678.png)

![1557993652033](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993652033.png)

![1557993665790](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993665790.png)

![1557993676683](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557993676683.png)



* 未加TLB的物理寻址

![1557994552329](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557994552329.png)

* 加了TLB的物理寻址

![1557994587196](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557994587196.png)

所有的地址翻译步骤都是在芯片上的MMU中执行的，因此非常快。

* 多级页表（可看）

![1557995312171](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995312171.png)

![1557995324548](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995324548.png)

![1557995342364](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995342364.png)

![1557995353717](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995353717.png)

#### 5、Linux的内存机制

![1557995948029](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995948029.png)

![1557995960047](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557995960047.png)

* **Linux内存机制中的段表示（段等价于区域）**

![1557996400202](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557996400202.png)

![1557996433062](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557996433062.png)

![1557996450637](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557996450637.png)

**task_struct描述了每个进程都有一个属于自己的页表**

* Linux的缺页处理

![1557996986658](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557996986658.png)

![1557996999639](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557996999639.png)

![1557997013080](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1557997013080.png)

#### 6、分段分页机制

**基础概念：**

* 逻辑地址:
  机器语言指令仍用这种地址指定一个操作数的地址或一条指令的地址。 这种寻址方式在Intel的分段结构中表现得尤为具体，它使得MS-DOS或Windows程序员把程序分为若干段。每个逻辑地址都由一个段和偏移量组成。

* 线性地址：
  线性地址是一个32位的无符号整数，可以表达高达232（4GB）的地址。通常用16进制表示线性地址，其取值范围为0x00000000～0xffffffff。

* 物理地址：

  也就是内存单元的实际地址，用于芯片级内存单元寻址。 物理地址也由32位无符号整数表示。

**分段机制：**

​	MMU是一种硬件电路，它包含两个部件，一个是分段部件，一个是分页部件，在此，我们把它们分别叫做分段机制和分页机制，以利于从逻辑的角度来理解硬件的实现机制。分段机制把一个逻辑地址转换为线性地址；接着，分页机制把一个线性地址转换为物理地址。

​	分段机制是IA32提供的寻址方式，这是硬件层面的。就是说，不管你是windows还是linux，只要使用IA32的CPU访问内存，都要经过MMU的转换流程才能得到物理地址，也就是说必须经过逻辑地址–线性地址–物理地址的转换

**Linux中分段的实现**

​	从2.2版开始，Linux让所有的进程（或叫任务）都使用相同的逻辑地址空间，因此就没有必要使用局部描述符表LDT。但内核中也用到LDT，那只是在VM86模式中运行Wine，因为就是说在Linux上模拟运行Winodws软件或DOS软件的程序时才使用。

​	**在 IA32 上任意给出的地址都是一个虚拟地址，即任意一个地址都是通过“选择符(段选择子GDT、LDT、IDT):偏移量”的方式给出的，这是段机制存访问模式的基本特点。**所以在IA32上设计操作系统时无法回避使用段机制。一个虚拟地址最终会通过“段基地址＋偏移量”的方式转化为一个线性地址。Linux的设计人员干脆让段的基地址为0，而段的界限为4GB，这时任意给出一个偏移量，则等式为“0+偏移量=线性地址”，也就是说“偏移量＝线性地址”。另外由于段机制规定“偏移量<4GB”，所以偏移量的范围为0H～FFFFFFFFH，这恰好是线性地址空间范围，也就是说虚拟地址直接映射到了线性地址，我们以后所提到的虚拟地址和线性地址指的也就是同一地址。看来，Linux在没有回避段机制的情况下巧妙地把段机制给绕过去了

​	分段机制是IA32架构CPU的特色，并不是操作系统寻址方式的必然选择。Linux为了跨平台，巧妙的绕开段机制，主要使用分页机制来寻址。

**分页机制：**

​	分页机制由CR0中的PG位启用。如PG=1，启用分页机制，并使用本节要描述的机制，把线性地址转换为物理地址。如PG=0，禁用分页机制，直接把段机制产生的线性地址当作物理地址使用。分页机制管理的对象是固定大小的存储块，称之为页(page)。分页机制把整个线性地址空间及整个物理地址空间都看成由页组成，在线性地址空间中的任何一页，可以映射为物理地址空间中的任何一页（我们把物理空间中的一页叫做一个页面或页框(page frame)）

​	**两级页表：**

​	假设每个进程都占用了4G的线性地址空间，页表共含1M个表项，每个表项占4个字节，那么每个进程的页表要占据4M的内存空间。为了节省页表占用的空间，我们使用两级页表。每个进程都会被分配一个页目录，但是只有被实际使用页表才会被分配到内存里面。一级页表需要一次分配所有页表空间，两级页表则可以在需要的时候再分配页表空间。

​	1. CR3包含着页目录的起始地址，用32位线性地址的最高10位A31~A22作为页目录的页目录项的索引，将它乘以4，与CR3中的页目录的起始地址相加，形成相应页表的地址。

​	2. 从指定的地址中取出32位页目录项，它的低12位为0，这32位是页表的起始地址。用32位线性地址中的A21~A12位作为页表中的页面的索引，将它乘以4，与页表的起始地址相加，形成32位页面地址。

​	3. 将A11~A0作为相对于页面地址的偏移量，与32位页面地址相加，形成32位物理地址。

reference：https://blog.csdn.net/benpaobagzb/article/details/50804328

#### 7、cache结构，是否共享

​	为了解决高速 CPU 和慢速内存之间的速度 gap，处理器使用了多层次的结构，即使用 Cache 技术。现代 CPU 通常是采用多层次缓存结构，如图1 展示的是 Intel Ivy Bridge 的结构。

![img](file:///C:\Users\changyan\AppData\Local\Temp\ksohtml70444\wps1.png)

​							图 1:  Intel Ivy Bridge Cache Architecture

​	Intel CPU 共有三级缓存，每个核有 L1、L2 Cache，以及所有核共享的 L3 Cache，亦称 LLC（Last-Level Cache）。如图 1 中，每个核有 64 KB的 L1 Cache，包含 32 KB 的数据缓存和 32 KB 的指令缓存；每个核也有256 KB 的 L2 Cache。四个核共享 6 MB 的 L3 Cache。

​	Cache 将内存划分为固定大小的块，称之为 lines，通常是 64 或者 128字节。当处理器需要数据时，首先会检查 L1 Cache 有没有：

1. Cache Hit（缓存命中）：在 L1 Cache 中有所要的数据，那么直接从Cache 中加载数据

2. Cache Miss：没在缓存中找到

   

   如果 Cache Miss，那么会从下一级缓存中查找，直到从内存中加载数据。当从内存中加载一个数据，通常会存储在 Cache 中（如果 Cache 满了，会替换）。这个基于的事实是，最近使用的数据很有可能会马上再次被使用。

   

   LLC 有个重要的特性：LLC 包含所有更低 level 缓存的数据的复本，也就是说，L3 Cache 中包含 L1、L2 Cache 中的 lines。结果就是将数据 flush或者驱逐出 LLC，也会导致其他所有层次的 Cache 中将这个数据去除。这是 Flush+Reload 攻击所利用的一个特性。

   

   为了一致性，使用了缓存一致性协议，通常是基于 MESI 协议。一个核上内存进行写操作，会使得相应数据在 L1、L2 Cache 中的复本被标记为无效，使得之后在其他核是对这个数据的访问不会从 L1、L2 Cache 中加载。

​	Cache是微体系结构的概念，是内存的映像。其内容是内存的子集，cache没有程序上的意义，或者说没有功能上的意义，她只是为了减少内存的访问而存在

​	Cache没有独立的编址空间，对编程是透明的，处理器访问cache和访问存储器使用相同的地址，这跟寄存器不一样，寄存器有一个独立的编址空间，例如MIPS中，寄存器地址为5位，共32个寄存器。

* **与内存的映射：**

![1558076489330](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558076489330.png)

![1558076495422](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558076495422.png)

![1558076507090](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558076507090.png)

![1558076515688](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558076515688.png)



#### 8、CPU调度

Linux作为一个多任务操作系统，必须支持程序的并发执行。

* 任务分为：

1. 非抢占式多任务

```js
除非任务自己结束，否则将会一直执行。
```

2. 抢占式多任务（Linux）

```js
这种情况下，由调度程序来决定什么时候停止一个进程的运行，这个强制的挂起动作即为**“抢占”**。采用抢占式多任务的基础是使用**时间片轮转**机制来为每个进程分配可以运行的时间单位。
```

reference：https://cloud.tencent.com/developer/article/1027448

* 进程优先级

  普通进程的优先级分为静态优先级和动态优先级

  实时进程的优先级分为静态优先级、动态优先级和实时优先级

  普通进程和实时进程的静态优先级计算方法一致，动态优先级计算方法不同

  * 静态优先级(static priority)：
    * 静态优先级数值越大，进程的优先级越小，分配的基时间量就越少。
    * 一个进程通常会继承其父进程的static priority。也可以通过系统调用nice()或者setpriority()指定
    * static priority的范围是100-139
  * dynamic priority
    * 范围与静态优先级相同
    * 动态优先级是调度器选择一个进程时实际参考的值(dynamic priority = max( 100, min((static priority - bonus + 5), 139)))
    * 如果进程是普通进程，进程创建时，在wake_up_forked_process()中子进程继承了父进程的动态优先级，并添加到父进程的就绪队列中，如果父进程不在任何就绪队列中，则通过effective_prio()来计算出子进程的动态优先级并根据计算结果将子进程放置到相应的就绪队列中。
    * 如果进程是实时进程，dynamic priority,其值是在setscheduler()中设置的且一经设置便不再改变
  * 实时进程的rt_priority：
    * 每个实时进程都有一与其相关的实时优先级，取值范围0-99
    * 其大小可以通过sched_setscheduler()和__setscheduler_params()来改变
    * rt_priority的值越大，实时优先级越高

reference：https://blog.csdn.net/liuxingen/article/details/46574689

reference：https://blog.csdn.net/helloanthea/article/details/28877221

* 两种进程类型的比较

  ​	Linux的进程分普通进程和实时进程，普通进程即非实时进程SCHED_OTHER或SCHED_NORMAL，而实时进程又分SCHED_FIFO与SCHED_RR，实时进程的优先级（0~99）都比普通进程的优先级（100~139）高，且直到死亡之前始终是活动进程，当系统中有实时进程运行时，普通进程几乎是无法分到时间片的（只能分到5%的CPU时间）。
  reference：https://blog.csdn.net/helloanthea/article/details/28877221 

![1558081809480](C:\Users\changyan\AppData\Roaming\Typora\typora-user-images\1558081809480.png)

reference：http://wulc.me/2015/11/21/Linux%E7%9A%84CPU%E8%B0%83%E5%BA%A6/

* 调度方式

内核2.6版本有5种调度方式，分别是SCHED_FIFO、SCHED_RR、SCHED_OTHER、SCHED_IDLE、SCHED_BATCH

下面重点描述SCHED_FIFO、SCHED_RR、SCHED_OTHER三种调度策略，SCHED_FIFO、SCHED_RR针对实时进程的调度，SCHED_OTHER针对非实时进程的调度。

- SCHED_FIFO

  ​	先到先服务调度策略

  ​	实时进程，先进先出，它就一直运行直到退出，除非它阻塞才会释放CPU, 或被更高优先级的实时进程抢占。

  ​	所有任务都采用FIFO时，

  1.创建进程时指定采用FIFO，并设置实时优先级rt_priority(1-99)。

  2.如果没有等待资源，则将该任务加入到就绪队列中。

  3.调度程序遍历就绪队列，根据实时优先级计算调度权值(1000+rt_priority),选择权值最高的任务使用cpu，该FIFO任务将一直占有cpu直到有优先级更高的任务就绪(即使优先级相同也不行)或者主动放弃(等待资源)。

  4.调度程序发现有优先级更高的任务到达(高优先级任务可能被中断或定时器任务唤醒，再或被当前运行的任务唤醒，等等)，则调度程序立即在当前任务堆栈中保存当前cpu寄存器的所有数据，重新从高优先级任务的堆栈中加载寄存器数据到cpu，此时高优先级的任务开始运行。重复第3步。

  5.如果当前任务因等待资源而主动放弃cpu使用权，则该任务将从就绪队列中删除，加入等待队列，此时重复第3步。

- SCHED_RR

  ​	轮转调度策略

  ​        实时进程，基于优先级的轮回法（Round Robin），只有当它的时间片用完，内核会把它放到进程队列的末尾。放在队列尾保证了所有具有相同优先级的RR任务的调度公平。 

  ​	所有任务都采用RR调度策略时

  1.创建任务时指定调度参数为RR，并设置任务的实时优先级和nice值(nice值将会转换为该任务的时间片的长度)。

  2.如果没有等待资源，则将该任务加入到就绪队列中。

  3.调度程序遍历就绪队列，根据实时优先级计算调度权值(1000+rt_priority),选择权值最高的任务使用cpu。

  4.如果就绪队列中的RR任务时间片为0，则会根据nice值设置该任务的时间片，同时将该任务放入就绪队列的末尾。重复步骤3。

  5.当前任务由于等待资源而主动退出cpu，则其加入等待队列中。重复步骤3。

  

- SCHED_OTHER

  ​	分时调度策略

  ​	所有任务都采用linux分时调度策略时。

  1.创建任务指定采用分时调度策略，并指定优先级nice值(-20~19)。

  2.将根据每个任务的nice值确定在cpu上的执行时间(counter)。

  3.如果没有等待资源，则将该任务加入到就绪队列中。

  4.调度程序遍历就绪队列中的任务，通过对每个任务动态优先级的计算(counter+20-nice)结果，选择计算结果最大的一个去运行，当这个时间片用完后(counter减至0)或者主动放弃cpu时，该任务将被放在就绪队列末尾(时间片用完)或等待队列(因等待资源而放弃cpu)中。

  5.此时调度程序重复上面计算过程，转到第4步。

  6.当调度程序发现所有就绪任务计算所得的权值都为不大于0时，重复第2步。

  **补充：**

  SCHED_NORMAL：

  非实时进程，基于优先级的轮回法（Round Robin）

  

**系统中既有分时调度，又有时间片轮转调度和先进先出调度**
1.RR调度和FIFO调度的进程属于实时进程，以分时调度的进程是非实时进程。

2.当实时进程准备就绪后，如果当前cpu正在运行非实时进程，则实时进程立即抢占非实时进程。

3.RR进程和FIFO进程都采用实时优先级做为调度的权值标准，RR是FIFO的一个延伸。FIFO时，如果两个进程的优先级一样，则这两个优先级一样的进程具体执行哪一个是由其在队列中的位置决定的，这样导致一些不公正性(优先级是一样的，为什么要让你一直运行?),如果将两个优先级一样的任务的调度策略都设为RR,则保证了这两个任务可以循环执行，保证了公平。

reference：https://blog.csdn.net/maray/article/details/2900689



#### 9、CPU三大架构 NUMA、SMP、MPP

* SMP

  ​	SMP （Symmetric Multiprocessing） , 对称多处理器. 顾名思义, 在SMP中所有的处理器都是对等的, 它们通过总线连接共享同一块物理内存，这也就导致了系统中所有资源(CPU、内存、I/O等)都是共享的，当我们打开服务器的背板盖，如果发现有多个cpu的槽位，但是却连接到同一个内存插槽的位置，那一般就是smp架构的服务器，日常中常见的pc啊，笔记本啊，手机还有一些老的服务器都是这个架构，其架构简单，但是拓展性能非常差

* NUMA

  ​	NUMA （ Non-Uniform Memory Access），非均匀访问存储模型，这种模型的是为了解决smp扩容性很差而提出的技术方案，如果说smp 相当于多个cpu 连接一个内存池导致请求经常发生冲突的话，numa 就是将cpu的资源分开，以node 为单位进行切割，每个node 里有着独有的core ，memory 等资源，这也就导致了cpu在性能使用上的提升，但是同样存在问题就是2个node 之间的资源交互非常慢，当cpu增多的情况下，性能提升的幅度并不是很高。所以可以看到很多明明有很多core的服务器却只有2个node区。

* MPP

  ​	MPP (Massive Parallel Processing) ，这个其实可以理解为刀片服务器，每个刀扇里的都是一台独立的smp架构服务器，且每个刀扇之间均有高性能的网络设备进行交互，保证了smp服务器之间的数据传输性能。相比numa 来说更适合大规模的计算，唯一不足的是，当其中的smp 节点增多的情况下，与之对应的计算管理系统也需要相对应的提高。



下面这个命令可以很简单的看出cpu的架构以及配置

~~~ bash
#lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    1 #每个core 有几个线程
Core(s) per socket:    4 #每个槽位有4个core 
Socket(s):             2 #服务器面板上有2个cpu 槽位
NUMA node(s):          2 #nodes的数量
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 44
Stepping:              2
CPU MHz:               2128.025
BogoMIPS:              4256.03
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0,2,4,6 #对应的core
NUMA node1 CPU(s):     1,3,5,7

~~~

由于numa 架构经常会有内存分配不均匀的情况，常常需要手动干预，除了代码以外，还有linux命令进行cpu的绑定:

~~~ shell
taskset  -cp 1,2  25718 #将进程ID 25718 绑定到cpu的第1和第2个core 里
~~~

reference：https://www.jianshu.com/p/81233f3c2c14

# 项目

## 项目

1、项目介绍

2、难点

3、如何优化

服务器性能提升方案

 因为几个项目都和网络安全传输有关，三面面试官让我详述如何提升数据包在网络中的安全传输 安全性可靠性等问题

多线程、多进程在实际服务器中的应用；

如果你不清楚现在需求怎么做



## 设计模式

1、手写单例模式

开放封闭原则的意义（设计模式）；

生产者消费模式

**工厂模式和简单工厂方法有什么区别？**



## 数据库

1、数据库的脏读，脏读如何解决

2、数据库的三个范式

3、创建一个表，三行三列

4、事务特性

5、手撕sql查询排序？如何通过索引优化该sql？谈谈Innodb中b+树？myisam和Innodb中b树有什么区别？

6、讲下关系型数据库和K-V数据库的特点

7、数据库索引相关

8、知道那些非关系型数据库？

9、数据库索引 索引原理 以及如何优化数据库

 数据库索引原理（这块脑抽答错了 后来面试官人很好给我引导到B+树上去）

\5. 聚集索引

数据库的垂直拆分和水平拆分

- 数据库的事务实现原理、操作过程、如何做到事物之间的独立性等问题
- 数据库的脏读，幻读，不可重复读出现的原因原理，解决办法
- 数据库的隔离级别、MVCC

组合索引

mysql写数据的时候，需要先将数据写到buffer里，再写到磁盘里，万一MySQL这时候突然挂了，怎么办？
8、如果mysql直接将数据写到磁盘里会怎样

**MySQL数据库的事务ACID，隔离级别？**



# 不知道是什么的问题

CDN

Taf服务端源码/taf 客户端源码

加密解密 加密算法（这块没答好）



# 分布式

1、是否熟悉docker镜像制作？了解docker-compose？

2、如何设计一个高并发的分布式服务器？

3、了解那些分布式组件？说下Zookeeper和HDFS，说下CAP理论

分布式存储解决方案

负载均衡

- CAP原则
- CAS操作
- 分布式raft算法
- zookeeper原理



# 情商

1. 简单介绍一下自己。

2. 你从实习中学到了什么（本人在暑假于一个小公司实习过）。

3. 你觉得现在和之前（实习之前）比有什么变化。

4. 为什么不去读研。





## 面试过程中的积累：





